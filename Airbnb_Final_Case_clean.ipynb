{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FAlfa-F/airbnb-big-data-analytics-uc3m/blob/main/Airbnb_Final_Case_clean.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjEASOaJSJX2"
      },
      "source": [
        "# ![logo_UC3M.png](data:image/png;base64,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)\n",
        "\n",
        "# UC3M Big Data Final Challenge\n",
        "\n",
        "## Team 3\n",
        "\n",
        "## Project Overview\n",
        "- **Theme:** Data-driven assessment of short-term rental dynamics (Airbnb scale) in Barcelona and Madrid.\n",
        "- **Objective:** Equip investors with evidence-based guidance on pricing, demand, host practices, and neighborhood positioning using >300k listings, >1M reviews, and calendar records for both cities.\n",
        "\n",
        "## Why This Matters\n",
        "- Leisure travel surpasses $4.7T globally; platforms like Airbnb are still gaining share.\n",
        "- Dense marketplaces with millions of hosts and tenants are perfect playgrounds for advanced analytics, descriptive storytelling, and predictive modeling.\n",
        "\n",
        "## Core Questions We Answer\n",
        "1. **Market Dynamics:** How do property types, hosts, reviews, and locations interact across Madrid and Barcelona?\n",
        "2. **Value Extraction:** Which cleaning, feature engineering, and segmentation steps actually move the needle?\n",
        "3. **Performance Drivers:** What differentiates premium listings from average ones (pricing power, host traits, review tone, amenity mix)?\n",
        "4. **Actionable Insights:** Where should an investor deploy capital, what supply gaps exist, and which levers (price/occupancy/experience) change outcomes fastest?\n",
        "5. **Modeling:** When should we rely on descriptive views, statistical tests, or predictive models such as Random Forests for price and price-per-person?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mMcnZPqXNdJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WEsqMaHT-5b"
      },
      "source": [
        "## Data Loading & Global Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayIMxi4GUWlg"
      },
      "source": [
        "**To run this notebook in Google Colab:**\n",
        "\n",
        "1. **Upload your data folder**: Upload the `Airbnb 3` folder (containing `Barcelona` and `Madrid` subfolders) to your Google Drive root directory.\n",
        "\n",
        "2. **Run the Drive mount cell below**: When you execute the cell that mounts Google Drive, you'll be asked to authorize access. Click the link and grant permissions.\n",
        "\n",
        "3. **Data location**: The notebook expects data at `/content/drive/MyDrive/Airbnb 3/`. If your data is in a different location, update the `COLAB_BASE_PATH` variable in the path configuration cell.\n",
        "\n",
        "4. **Execute cells in order**: Run all cells sequentially from top to bottom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tlTHdaC3ZZ_Y"
      },
      "outputs": [],
      "source": [
        "# Google Drive mount for Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"✓ Google Drive mounted successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_gCcHbWjtL4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Set modern visual style\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "plt.rcParams['axes.facecolor'] = '#f8f9fa'\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# Define consistent color scheme\n",
        "COLORS = {\n",
        "    'madrid': '#E63946',      # Vibrant red\n",
        "    'barcelona': '#457B9D',   # Ocean blue\n",
        "    'accent': '#F77F00',      # Orange\n",
        "    'success': '#06D6A0',     # Teal\n",
        "    'neutral': '#6C757D'      # Gray\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2seRgPMmhM1"
      },
      "source": [
        "## Visualization Helper Functions\n",
        "\n",
        "Define reusable functions for consistent styling across all visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k0aAYgimhM1"
      },
      "outputs": [],
      "source": [
        "def style_axis(ax, title, xlabel, ylabel, grid=True):\n",
        "    \"\"\"Apply consistent styling to matplotlib axis\"\"\"\n",
        "    ax.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
        "    ax.set_xlabel(xlabel, fontsize=13, fontweight='bold')\n",
        "    ax.set_ylabel(ylabel, fontsize=13, fontweight='bold')\n",
        "    if grid:\n",
        "        ax.grid(True, alpha=0.3, linestyle='--')\n",
        "    return ax\n",
        "\n",
        "def format_currency(x, p):\n",
        "    \"\"\"Format numbers as currency with thousands separator\"\"\"\n",
        "    return f'€{int(x):,}'\n",
        "\n",
        "def add_value_labels(ax, orientation='v', format_fn=None):\n",
        "    \"\"\"Add value labels to bar plots\"\"\"\n",
        "    for container in ax.containers:\n",
        "        if format_fn:\n",
        "            labels = [format_fn(v.get_height() if orientation == 'v' else v.get_width())\n",
        "                     for v in container]\n",
        "        else:\n",
        "            labels = [f'{int(v.get_height() if orientation == \"v\" else v.get_width()):,}'\n",
        "                     for v in container]\n",
        "        if orientation == 'v':\n",
        "            ax.bar_label(container, labels=labels, padding=3, fontsize=10, fontweight='bold')\n",
        "        else:\n",
        "            ax.bar_label(container, labels=labels, padding=3, fontsize=10, fontweight='bold')\n",
        "    return ax\n",
        "\n",
        "print(\"✓ Helper functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbu0gIU5mhM2"
      },
      "outputs": [],
      "source": [
        "# === PATH CONFIGURATION ===\n",
        "# Google Colab path, assumes 'Airbnb 3' folder is in Drive root\n",
        "# If you placed it elsewhere, update this path:\n",
        "base_path = \"/content/drive/MyDrive/Airbnb 3\"\n",
        "\n",
        "# Define file paths, using .gz files where they exist\n",
        "paths = {\n",
        "    'barcelona_listings': f\"{base_path}/Barcelona/listings.csv.gz\",\n",
        "    'barcelona_reviews': f\"{base_path}/Barcelona/reviews.csv.gz\",\n",
        "    'barcelona_calendar': f\"{base_path}/Barcelona/calendar.csv.gz\",\n",
        "    'madrid_listings': f\"{base_path}/Madrid/listings.csv.gz\",\n",
        "    'madrid_reviews': f\"{base_path}/Madrid/reviews.csv.gz\",\n",
        "    'madrid_calendar': f\"{base_path}/Madrid/calendar.csv.gz\",\n",
        "}\n",
        "\n",
        "print(f\"✓ Paths configured: {base_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIe79CwhmhM2"
      },
      "outputs": [],
      "source": [
        "# Load datasets,  pandas automatically handles .gz compression\n",
        "\n",
        "print(\"Loading data...\")\n",
        "madrid_calendar_data = pd.read_csv(paths['madrid_calendar'], compression='gzip')\n",
        "barcelona_calendar_data = pd.read_csv(paths['barcelona_calendar'], compression='gzip')\n",
        "barcelona_reviews_data = pd.read_csv(paths['barcelona_reviews'], compression='gzip')\n",
        "madrid_reviews_data = pd.read_csv(paths['madrid_reviews'], compression='gzip')\n",
        "barcelona_listings = pd.read_csv(paths['barcelona_listings'], compression='gzip')\n",
        "madrid_listings = pd.read_csv(paths['madrid_listings'], compression='gzip')\n",
        "\n",
        "if 'id' not in madrid_listings.columns:\n",
        "    if 'listings.csv' in madrid_listings.columns:\n",
        "        print(\"Correcting 'id' column for Madrid listings...\")\n",
        "        madrid_listings['id'] = madrid_listings['listings.csv'].astype(float)\n",
        "        madrid_listings = madrid_listings.drop(columns=['listings.csv'])\n",
        "        print(\"'id' column corrected for Madrid listings.\")\n",
        "    else:\n",
        "        raise ValueError(\"Madrid listings file has neither 'id' nor 'listings.csv' columns.\")\n",
        "\n",
        "print(\"✓ Data loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "618b3VosmhM3"
      },
      "outputs": [],
      "source": [
        "# Add city labels to each dataset\n",
        "barcelona_listings['City'] = 'Barcelona'\n",
        "madrid_listings['City'] = 'Madrid'\n",
        "madrid_calendar_data['City'] = 'Madrid'\n",
        "barcelona_calendar_data['City'] = 'Barcelona'\n",
        "madrid_reviews_data['City'] = 'Madrid'\n",
        "barcelona_reviews_data['City'] = 'Barcelona'\n",
        "\n",
        "# Combine datasets\n",
        "combined_listings = pd.concat([barcelona_listings, madrid_listings], ignore_index=True)\n",
        "combined_reviews = pd.concat([barcelona_reviews_data, madrid_reviews_data], ignore_index=True)\n",
        "combined_calendar = pd.concat([barcelona_calendar_data, madrid_calendar_data], ignore_index=True)\n",
        "\n",
        "print(f\"✓ Combined {len(combined_listings):,} listings\")\n",
        "print(f\"✓ Combined {len(combined_reviews):,} reviews\")\n",
        "print(f\"✓ Combined {len(combined_calendar):,} calendar entries\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRS-rGvonYvv"
      },
      "outputs": [],
      "source": [
        "combined_calendar['date'] = pd.to_datetime(combined_calendar['date'])\n",
        "if combined_calendar['price'].dtype == 'object':\n",
        "    combined_calendar['price'] = combined_calendar['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
        "combined_calendar['month'] = combined_calendar['date'].dt.month\n",
        "combined_calendar['year'] = combined_calendar['date'].dt.year\n",
        "if combined_listings['price'].dtype == 'object':\n",
        "    combined_listings['price'] = combined_listings['price'].str.replace('$', '').str.replace(',', '').astype(float)\n",
        "combined_listings['date'] = pd.to_datetime(combined_calendar['date'])\n",
        "combined_listings['month'] = combined_calendar['date'].dt.month\n",
        "combined_listings['year'] = combined_calendar['date'].dt.year\n",
        "if combined_reviews['date'].dtype == 'object':\n",
        "    combined_reviews['date'] = pd.to_datetime(combined_reviews['date'])\n",
        "combined_reviews['month'] = combined_reviews['date'].dt.month\n",
        "combined_reviews['year'] = combined_reviews['date'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYYNEaq86bYH"
      },
      "outputs": [],
      "source": [
        "# Load Barcelona neighborhood data\n",
        "barcelona_neighbourhoods_csv_path = f\"{base_path}/Barcelona/neighbourhoods.csv\"\n",
        "barcelona_neighbourhoods_geojson_path = f\"{base_path}/Barcelona/neighbourhoods.geojson\"\n",
        "\n",
        "# Load data into DataFrames\n",
        "barcelona_neighbourhoods_data = pd.read_csv(barcelona_neighbourhoods_csv_path)\n",
        "import geopandas as gpd  # Import geopandas for geojson\n",
        "barcelona_neighbourhoods_geo = gpd.read_file(barcelona_neighbourhoods_geojson_path)\n",
        "\n",
        "# Display first few rows for verification\n",
        "display(barcelona_neighbourhoods_data.head())\n",
        "display(barcelona_neighbourhoods_geo.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjxzmJzpmhM3"
      },
      "outputs": [],
      "source": [
        "# Check available columns in combined_listings\n",
        "print(\"Available columns in combined_listings:\")\n",
        "print(combined_listings.columns.tolist())\n",
        "print(f\"\\nTotal columns: {len(combined_listings.columns)}\")\n",
        "print(f\"\\nDataFrame shape: {combined_listings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7d-du586qoX"
      },
      "outputs": [],
      "source": [
        "# Load Madrid neighborhood data\n",
        "madrid_neighbourhoods_csv_path = f\"{base_path}/Madrid/neighbourhoods.csv\"\n",
        "madrid_neighbourhoods_geojson_path = f\"{base_path}/Madrid/neighbourhoods.geojson\"\n",
        "\n",
        "# Load data into DataFrames\n",
        "madrid_neighbourhoods_data = pd.read_csv(madrid_neighbourhoods_csv_path)\n",
        "madrid_neighbourhoods_geo = gpd.read_file(madrid_neighbourhoods_geojson_path)\n",
        "\n",
        "# Display first few rows for verification (optional)\n",
        "display(madrid_neighbourhoods_data.head())\n",
        "display(madrid_neighbourhoods_geo.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImwvI4zaitjN"
      },
      "source": [
        "# **Section 1: Price Analysis & Market Positioning**\n",
        "\n",
        "We use this section as the strategic overview: benchmark both cities, highlight pricing gradients by neighborhood and property archetype, and stress-test the data quality that feeds statistical tests and models later on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNL4-nhWcgCO"
      },
      "source": [
        "This opening section sets the stage by comparing Madrid and Barcelona on key metrics like median price, price per guest, neighborhood variety, and host supply. We then dive deeper into specific factors in later sections.\n",
        "\n",
        "**What we don't know.** Our data has some gaps. We can't see actual occupancy or distinguish between dates that are booked versus dates the host chose to block. We also don't have square meter measurements to properly compare property sizes. So we use unavailable dates as a rough proxy for demand, use guest capacity and room counts as imperfect size estimates, and focus our conclusions on what we can actually measure: pricing patterns, host behavior, review quality, and amenities offered.\n",
        "\n",
        "**How to read this section.**\n",
        "- We start with descriptive analysis to understand the landscape and form initial ideas.\n",
        "- We then use statistical tests and models to confirm which factors actually affect prices.\n",
        "- When our data limitations prevent us from giving solid investment advice, we clearly say so. This way you can add your own assumptions about things like occupancy and acquisition costs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msiHpsMCn2Uk"
      },
      "source": [
        "## **Step 1: Pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HudqrgKcGtC"
      },
      "source": [
        "We keep only the columns that matter for a pricing lens: rates, property type, capacity, room/bath counts, review metrics, host traits, and availability settings. Cleaning the full raw schema (~100 columns) would add noise without changing conclusions, so we apply a “fit for purpose” rule: engineer and polish the variables that have business signal, ignore the rest until a later analysis proves otherwise.\n",
        "\n",
        "The cells below audit missingness, document any city-level skews, and give us a view of how much imputation or filtering is required before modeling. We start with listings, then replicate the process for calendar data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjBPWyTgpSTa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_nulls_for_price_analysis(df):\n",
        "    key_columns = [\n",
        "        'price',\n",
        "        'room_type',\n",
        "        'neighbourhood_cleansed',\n",
        "        'property_type',\n",
        "        'accommodates',\n",
        "        'bathrooms',\n",
        "        'bedrooms',\n",
        "        'beds',\n",
        "        'review_scores_rating',\n",
        "        'review_scores_cleanliness',\n",
        "        'review_scores_location',\n",
        "        'number_of_reviews',\n",
        "        'instant_bookable',\n",
        "        'host_is_superhost',\n",
        "        'host_listings_count',\n",
        "        'host_response_rate',\n",
        "        'minimum_nights',\n",
        "        'maximum_nights',\n",
        "        'availability_365',\n",
        "        'amenities'\n",
        "    ]\n",
        "\n",
        "    # Overall null analysis\n",
        "    null_analysis = pd.DataFrame({\n",
        "        'null_count': df[key_columns].isnull().sum(),\n",
        "        'null_percentage': (df[key_columns].isnull().sum() / len(df) * 100).round(2)\n",
        "    })\n",
        "    null_analysis['dtype'] = df[key_columns].dtypes\n",
        "    null_analysis = null_analysis.sort_values('null_percentage', ascending=False)\n",
        "\n",
        "    # City-specific analysis\n",
        "    cities = df['City'].unique()\n",
        "    city_null_counts = {}\n",
        "    city_null_percentages = {}\n",
        "\n",
        "    for city in cities:\n",
        "        city_data = df[df['City'] == city]\n",
        "        city_null_counts[city] = city_data[key_columns].isnull().sum()\n",
        "        city_null_percentages[city] = (city_data[key_columns].isnull().sum() / len(city_data) * 100).round(2)\n",
        "\n",
        "    null_by_city = pd.DataFrame(city_null_counts)\n",
        "    null_by_city_pct = pd.DataFrame(city_null_percentages)\n",
        "\n",
        "    return null_analysis, null_by_city, null_by_city_pct\n",
        "\n",
        "# Run analysis\n",
        "null_analysis, null_by_city, null_by_city_pct = analyze_nulls_for_price_analysis(combined_listings)\n",
        "\n",
        "print(\"Overall null analysis:\")\n",
        "print(null_analysis)\n",
        "print(\"\\nNull counts by city:\")\n",
        "print(null_by_city)\n",
        "print(\"\\nNull percentages by city:\")\n",
        "print(null_by_city_pct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCJNDwrjgnuw"
      },
      "source": [
        "We replicate the missing-value audit for `calendar` so we understand how reliable nightly prices, availability flags, and min/max night rules are per city."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTWZ48VyppXE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_calendar_nulls(df):\n",
        "    key_columns = [\n",
        "        'listing_id',\n",
        "        'date',\n",
        "        'available',\n",
        "        'price',\n",
        "        'adjusted_price',\n",
        "        'minimum_nights',\n",
        "        'maximum_nights'\n",
        "    ]\n",
        "\n",
        "    # Overall null analysis\n",
        "    null_analysis = pd.DataFrame({\n",
        "        'null_count': df[key_columns].isnull().sum(),\n",
        "        'null_percentage': (df[key_columns].isnull().sum() / len(df) * 100).round(2)\n",
        "    })\n",
        "    null_analysis['dtype'] = df[key_columns].dtypes\n",
        "    null_analysis = null_analysis.sort_values('null_percentage', ascending=False)\n",
        "\n",
        "    # Split by city using the listing_id to match with combined_listings\n",
        "    calendar_with_city = df.merge(\n",
        "        combined_listings[['id', 'City']],\n",
        "        left_on='listing_id',\n",
        "        right_on='id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    cities = combined_calendar['City'].unique()\n",
        "    city_null_counts = {}\n",
        "    city_null_percentages = {}\n",
        "\n",
        "    for city in cities:\n",
        "        city_data = combined_calendar[combined_calendar['City'] == city]\n",
        "        city_null_counts[city] = city_data[key_columns].isnull().sum()\n",
        "        city_null_percentages[city] = (city_data[key_columns].isnull().sum() / len(city_data) * 100).round(2)\n",
        "\n",
        "    null_by_city = pd.DataFrame(city_null_counts)\n",
        "    null_by_city_pct = pd.DataFrame(city_null_percentages)\n",
        "\n",
        "    return null_analysis, null_by_city, null_by_city_pct\n",
        "\n",
        "# Run analysis\n",
        "null_analysis, null_by_city, null_by_city_pct = analyze_calendar_nulls(combined_calendar)\n",
        "\n",
        "print(\"Overall calendar null analysis:\")\n",
        "print(null_analysis)\n",
        "print(\"\\nNull counts by city:\")\n",
        "print(null_by_city)\n",
        "print(\"\\nNull percentages by city:\")\n",
        "print(null_by_city_pct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv2yo0qcjkk5"
      },
      "source": [
        "From this point on we work on analysis-specific copies: `listings_first_clean` and `calendar_first_clean`. Each section can then tailor its own imputations or outlier rules without stepping on the others. The only global drop is `adjusted_price`, which is practically empty across both cities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Yv01KggmXlV"
      },
      "outputs": [],
      "source": [
        "calendar_first_clean = combined_calendar.copy(deep=True)\n",
        "listings_first_clean = combined_listings.copy(deep=True)\n",
        "calendar_first_clean = calendar_first_clean.drop('adjusted_price', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl0PTPA67gSu"
      },
      "source": [
        "Pricing errors at the extreme right tail (ghost listings, manual entry mistakes, single-night luxury villas) warp all descriptive charts. Dropping the top 1 % keeps the mainstream market intact while removing values that can easily double a neighborhood average. I validated both versions (with/without the filter) and the filtered view produces narratives that match reality (e.g., central districts surface as the most expensive instead of obscure neighborhoods with a single erroneous record)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlfPWc5J5SXZ"
      },
      "outputs": [],
      "source": [
        "# Calculate the 99th percentile price cutoff\n",
        "price_cutoff = listings_first_clean['price'].quantile(0.99)\n",
        "\n",
        "# Filter the dataset\n",
        "listings_first_clean = listings_first_clean[listings_first_clean['price'] <= price_cutoff]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZW4bq_Vj2lf"
      },
      "source": [
        "Before deciding how aggressively to drop or impute, we inspect which property archetypes lack room/bath data. If missingness is concentrated in shared rooms, we can justify tailored defaults; if it is random across entire homes we should be more conservative. Airbnb requires at least one bed, so seeing a missing `beds` value immediately hints at data entry errors that we may need to fix manually."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc4YzIGRmRdh"
      },
      "outputs": [],
      "source": [
        "def analyze_missing_room_data(listings_df):\n",
        "    \"\"\"Analyze listings with missing bathroom, bedroom, or bed data\"\"\"\n",
        "    # Create mask for missing values\n",
        "    missing_rooms = listings_df[\n",
        "        listings_df['bathrooms'].isna() |\n",
        "        listings_df['bedrooms'].isna() |\n",
        "        listings_df['beds'].isna()\n",
        "    ]\n",
        "\n",
        "    # Key columns for analysis\n",
        "    analysis_cols = [\n",
        "        'id', 'City', 'bathrooms', 'bedrooms', 'beds',\n",
        "        'property_type', 'room_type', 'accommodates',\n",
        "        'price', 'review_scores_rating'\n",
        "    ]\n",
        "\n",
        "    # Summary statistics\n",
        "    stats = {\n",
        "        'total_listings': len(listings_df),\n",
        "        'missing_data_listings': len(missing_rooms),\n",
        "        'missing_percentage': (len(missing_rooms) / len(listings_df) * 100),\n",
        "        'by_city': missing_rooms.groupby('City').size().to_dict(),\n",
        "        'by_property_type': missing_rooms.groupby('property_type').size().to_dict(),\n",
        "        'by_room_type': missing_rooms.groupby('room_type').size().to_dict()\n",
        "    }\n",
        "\n",
        "    return missing_rooms[analysis_cols], stats\n",
        "\n",
        "# Run analysis\n",
        "missing_listings, missing_stats = analyze_missing_room_data(combined_listings)\n",
        "\n",
        "print(\"Missing room data statistics:\")\n",
        "print(f\"Total missing: {missing_stats['missing_data_listings']} ({missing_stats['missing_percentage']}%)\")\n",
        "print(\"\\nBy city:\")\n",
        "for city, count in missing_stats['by_city'].items():\n",
        "    print(f\"{city}: {count}\")\n",
        "print(\"\\nBy property type (top 5):\")\n",
        "for prop_type, count in dict(sorted(missing_stats['by_property_type'].items(), key=lambda x: x[1], reverse=True)[:5]).items():\n",
        "    print(f\"{prop_type}: {count}\")\n",
        "print(\"\\nSample of listings with missing data:\")\n",
        "print(missing_listings.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qulp1jAki6m"
      },
      "source": [
        "Capturing the baseline room-type mix (overall and by city) lets us monitor whether later cleaning steps distort supply. If, for instance, filtering nulls removes too many private rooms in Barcelona, the remaining distribution would overstate entire-home pricing. This quick snapshot becomes our guardrail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77d7JsDsmDbP"
      },
      "outputs": [],
      "source": [
        "def analyze_room_type_distribution(df):\n",
        "    \"\"\"Analyze room type distribution in the dataset\"\"\"\n",
        "\n",
        "    # Overall distribution\n",
        "    dist_overall = df['room_type'].value_counts()\n",
        "    dist_percentage = df['room_type'].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Distribution by city\n",
        "    dist_by_city = df.groupby(['City', 'room_type']).size().unstack().fillna(0)\n",
        "    dist_by_city_pct = df.groupby(['City', 'room_type']).size().unstack().fillna(0).apply(\n",
        "        lambda x: x/x.sum() * 100, axis=1\n",
        "    )\n",
        "\n",
        "    print(\"Overall Room Type Distribution:\")\n",
        "    for room_type, count in dist_overall.items():\n",
        "        print(f\"{room_type}: {count} ({dist_percentage[room_type]:.1f}%)\")\n",
        "\n",
        "    print(\"\\nDistribution by City (Count):\")\n",
        "    print(dist_by_city)\n",
        "\n",
        "    print(\"\\nDistribution by City (Percentage):\")\n",
        "    print(dist_by_city_pct.round(1))\n",
        "\n",
        "    return dist_overall, dist_by_city, dist_by_city_pct\n",
        "\n",
        "# Run analysis\n",
        "dist_overall, dist_by_city, dist_by_city_pct = analyze_room_type_distribution(combined_listings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7bXl4trk1-C"
      },
      "source": [
        "We run the same check specifically on listings with null prices. If an entire room type or city dominates those rows, we need a remediation plan before comparing price levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b61umwlBsHX2"
      },
      "outputs": [],
      "source": [
        "def analyze_null_price_distribution(listings_df):\n",
        "    \"\"\"Analyze room type distribution for listings with null prices\"\"\"\n",
        "\n",
        "    # Get listings with null prices\n",
        "    null_price_listings = listings_df[listings_df['price'].isna()]\n",
        "\n",
        "    # Calculate distribution\n",
        "    dist = null_price_listings['room_type'].value_counts()\n",
        "    dist_pct = null_price_listings['room_type'].value_counts(normalize=True) * 100\n",
        "\n",
        "    # Distribution by city\n",
        "    dist_by_city = null_price_listings.groupby(['City', 'room_type']).size().unstack(fill_value=0)\n",
        "    dist_by_city_pct = null_price_listings.groupby(['City', 'room_type']).size().unstack(fill_value=0).apply(\n",
        "        lambda x: x/x.sum() * 100, axis=1\n",
        "    )\n",
        "\n",
        "    print(\"Room Type Distribution for Listings with Null Prices:\")\n",
        "    for room_type, count in dist.items():\n",
        "        print(f\"{room_type}: {count} ({dist_pct[room_type]:.1f}%)\")\n",
        "\n",
        "    print(\"\\nDistribution by City (Count):\")\n",
        "    print(dist_by_city)\n",
        "\n",
        "    print(\"\\nDistribution by City (Percentage):\")\n",
        "    print(dist_by_city_pct.round(1))\n",
        "\n",
        "# Run analysis\n",
        "analyze_null_price_distribution(combined_listings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkx783qTk-Ue"
      },
      "source": [
        "Instead of dropping listings with missing beds/baths/bedrooms (which would disproportionately remove private and shared rooms), we benchmark the central tendency per `room_type`. Both the mean and median are captured for reference, but we ultimately plug medians because our distributions are skewed and medians preserve structure without being pulled by luxury outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1G-AMxdyrSP"
      },
      "outputs": [],
      "source": [
        "def validate_calendar_price_prediction(listings_df, calendar_df):\n",
        "    # Get listings with known prices\n",
        "    known_price_listings = listings_df[listings_df['price'].notna()].copy()\n",
        "\n",
        "    # Calculate calendar stats per listing\n",
        "    calendar_stats = calendar_df.groupby('listing_id').agg({\n",
        "        'price': ['mean', 'median', 'std', 'count']\n",
        "    })\n",
        "    calendar_stats.columns = ['cal_mean_price', 'cal_median_price', 'cal_price_std', 'price_count']\n",
        "    calendar_stats = calendar_stats.reset_index()\n",
        "\n",
        "    # Merge listings with their calendar stats\n",
        "    validation_df = known_price_listings.merge(\n",
        "        calendar_stats,\n",
        "        left_on='id',\n",
        "        right_on='listing_id',\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # Calculate error metrics\n",
        "    validation_df['abs_error'] = abs(validation_df['price'] - validation_df['cal_median_price'])\n",
        "    validation_df['pct_error'] = (validation_df['abs_error'] / validation_df['price']) * 100\n",
        "\n",
        "    # Group metrics by room type\n",
        "    metrics = validation_df.groupby('room_type').agg({\n",
        "        'abs_error': ['mean', 'median'],\n",
        "        'pct_error': ['mean', 'median'],\n",
        "        'id': 'count'\n",
        "    }).round(2)\n",
        "\n",
        "    print(\"Validation Metrics by Room Type:\")\n",
        "    print(metrics)\n",
        "\n",
        "    return validation_df\n",
        "\n",
        "# Run validation\n",
        "validation_df = validate_calendar_price_prediction(listings_first_clean, calendar_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvnHY2gVmkpA"
      },
      "source": [
        "Median-based imputation wins decisively, across room types it halves both the absolute and percentage error versus using means, so we push that rule into the production cleaning step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU51kCu9yyV8"
      },
      "outputs": [],
      "source": [
        "def impute_prices_from_calendar(listings_df, calendar_df):\n",
        "    listings_df = listings_df.copy()\n",
        "\n",
        "    calendar_stats = calendar_df.groupby('listing_id').agg({\n",
        "        'price': ['mean', 'median', 'std', 'count']\n",
        "    }).reset_index()\n",
        "    calendar_stats.columns = ['listing_id', 'cal_mean_price', 'cal_median_price', 'cal_price_std', 'price_count']\n",
        "\n",
        "    listings_df = listings_df.merge(\n",
        "        calendar_stats,\n",
        "        left_on='id',\n",
        "        right_on='listing_id',\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    mask_missing_price = listings_df['price'].isna()\n",
        "    mask_has_calendar = listings_df['cal_mean_price'].notna()\n",
        "\n",
        "    listings_df.loc[mask_missing_price & mask_has_calendar, 'price'] = \\\n",
        "        listings_df.loc[mask_missing_price & mask_has_calendar, 'cal_median_price']\n",
        "\n",
        "    imputed_count = (mask_missing_price & mask_has_calendar).sum()\n",
        "    remaining_nulls = listings_df['price'].isna().sum()\n",
        "\n",
        "    print(f\"Imputed {imputed_count} prices\")\n",
        "    print(f\"Remaining nulls: {remaining_nulls}\")\n",
        "\n",
        "    return listings_df\n",
        "\n",
        "# Run imputation\n",
        "listings_first_clean = impute_prices_from_calendar(listings_first_clean, calendar_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZOBR8e1yfGt"
      },
      "source": [
        "Next up: beds, bedrooms, and bathrooms. We impute by `property_type` first (a loft does not behave like a villa), then fall back to the global median for any lingering gaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R94oN4jy056"
      },
      "outputs": [],
      "source": [
        "def impute_room_data(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Calculate medians by property type\n",
        "    property_medians = df.groupby('property_type').agg({\n",
        "        'beds': 'median',\n",
        "        'bedrooms': 'median',\n",
        "        'bathrooms': 'median'\n",
        "    })\n",
        "\n",
        "    # Calculate overall medians for fallback\n",
        "    overall_medians = df[['beds', 'bedrooms', 'bathrooms']].median()\n",
        "\n",
        "    # Impute missing values\n",
        "    for column in ['beds', 'bedrooms', 'bathrooms']:\n",
        "        missing_mask = df[column].isna()\n",
        "        # First try property type median\n",
        "        df.loc[missing_mask, column] = df.loc[missing_mask, 'property_type'].map(property_medians[column])\n",
        "        # For any remaining nulls, use overall median\n",
        "        still_missing = df[column].isna()\n",
        "        if still_missing.any():\n",
        "            df.loc[still_missing, column] = overall_medians[column]\n",
        "\n",
        "    print(\"Imputation summary:\")\n",
        "    for column in ['beds', 'bedrooms', 'bathrooms']:\n",
        "        remaining_nulls = df[column].isna().sum()\n",
        "        print(f\"{column}: {remaining_nulls} remaining nulls\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# Run room data imputation\n",
        "listings_first_clean = impute_room_data(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGWypqP4yoqY"
      },
      "source": [
        "Review nulls mostly come from listings with zero reviews, which is perfectly valid and should remain 0 rather than be imputed. Still, we check if any listing with a total review count of 0 somehow has sub-scores populated (that would indicate inconsistent ingestion)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge8tjZCct8xI"
      },
      "outputs": [],
      "source": [
        "def analyze_review_data(df):\n",
        "    print(\"Listings with zero reviews:\", len(df[df['number_of_reviews'] == 0]))\n",
        "    print(\"\\nOf those with zero reviews:\")\n",
        "    zero_review_listings = df[df['number_of_reviews'] == 0]\n",
        "    print(\"- Null ratings:\", zero_review_listings['review_scores_rating'].isna().sum())\n",
        "    print(\"- Null cleanliness:\", zero_review_listings['review_scores_cleanliness'].isna().sum())\n",
        "    print(\"- Null location:\", zero_review_listings['review_scores_location'].isna().sum())\n",
        "\n",
        "analyze_review_data(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o5-TDwNzA50"
      },
      "source": [
        "When a listing lacks every score we simply keep 0s; downstream visuals interpret that as “not yet rated.” For the tiny set of listings that *do* have reviews but are missing one of the sub-scores, we drop them to avoid artificially inflating or deflating sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zbou_4TNy-wA"
      },
      "outputs": [],
      "source": [
        "def analyze_superhost_nulls(df):\n",
        "    \"\"\"Analyze listings with null superhost status before deciding how to handle them\"\"\"\n",
        "\n",
        "    superhost_nulls = df[df['host_is_superhost'].isna()]\n",
        "\n",
        "    print(f\"Total listings with null superhost status: {len(superhost_nulls)}\")\n",
        "    print(f\"Percentage of total: {len(superhost_nulls)/len(df)*100:.2f}%\\n\")\n",
        "\n",
        "    # Check room type distribution\n",
        "    print(\"Room type distribution of nulls:\")\n",
        "    print(superhost_nulls['room_type'].value_counts())\n",
        "    print(\"\\nAs percentages:\")\n",
        "    print(superhost_nulls['room_type'].value_counts(normalize=True) * 100)\n",
        "\n",
        "    # Check by city\n",
        "    print(\"\\n\\nDistribution by city:\")\n",
        "    print(superhost_nulls['City'].value_counts())\n",
        "\n",
        "    # Check host characteristics\n",
        "    print(\"\\n\\nHost listing counts for these nulls:\")\n",
        "    print(superhost_nulls['host_listings_count'].describe())\n",
        "\n",
        "    # Check if they have reviews\n",
        "    print(\"\\n\\nReview status:\")\n",
        "    print(f\"With reviews: {(superhost_nulls['number_of_reviews'] > 0).sum()}\")\n",
        "    print(f\"Without reviews: {(superhost_nulls['number_of_reviews'] == 0).sum()}\")\n",
        "\n",
        "    # Sample some records\n",
        "    print(\"\\n\\nSample records:\")\n",
        "    print(superhost_nulls[['id', 'City', 'room_type', 'host_listings_count',\n",
        "                            'number_of_reviews', 'price', 'host_since']].head(10))\n",
        "\n",
        "    return superhost_nulls\n",
        "\n",
        "# Run analysis before making decision\n",
        "superhost_null_analysis = analyze_superhost_nulls(listings_first_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtwyD7T-mhM7"
      },
      "outputs": [],
      "source": [
        "# Average number of reviews for listings with null superhost status\n",
        "superhost_nulls = listings_first_clean[listings_first_clean['host_is_superhost'].isna()]\n",
        "superhost_yes = listings_first_clean[listings_first_clean['host_is_superhost'] == 't']\n",
        "superhost_no = listings_first_clean[listings_first_clean['host_is_superhost'] == 'f']\n",
        "\n",
        "print(\"Listings with NULL superhost status:\")\n",
        "print(f\"Review Count - Mean: {superhost_nulls['number_of_reviews'].mean():.2f}\")\n",
        "print(f\"Review Count - Median: {superhost_nulls['number_of_reviews'].median():.2f}\")\n",
        "print(f\"Review Rating - Mean: {superhost_nulls['review_scores_rating'].mean():.2f}\")\n",
        "print(f\"Review Rating - Median: {superhost_nulls['review_scores_rating'].median():.2f}\")\n",
        "\n",
        "print(\"\\n\\nListings that ARE superhosts (host_is_superhost = 't'):\")\n",
        "print(f\"Review Count - Mean: {superhost_yes['number_of_reviews'].mean():.2f}\")\n",
        "print(f\"Review Count - Median: {superhost_yes['number_of_reviews'].median():.2f}\")\n",
        "print(f\"Review Rating - Mean: {superhost_yes['review_scores_rating'].mean():.2f}\")\n",
        "print(f\"Review Rating - Median: {superhost_yes['review_scores_rating'].median():.2f}\")\n",
        "\n",
        "print(\"\\n\\nListings that are NOT superhosts (host_is_superhost = 'f'):\")\n",
        "print(f\"Review Count - Mean: {superhost_no['number_of_reviews'].mean():.2f}\")\n",
        "print(f\"Review Count - Median: {superhost_no['number_of_reviews'].median():.2f}\")\n",
        "print(f\"Review Rating - Mean: {superhost_no['review_scores_rating'].mean():.2f}\")\n",
        "print(f\"Review Rating - Median: {superhost_no['review_scores_rating'].median():.2f}\")\n",
        "\n",
        "print(\"\\n\\nFor comparison - ALL listings:\")\n",
        "print(f\"Review Count - Mean: {listings_first_clean['number_of_reviews'].mean():.2f}\")\n",
        "print(f\"Review Count - Median: {listings_first_clean['number_of_reviews'].median():.2f}\")\n",
        "print(f\"Review Rating - Mean: {listings_first_clean['review_scores_rating'].mean():.2f}\")\n",
        "print(f\"Review Rating - Median: {listings_first_clean['review_scores_rating'].median():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmUTV43umhM8"
      },
      "source": [
        "Okay we'll keep the ones with null superhost since:\n",
        "* They're clearly legitimate, active properties\n",
        "* Losing 891 rows means losing 2.63% of your analysis power\n",
        "* They have BETTER than average review counts, suggesting they're quality listings\n",
        "* The 95 without reviews are only 10% of the null group, not concerning\n",
        "\n",
        "So we'll just assume they are NOT superhosts (conservative assumption)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3E1xRyjmhM8"
      },
      "outputs": [],
      "source": [
        "def handle_nulls(df):\n",
        "    df = df.copy()\n",
        "    initial_len = len(df)\n",
        "\n",
        "    # Based on analysis above, either drop or impute superhost nulls\n",
        "    # Option 1 (taken): Assume they're NOT superhosts (safer assumption)\n",
        "    df['host_is_superhost'] = df['host_is_superhost'].fillna('f')\n",
        "\n",
        "    # Option 2: Drop them in case we change our mind\n",
        "    # df = df.dropna(subset=['host_is_superhost'])\n",
        "\n",
        "    # Replace null response rates with \"unknown\"\n",
        "    df['host_response_rate'] = df['host_response_rate'].fillna(\"unknown\")\n",
        "    df['review_scores_rating'] = df['review_scores_rating'].fillna(0)\n",
        "    df['review_scores_cleanliness'] = df['review_scores_cleanliness'].fillna(0)\n",
        "    df['review_scores_location'] = df['review_scores_location'].fillna(0)\n",
        "\n",
        "    print(f\"Initial rows: {initial_len}\")\n",
        "    print(f\"Rows after handling nulls: {len(df)}\")\n",
        "    print(f\"Rows removed: {initial_len - len(df)}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "listings_first_clean = handle_nulls(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fRkn3wpzwiR"
      },
      "source": [
        "Quick sanity check: confirm that the core columns feeding Section 1 are now null-free."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvD2482k1hl8"
      },
      "outputs": [],
      "source": [
        "def check_key_nulls(df):\n",
        "    key_columns = [\n",
        "        'price',\n",
        "        'room_type',\n",
        "        'neighbourhood_cleansed',\n",
        "        'property_type',\n",
        "        'accommodates',\n",
        "        'bathrooms',\n",
        "        'bedrooms',\n",
        "        'beds',\n",
        "        'review_scores_rating',\n",
        "        'review_scores_cleanliness',\n",
        "        'review_scores_location',\n",
        "        'number_of_reviews',\n",
        "        'instant_bookable',\n",
        "        'host_is_superhost',\n",
        "        'host_listings_count',\n",
        "        'host_response_rate',\n",
        "        'minimum_nights',\n",
        "        'maximum_nights',\n",
        "        'availability_365',\n",
        "        'amenities'\n",
        "    ]\n",
        "\n",
        "    null_analysis = df[key_columns].isnull().sum()\n",
        "    print(\"Null values in key columns:\")\n",
        "    print(null_analysis[null_analysis > 0])  # Only show columns with nulls\n",
        "\n",
        "check_key_nulls(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff60Xoxmzk92"
      },
      "source": [
        "Only 96 listings still lacked `host_listings_count`, so we simply drop them since they are too few to influence supply metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUArQZgDm9iw"
      },
      "outputs": [],
      "source": [
        "# Drop rows with nulls in 'host_listings_count'\n",
        "listings_first_clean = listings_first_clean.dropna(subset=['host_listings_count'])\n",
        "\n",
        "# Verify the drop was successful\n",
        "print(\"Number of rows after dropping host_listings_count nulls:\", len(listings_first_clean))\n",
        "print(\"\\nRemaining nulls in host_listings_count:\", listings_first_clean['host_listings_count'].isnull().sum())\n",
        "\n",
        "# Additional verification of our cleaned dataset\n",
        "print(\"\\nShape of cleaned dataset:\", listings_first_clean.shape)\n",
        "print(\"\\nKey columns with any remaining nulls:\")\n",
        "key_columns = [\n",
        "    'price', 'room_type', 'neighbourhood_cleansed', 'property_type',\n",
        "    'accommodates', 'bathrooms', 'bedrooms', 'beds', 'review_scores_rating',\n",
        "    'review_scores_cleanliness', 'review_scores_location', 'number_of_reviews',\n",
        "    'instant_bookable', 'host_is_superhost', 'host_listings_count',\n",
        "    'host_response_rate', 'minimum_nights', 'maximum_nights',\n",
        "    'availability_365', 'amenities'\n",
        "]\n",
        "nulls = listings_first_clean[key_columns].isnull().sum()\n",
        "print(nulls[nulls > 0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNMByqiSz2Eo"
      },
      "source": [
        "With a clean base in place, we engineer the features we will repeatedly reference: price-per-person, price deltas vs. city/neighborhood averages, host professionalism flags, and availability proxies. These columns fuel every visualization and test in Section 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLpig16YgXF9"
      },
      "outputs": [],
      "source": [
        "def create_derived_columns(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Availability metrics\n",
        "    df['days_unavailable'] = 365 - df['availability_365']\n",
        "    df['availability_rate'] = df['availability_365'] / 365\n",
        "\n",
        "\n",
        "    # Price metrics\n",
        "    df['price_per_person'] = df['price'] / df['accommodates']\n",
        "    df['price_per_bedroom'] = df['price'] / df['bedrooms']\n",
        "    df['price_per_bathroom'] = df['price'] / df['bathrooms']\n",
        "    df['price_per_bed'] = df['price'] / df['beds']\n",
        "\n",
        "    # Property characteristics\n",
        "    df['total_rooms'] = df['bedrooms'] + df['bathrooms']\n",
        "    df['room_density'] = df['total_rooms'] / df['accommodates']\n",
        "\n",
        "    # Host characteristics\n",
        "    df['is_professional_host'] = df['host_listings_count'] > 1\n",
        "    df['is_instant_book'] = df['instant_bookable'].map({'t': True, 'f': False})\n",
        "\n",
        "    # Review metrics\n",
        "    df['has_reviews'] = df['number_of_reviews'] > 0\n",
        "\n",
        "    # Market positioning\n",
        "    df['city_avg_price'] = df.groupby('City')['price'].transform('mean')\n",
        "    df['price_vs_city_avg'] = (df['price'] - df['city_avg_price']) / df['city_avg_price']\n",
        "    df['neighborhood_avg_price'] = df.groupby('neighbourhood_cleansed')['price'].transform('mean')\n",
        "    df['price_vs_neighborhood_avg'] = (df['price'] - df['neighborhood_avg_price']) / df['neighborhood_avg_price']\n",
        "\n",
        "    return df\n",
        "\n",
        "listings_first_clean = create_derived_columns(listings_first_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnvefxTImhM9"
      },
      "outputs": [],
      "source": [
        "# For academic rigor, we must use the same cleaned dataset in all sections.\n",
        "# This ensures we're analyzing the same population throughout the analysis.\n",
        "\n",
        "combined_listings = listings_first_clean.copy()\n",
        "madrid_listings = combined_listings[combined_listings['City'] == 'Madrid'].copy()\n",
        "barcelona_listings = combined_listings[combined_listings['City'] == 'Barcelona'].copy()\n",
        "\n",
        "print(\"✓ Cleaned data reassigned to combined_listings\")\n",
        "print(f\"  Madrid listings: {len(madrid_listings):,}\")\n",
        "print(f\"  Barcelona listings: {len(barcelona_listings):,}\")\n",
        "print(f\"  Combined total: {len(combined_listings):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkYVMTmomhM-"
      },
      "source": [
        "**Data Integrity Check**\n",
        "\n",
        "Now that Section 1 cleaning is complete, we reassign the cleaned dataset to the variables used throughout the rest of the notebook (`combined_listings`, `madrid_listings`, `barcelona_listings`). This ensures academic rigor: every analysis operates on the same cleaned population."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olF-r-8WGoQH"
      },
      "source": [
        "## **Step 2: Descriptive Analytics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOXNm3og2g_J"
      },
      "source": [
        "We now contrast Madrid vs. Barcelona visually. To avoid comparing unlike-for-unlike, every view has two angles: absolute price and a normalized version (`price_per_person`, or later, price vs. neighborhood average). That keeps the focus on value creation, not just bigger floor plans.\n",
        "\n",
        "Outliers can dominate charts when 300k+ listings are involved, so each visualization trims the top 2.5–5 % for clarity. The goal isn’t to hide luxury units; it’s to prevent one erroneous €10k nightly rate from rescaling entire axes. We start with simple histograms to anchor the overall distribution before slicing by neighborhood, room type, and capacity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-JTwKqMH7lp"
      },
      "outputs": [],
      "source": [
        "# Price distribution analysis\n",
        "def plot_price_distribution(df, city, ax, color):\n",
        "    \"\"\"Helper function to plot price distribution for a city\"\"\"\n",
        "    city_data = df[df['City'] == city]\n",
        "    mean_price = city_data['price'].mean()\n",
        "\n",
        "    sns.histplot(data=city_data, x='price', bins=50, ax=ax,\n",
        "                 color=color, alpha=0.7, edgecolor='white', linewidth=0.5)\n",
        "\n",
        "    ax.axvline(mean_price, color='darkred' if city == 'Madrid' else 'darkblue',\n",
        "               linestyle='--', linewidth=2.5, label=f'Mean: €{mean_price:.2f}')\n",
        "\n",
        "    ax.set_title(f'Price Distribution in {city}', fontsize=14, fontweight='bold', pad=15)\n",
        "    ax.set_xlabel('Price (€)', fontsize=12)\n",
        "    ax.set_ylabel('Frequency', fontsize=12)\n",
        "    ax.legend(fontsize=10, frameon=True, shadow=True)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "# Create figure with two subplots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle('Airbnb Price Distribution Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "plot_price_distribution(listings_first_clean, 'Madrid', ax1, COLORS['madrid'])\n",
        "plot_price_distribution(listings_first_clean, 'Barcelona', ax2, COLORS['barcelona'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kla5zNnimhM-"
      },
      "outputs": [],
      "source": [
        "# Calculate price per person\n",
        "listings_first_clean['price_per_person'] = listings_first_clean['price'] / listings_first_clean['accommodates']\n",
        "\n",
        "# Price per person distribution\n",
        "def plot_price_per_person(df, city, ax, color):\n",
        "    \"\"\"Helper function to plot price per person distribution\"\"\"\n",
        "    city_data = df[df['City'] == city]\n",
        "    mean_ppp = city_data['price_per_person'].mean()\n",
        "\n",
        "    sns.histplot(data=city_data, x='price_per_person', bins=50, ax=ax,\n",
        "                 color=color, alpha=0.7, edgecolor='white', linewidth=0.5)\n",
        "\n",
        "    ax.axvline(mean_ppp, color='darkred' if city == 'Madrid' else 'darkblue',\n",
        "               linestyle='--', linewidth=2.5, label=f'Mean: €{mean_ppp:.2f}')\n",
        "\n",
        "    ax.set_title(f'Price per Person in {city}', fontsize=14, fontweight='bold', pad=15)\n",
        "    ax.set_xlabel('Price per Person (€)', fontsize=12)\n",
        "    ax.set_ylabel('Frequency', fontsize=12)\n",
        "    ax.legend(fontsize=10, frameon=True, shadow=True)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle('Price per Person Distribution', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "plot_price_per_person(listings_first_clean, 'Madrid', ax1, COLORS['madrid'])\n",
        "plot_price_per_person(listings_first_clean, 'Barcelona', ax2, COLORS['barcelona'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bvigsqs259HS"
      },
      "source": [
        "Both cities exhibit the typical right-skewed pattern: a dense cluster of budget listings with longer luxury tails. Barcelona sits ~24 € higher on the mean for price, and ~3 € higher on price-per-person, which persists after trimming extremes. This could indicate genuine pricing power rather than noise. With that baseline, we investigate where (neighborhoods) and how (room types, accommodates) that premium materializes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv_JcpLLKqKe"
      },
      "outputs": [],
      "source": [
        "# Calculate price per person if not already done\n",
        "if 'price_per_person' not in listings_first_clean.columns:\n",
        "    listings_first_clean['price_per_person'] = listings_first_clean['price'] / listings_first_clean['accommodates']\n",
        "\n",
        "# Aggregate neighborhood prices\n",
        "neighborhood_prices = listings_first_clean.groupby(['City', 'neighbourhood_cleansed'])['price_per_person'].agg(\n",
        "    ['mean', 'count']).reset_index()\n",
        "neighborhood_prices = neighborhood_prices[neighborhood_prices['count'] > 10]  # Filter low-count neighborhoods\n",
        "\n",
        "# Get top 10 neighborhoods per city\n",
        "madrid_top = neighborhood_prices[neighborhood_prices['City'] == 'Madrid'].nlargest(10, 'mean')\n",
        "barcelona_top = neighborhood_prices[neighborhood_prices['City'] == 'Barcelona'].nlargest(10, 'mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPP6PaeYmhM_"
      },
      "outputs": [],
      "source": [
        "# Visualize top neighborhoods\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 11))\n",
        "fig.suptitle('Top 10 Most Expensive Neighborhoods by Price per Person',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "# Madrid plot\n",
        "bars1 = ax1.barh(madrid_top['neighbourhood_cleansed'], madrid_top['mean'],\n",
        "                 color=COLORS['madrid'], alpha=0.8, edgecolor='white', linewidth=1.5)\n",
        "ax1.set_title('Madrid', fontsize=14, fontweight='bold', pad=10)\n",
        "ax1.set_xlabel('Average Price per Person (€)', fontsize=12)\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, value) in enumerate(zip(bars1, madrid_top['mean'])):\n",
        "    ax1.text(value + 1, bar.get_y() + bar.get_height()/2, f'€{value:.2f}',\n",
        "             va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Barcelona plot\n",
        "bars2 = ax2.barh(barcelona_top['neighbourhood_cleansed'], barcelona_top['mean'],\n",
        "                 color=COLORS['barcelona'], alpha=0.8, edgecolor='white', linewidth=1.5)\n",
        "ax2.set_title('Barcelona', fontsize=14, fontweight='bold', pad=10)\n",
        "ax2.set_xlabel('Average Price per Person (€)', fontsize=12)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, value) in enumerate(zip(bars2, barcelona_top['mean'])):\n",
        "    ax2.text(value + 1, bar.get_y() + bar.get_height()/2, f'€{value:.2f}',\n",
        "             va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNiLyPjqmhM_"
      },
      "outputs": [],
      "source": [
        "# Analyze by absolute price (not per person)\n",
        "price_cutoff_95 = listings_first_clean['price'].quantile(0.95)\n",
        "df_filtered = listings_first_clean[listings_first_clean['price'] < price_cutoff_95]\n",
        "\n",
        "neighborhood_absolute = df_filtered.groupby(['City', 'neighbourhood_cleansed'])['price'].agg(\n",
        "    ['mean', 'count']).reset_index()\n",
        "neighborhood_absolute = neighborhood_absolute[neighborhood_absolute['count'] > 10]\n",
        "\n",
        "madrid_top_abs = neighborhood_absolute[neighborhood_absolute['City'] == 'Madrid'].nlargest(10, 'mean')\n",
        "barcelona_top_abs = neighborhood_absolute[neighborhood_absolute['City'] == 'Barcelona'].nlargest(10, 'mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nBHZCwBmhM_"
      },
      "outputs": [],
      "source": [
        "# Visualize by absolute price\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 11))\n",
        "fig.suptitle('Top 10 Most Expensive Neighborhoods by Absolute Price',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "# Madrid plot\n",
        "bars1 = ax1.barh(madrid_top_abs['neighbourhood_cleansed'], madrid_top_abs['mean'],\n",
        "                 color=COLORS['madrid'], alpha=0.8, edgecolor='white', linewidth=1.5)\n",
        "ax1.set_title('Madrid', fontsize=14, fontweight='bold', pad=10)\n",
        "ax1.set_xlabel('Average Price (€)', fontsize=12)\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "for i, (bar, value) in enumerate(zip(bars1, madrid_top_abs['mean'])):\n",
        "    ax1.text(value + 2, bar.get_y() + bar.get_height()/2, f'€{value:.2f}',\n",
        "             va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "# Barcelona plot\n",
        "bars2 = ax2.barh(barcelona_top_abs['neighbourhood_cleansed'], barcelona_top_abs['mean'],\n",
        "                 color=COLORS['barcelona'], alpha=0.8, edgecolor='white', linewidth=1.5)\n",
        "ax2.set_title('Barcelona', fontsize=14, fontweight='bold', pad=10)\n",
        "ax2.set_xlabel('Average Price (€)', fontsize=12)\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "for i, (bar, value) in enumerate(zip(bars2, barcelona_top_abs['mean'])):\n",
        "    ax2.text(value + 2, bar.get_y() + bar.get_height()/2, f'€{value:.2f}',\n",
        "             va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBzls2ZK7oIH"
      },
      "source": [
        "No surprise: the top price-per-person neighborhoods cluster inside the urban core (Goya, Sol, Castellana...). Switching from absolute price to price-per-person reshuffles the order because some districts skew toward large multi-bedroom homes (higher absolute rates) while others specialize in compact premium studios. Remember the dataset covers the municipal limits of Madrid and Barcelona, not the full autonomous communities, so the comparisons stay apples-to-apples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzyU13obLYH5"
      },
      "outputs": [],
      "source": [
        "# Get room types with sufficient data\n",
        "property_counts = listings_first_clean.groupby('room_type').size()\n",
        "common_types = property_counts[property_counts >= 20].index\n",
        "plot_data = listings_first_clean[listings_first_clean['room_type'].isin(common_types)]\n",
        "\n",
        "# Create enhanced boxplot\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "# Use custom palette (fixed typo: removed space before Madrid)\n",
        "city_palette = {'Madrid': COLORS['madrid'], 'Barcelona': COLORS['barcelona']}\n",
        "box_plot = sns.boxplot(x='room_type', y='price', hue='City', data=plot_data,\n",
        "                       palette=city_palette, ax=ax, linewidth=2)\n",
        "\n",
        "# Enhance visual appearance\n",
        "for patch in ax.patches:\n",
        "    patch.set_alpha(0.7)\n",
        "\n",
        "ax.set_title('Price Distribution by Room Type and City',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Room Type', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Price (€)', fontsize=13, fontweight='bold')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax.legend(title='City', fontsize=11, title_fontsize=12, frameon=True, shadow=True)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwsRRhYl_dPf"
      },
      "source": [
        "Boxplots by room type confirm the intuition: hotel rooms command the richest rates once we control for size, followed by entire homes, then private rooms and shared rooms (just as one would expect).\n",
        "\n",
        "Entire homes show the widest spread (they range from studios to multi-level villas), whereas shared rooms sit in the tightest band. Across every category Barcelona’s median is higher, suggesting investors rely on either more differentiated product or stronger demand to justify the uplift."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTr_qT-JJolZ"
      },
      "outputs": [],
      "source": [
        "def analyze_price_by_accommodates(df):\n",
        "\n",
        "\n",
        "    # Filter for common accommodates sizes\n",
        "    common_sizes = df['accommodates'].value_counts() > 20\n",
        "    common_sizes = common_sizes[common_sizes].index\n",
        "    plot_data = df[df['accommodates'].isin(common_sizes)]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create violin plot\n",
        "    sns.violinplot(x='accommodates', y='price', hue='City', data=plot_data,\n",
        "                  palette={'Madrid': 'blue', 'Barcelona': 'red'}, alpha=0.6)\n",
        "\n",
        "    plt.title('Price Distribution by Number of Accommodates')\n",
        "    plt.xlabel('Number of People Accommodated')\n",
        "    plt.ylabel('Price (€)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "analyze_price_by_accommodates(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5AZRP4ShZGX"
      },
      "source": [
        "Violin plots by guest capacity show a clear pattern: prices increase as properties accommodate more people, but the price range widens dramatically for larger properties. Smaller units (1 to 4 guests) have tight, consistent price distributions. Larger properties show much more variation, splitting between standard family homes and luxury properties. Barcelona consistently prices higher than Madrid across nearly all capacity levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iku_Leg7MQDH"
      },
      "outputs": [],
      "source": [
        "def analyze_price_by_total_rooms(df):\n",
        "    # Create a copy of the dataframe\n",
        "    df = df.copy()\n",
        "\n",
        "\n",
        "    # Create total rooms - ensure we're working with numeric values\n",
        "    df['total_rooms'] = df['bedrooms'].fillna(1) + df['bathrooms'].fillna(0)\n",
        "    df['total_rooms'] = df['total_rooms'].astype(int)\n",
        "\n",
        "    # Filter for common room counts (at least 20 listings)\n",
        "    room_counts = df['total_rooms'].value_counts()\n",
        "    common_rooms = room_counts[room_counts >= 20].index\n",
        "    plot_data = df[df['total_rooms'].isin(common_rooms)]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Create box plot without alpha in palette\n",
        "    sns.boxplot(x='total_rooms', y='price', hue='City', data=plot_data,\n",
        "                palette={'Madrid': 'blue', 'Barcelona': 'red'})\n",
        "\n",
        "    # Set alpha manually for patches\n",
        "    for patch in plt.gca().patches:\n",
        "        patch.set_alpha(0.6)\n",
        "\n",
        "    plt.title('Price Distribution by Total Number of Rooms')\n",
        "    plt.xlabel('Total Rooms (Bedrooms + Bathrooms)')\n",
        "    plt.ylabel('Price (€)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the analysis\n",
        "analyze_price_by_total_rooms(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPHet-DRvEwl"
      },
      "source": [
        "Room-count distributions mirror the accommodates story: more rooms correlate with higher prices, yet the dispersion widens drastically at the top end. Madrid briefly overtakes Barcelona for some of the largest homes, but those segments are sparsely populated and often trimmed by our 99th-percentile rule, so we avoid over-interpreting them. The more useful insight is how price-per-person behaves as we scale capacity, which we explore next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I-K2wyiNujA"
      },
      "outputs": [],
      "source": [
        "def analyze_price_efficiency(df):\n",
        "    # Create a copy of the dataframe\n",
        "    df = df.copy()\n",
        "\n",
        "\n",
        "    df['price_per_person'] = df['price'] / df['accommodates']\n",
        "\n",
        "    # Remove extreme price_per_person values\n",
        "    df = df[df['price_per_person'] < df['price_per_person'].quantile(0.95)]\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Calculate mean price per person for each number of accommodates\n",
        "    mean_prices = df.groupby(['City', 'accommodates'])['price_per_person'].mean().reset_index()\n",
        "\n",
        "    # Plot lines for each city\n",
        "    for city, color in zip(['Madrid', 'Barcelona'], ['blue', 'red']):\n",
        "        city_data = mean_prices[mean_prices['City'] == city]\n",
        "\n",
        "        # Add main line\n",
        "        plt.plot(city_data['accommodates'], city_data['price_per_person'],\n",
        "                color=color, linewidth=2, label=city)\n",
        "\n",
        "        # Add confidence interval\n",
        "        city_raw = df[df['City'] == city]\n",
        "        for accom in city_data['accommodates']:\n",
        "            prices = city_raw[city_raw['accommodates'] == accom]['price_per_person']\n",
        "            plt.fill_between([accom],\n",
        "                           [prices.quantile(0.25)],\n",
        "                           [prices.quantile(0.75)],\n",
        "                           color=color, alpha=0.1)\n",
        "\n",
        "    plt.title('Average Price per Person by Accommodation Capacity')\n",
        "    plt.xlabel('Number of People Accommodated')\n",
        "    plt.ylabel('Price per Person (€)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the analysis\n",
        "analyze_price_efficiency(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oqLrKZ3m6s"
      },
      "source": [
        "Average price per person declines as guest capacity increases, showing classic economies of scale. However, there are notable peaks where efficiency is highest. Barcelona peaks around 12 guests at roughly 52 euros per person, while Madrid shows smaller peaks around 2 and 13 guests at around 44 and 43 euros per person respectively. For investors, properties at these capacity levels can deliver strong yield per guest. Barcelona consistently charges more per person than Madrid across nearly all capacity levels, maintaining a premium of roughly 5 to 10 euros per person throughout most of the range."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnFcFC97JH6Q"
      },
      "source": [
        "## **Step 3: Statistical Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oMHB0TI4QV_"
      },
      "source": [
        "We stress-test the descriptive patterns statistically. Because price distributions are non-normal, we first confirm that with D’Agostino tests and then rely on the Mann–Whitney U test to evaluate whether Barcelona’s prices are significantly higher overall and within each room type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp3SYsWiJF5J"
      },
      "outputs": [],
      "source": [
        "import scipy.stats as stats\n",
        "import numpy as np\n",
        "\n",
        "def compare_city_prices(df):\n",
        "    # Separate prices by city\n",
        "    barcelona_prices = df[df['City'] == 'Barcelona']['price']\n",
        "    madrid_prices = df[df['City'] == 'Madrid']['price']\n",
        "\n",
        "    # Basic descriptive statistics\n",
        "    print(\"Descriptive Statistics:\")\n",
        "    print(\"\\nBarcelona:\")\n",
        "    print(f\"Mean Price: €{barcelona_prices.mean():.2f}\")\n",
        "    print(f\"Median Price: €{barcelona_prices.median():.2f}\")\n",
        "    print(f\"Std Dev: €{barcelona_prices.std():.2f}\")\n",
        "\n",
        "    print(\"\\nMadrid:\")\n",
        "    print(f\"Mean Price: ${madrid_prices.mean():.2f}\")\n",
        "    print(f\"Median Price: ${madrid_prices.median():.2f}\")\n",
        "    print(f\"Std Dev: ${madrid_prices.std():.2f}\")\n",
        "\n",
        "    # Test for normality\n",
        "    _, barcelona_norm_p = stats.normaltest(barcelona_prices)\n",
        "    _, madrid_norm_p = stats.normaltest(madrid_prices)\n",
        "\n",
        "    print(\"\\nNormality Test p-values:\")\n",
        "    print(f\"Barcelona: {barcelona_norm_p:.4f}\")\n",
        "    print(f\"Madrid: {madrid_norm_p:.4f}\")\n",
        "\n",
        "    # Since test for normality was negative\n",
        "    # we'll use Mann-Whitney U test (non-parametric)\n",
        "    statistic, p_value = stats.mannwhitneyu(\n",
        "        barcelona_prices,\n",
        "        madrid_prices,\n",
        "        alternative='greater'  # Testing if Barcelona prices are higher\n",
        "    )\n",
        "\n",
        "    print(\"\\nMann-Whitney U Test Results:\")\n",
        "    print(f\"Statistic: {statistic}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "    return statistic, p_value\n",
        "\n",
        "# Run the analysis\n",
        "statistic, p_value = compare_city_prices(listings_first_clean)\n",
        "\n",
        "\n",
        "# Additional analysis by property type\n",
        "def compare_prices_by_property_type(df):\n",
        "    property_types = df['room_type'].value_counts().head(5).index\n",
        "\n",
        "    print(\"\\nPrice Comparison by Top Property Types:\")\n",
        "    for prop_type in property_types:\n",
        "        barcelona_prices = df[(df['City'] == 'Barcelona') &\n",
        "                            (df['room_type'] == prop_type)]['price']\n",
        "        madrid_prices = df[(df['City'] == 'Madrid') &\n",
        "                          (df['room_type'] == prop_type)]['price']\n",
        "\n",
        "        if len(barcelona_prices) > 0 and len(madrid_prices) > 0:\n",
        "            _, p_value = stats.mannwhitneyu(\n",
        "                barcelona_prices,\n",
        "                madrid_prices,\n",
        "                alternative='greater'\n",
        "            )\n",
        "\n",
        "            print(f\"\\n{prop_type}:\")\n",
        "            print(f\"Barcelona Mean: €{barcelona_prices.mean():.2f}\")\n",
        "            print(f\"Madrid Mean: €{madrid_prices.mean():.2f}\")\n",
        "            print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "# Run property type analysis\n",
        "compare_prices_by_property_type(listings_first_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33XTYSGcAs2L"
      },
      "source": [
        "Results are clear: p-values are well below 0.01 both overall and across every room type, so we can confidently conclude that Barcelona commands a true price premium over Madrid.\n",
        "\n",
        "Barcelona averages €158 per night versus Madrid's €134, a difference of roughly €24 or 18%. This premium holds consistently across all property types, from entire homes (Barcelona €192 versus Madrid €158) to shared rooms (Barcelona €76 versus Madrid €46).\n",
        "\n",
        "Later sections explore why this premium exists by examining supply factors like property characteristics and amenities, along with demand indicators like reviews and occupancy patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TntsUPF2WGas"
      },
      "source": [
        "## **Step 4: Prescriptive Analytics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8t2ZOpxBXEc"
      },
      "source": [
        "To turn our findings into practical recommendations, we build two prediction models using Random Forest: one predicts the total nightly price, and the other predicts price per person. While correlation analysis shows us basic relationships (like bigger properties cost more, but charge less per guest), the Random Forest models tell us which factors matter most for setting competitive prices.\n",
        "\n",
        "We chose Random Forest because it works well with different types of data (numbers, categories, etc.) and clearly shows which factors have the biggest impact on pricing, which is more useful for investment decisions than just having an accurate prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6WZi8Q7lXdl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import ast\n",
        "\n",
        "def analyze_price_correlations(df):\n",
        "    # Prepare numerical features\n",
        "    numerical_features = [\n",
        "        'accommodates',\n",
        "        'bathrooms',\n",
        "        'bedrooms',\n",
        "        'beds',\n",
        "        'number_of_reviews',\n",
        "        'review_scores_rating',\n",
        "        'review_scores_cleanliness',\n",
        "        'review_scores_location',\n",
        "        'minimum_nights',\n",
        "        'maximum_nights',\n",
        "        'availability_365',\n",
        "        'host_listings_count',\n",
        "        'price',\n",
        "        'price_per_person'\n",
        "    ]\n",
        "\n",
        "    # Prepare categorical features\n",
        "    categorical_features = [\n",
        "        'room_type',\n",
        "        'property_type',\n",
        "        'neighbourhood_cleansed',\n",
        "        'instant_bookable',\n",
        "        'host_is_superhost'\n",
        "    ]\n",
        "\n",
        "    # Create a copy of numerical features\n",
        "    corr_df = df[numerical_features].copy()\n",
        "\n",
        "    # Encode and add categorical features\n",
        "    le = LabelEncoder()\n",
        "    for cat_col in categorical_features:\n",
        "        corr_df[cat_col] = le.fit_transform(df[cat_col].astype(str))\n",
        "\n",
        "    # Calculate correlation matrix\n",
        "    correlation_matrix = corr_df.corr()\n",
        "\n",
        "    # Get correlations with price and price_per_person\n",
        "    price_correlations = correlation_matrix['price'].sort_values(ascending=False)\n",
        "    price_per_person_correlations = correlation_matrix['price_per_person'].sort_values(ascending=False)\n",
        "\n",
        "    return price_correlations, price_per_person_correlations\n",
        "\n",
        "# Analyze each city separately\n",
        "for city in ['Madrid', 'Barcelona']:\n",
        "    city_data = listings_first_clean[listings_first_clean['City'] == city]\n",
        "    price_corr, price_per_person_corr = analyze_price_correlations(city_data)\n",
        "\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"\\nCorrelations for {city}:\")\n",
        "    print(f\"\\nCorrelations with Price (sorted):\")\n",
        "    print(price_corr)\n",
        "    print(f\"\\nCorrelations with Price Per Person (sorted):\")\n",
        "    print(price_per_person_corr)\n",
        "    print(f\"\\n{'='*50}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtuO3VwtCfSw"
      },
      "source": [
        "**Price model:** Size-related variables like guest capacity, beds, and bathrooms have the strongest correlations with price. This makes sense but doesn't tell us much beyond \"bigger properties cost more.\" That's why we also build a price-per-person model to identify what drives value beyond just size.\n",
        "\n",
        "**Price-per-person model:** Capacity variables flip their relationship here. More guests means lower price per person, which is expected (economies of scale). Beyond that, the correlations are much weaker, meaning we need more sophisticated analysis to find what truly matters.\n",
        "\n",
        "**Key differences between cities:**\n",
        "- Barcelona shows stronger correlations between reviews and price (0.20 for review count, 0.15 for ratings) compared to Madrid (essentially 0)\n",
        "- Barcelona guests seem willing to pay more for well-reviewed properties, while Madrid pricing is driven almost entirely by size\n",
        "- Both cities show similar negative correlations with room type and property type, confirming entire homes cost more than private or shared rooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7Bys5bCWin7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import ast\n",
        "\n",
        "def prepare_data_for_modeling(df):\n",
        "    # Select key numerical columns\n",
        "    numerical_features = [\n",
        "        'accommodates',\n",
        "        'bathrooms',\n",
        "        'bedrooms',\n",
        "        'beds',\n",
        "        'number_of_reviews',\n",
        "        'review_scores_rating',\n",
        "        'review_scores_cleanliness',\n",
        "        'review_scores_location',\n",
        "        'minimum_nights',\n",
        "        'maximum_nights',\n",
        "        'availability_365',\n",
        "        'host_listings_count'\n",
        "    ]\n",
        "\n",
        "    # Select key categorical columns\n",
        "    categorical_features = [\n",
        "        'room_type',\n",
        "        'property_type',\n",
        "        'neighbourhood_cleansed',\n",
        "        'instant_bookable',\n",
        "        'host_is_superhost'\n",
        "    ]\n",
        "\n",
        "    # Create a copy of the dataframe with selected features\n",
        "    X = df[numerical_features + categorical_features].copy()\n",
        "    y = df['price']\n",
        "\n",
        "    # Handle categorical variables\n",
        "    label_encoders = {}\n",
        "    for cat_col in categorical_features:\n",
        "        label_encoders[cat_col] = LabelEncoder()\n",
        "        X[cat_col] = label_encoders[cat_col].fit_transform(X[cat_col].astype(str))\n",
        "\n",
        "    # Process amenities more safely\n",
        "    def parse_amenities(amenities_str):\n",
        "        try:\n",
        "            if pd.isna(amenities_str):\n",
        "                return set()\n",
        "            # Remove brackets and split by comma\n",
        "            cleaned = amenities_str.strip('[]{}').replace('\"', '').replace(\"'\", \"\")\n",
        "            return {item.strip() for item in cleaned.split(',') if item.strip()}\n",
        "        except:\n",
        "            return set()\n",
        "\n",
        "    # Convert amenities to sets\n",
        "    amenities = df['amenities'].apply(parse_amenities)\n",
        "\n",
        "    # Get most common amenities (top 20)\n",
        "    all_amenities = set()\n",
        "    for amenity_set in amenities:\n",
        "        all_amenities.update(amenity_set)\n",
        "\n",
        "    amenity_counts = pd.Series([\n",
        "        sum(1 for amenity_set in amenities if amenity in amenity_set)\n",
        "        for amenity in all_amenities\n",
        "    ], index=all_amenities).sort_values(ascending=False)\n",
        "\n",
        "    top_amenities = amenity_counts.head(20).index\n",
        "\n",
        "    # Create binary columns for top amenities\n",
        "    for amenity in top_amenities:\n",
        "        X[f'has_{amenity.lower().replace(\" \", \"_\")}'] = amenities.apply(\n",
        "            lambda x: 1 if amenity in x else 0\n",
        "        )\n",
        "\n",
        "    return X, y, label_encoders\n",
        "\n",
        "# The rest of the code remains the same\n",
        "def train_and_analyze_random_forest(X, y):\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train Random Forest model\n",
        "    rf_model = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=15,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Get feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': rf_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    return rf_model, feature_importance, mse, r2\n",
        "\n",
        "# Run the analysis\n",
        "X, y, label_encoders = prepare_data_for_modeling(listings_first_clean)\n",
        "model, feature_importance, mse, r2 = train_and_analyze_random_forest(X, y)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "print(\"\\nTop 20 Most Important Features:\")\n",
        "print(feature_importance.head(20))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(\n",
        "    x='importance',\n",
        "    y='feature',\n",
        "    data=feature_importance.head(20)\n",
        ")\n",
        "plt.title('Top 20 Most Important Features for Price Prediction')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRIdSWUfEHA8"
      },
      "source": [
        "**Key takeaways from the price model:**\n",
        "\n",
        "Guest capacity is by far the most important factor, explaining 37% of price variation. This dwarfs everything else. Bathrooms come in second at 7%, significantly outranking bedrooms (3.6%). This suggests bathrooms signal premium quality more than just bedroom count.\n",
        "\n",
        "Availability throughout the year matters more than you'd expect (6%), ranking third overall. Properties with high availability tend to charge more, likely because professional hosts keep their calendars open and price confidently.\n",
        "\n",
        "Neighborhood is the fifth most important factor (5.6%), confirming location drives pricing. This effect shows up twice: directly through which neighborhood you're in, and indirectly through location review scores (3.1%).\n",
        "\n",
        "Property type and room type together account for about 6% of importance. The gap between hotel rooms, entire homes, and shared spaces creates significant price variation.\n",
        "\n",
        "Review metrics collectively matter (7% combined across rating, cleanliness, and location scores). Strong review profiles give hosts pricing power.\n",
        "\n",
        "Specific amenities start appearing in the top 20, with elevators (0.9%), shampoo (0.6%), and dedicated workspaces (0.5%) making the cut. These premium touches add value beyond basic size metrics.\n",
        "\n",
        "Now we examine price per person to see what drives efficiency and value beyond just property size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lpU1qpb8ZMQA"
      },
      "outputs": [],
      "source": [
        "def prepare_data_for_modeling_price_per_person(df):\n",
        "    # Calculate price per person\n",
        "    df = df.copy()\n",
        "    df['price_per_person'] = df['price'] / df['accommodates']\n",
        "\n",
        "    # Select key numerical columns\n",
        "    numerical_features = [\n",
        "        'accommodates',\n",
        "        'bathrooms',\n",
        "        'bedrooms',\n",
        "        'beds',\n",
        "        'number_of_reviews',\n",
        "        'review_scores_rating',\n",
        "        'review_scores_cleanliness',\n",
        "        'review_scores_location',\n",
        "        'minimum_nights',\n",
        "        'maximum_nights',\n",
        "        'availability_365',\n",
        "        'host_listings_count'\n",
        "    ]\n",
        "\n",
        "    # Select key categorical columns\n",
        "    categorical_features = [\n",
        "        'room_type',\n",
        "        'property_type',\n",
        "        'neighbourhood_cleansed',\n",
        "        'instant_bookable',\n",
        "        'host_is_superhost'\n",
        "    ]\n",
        "\n",
        "    # Create a copy of the dataframe with selected features\n",
        "    X = df[numerical_features + categorical_features].copy()\n",
        "    y = df['price_per_person']\n",
        "\n",
        "    # Handle categorical variables\n",
        "    label_encoders = {}\n",
        "    for cat_col in categorical_features:\n",
        "        label_encoders[cat_col] = LabelEncoder()\n",
        "        X[cat_col] = label_encoders[cat_col].fit_transform(X[cat_col].astype(str))\n",
        "\n",
        "    # Process amenities\n",
        "    def parse_amenities(amenities_str):\n",
        "        try:\n",
        "            if pd.isna(amenities_str):\n",
        "                return set()\n",
        "            cleaned = amenities_str.strip('[]{}').replace('\"', '').replace(\"'\", \"\")\n",
        "            return {item.strip() for item in cleaned.split(',') if item.strip()}\n",
        "        except:\n",
        "            return set()\n",
        "\n",
        "    # Convert amenities to sets\n",
        "    amenities = df['amenities'].apply(parse_amenities)\n",
        "\n",
        "    # Get most common amenities (top 20)\n",
        "    all_amenities = set()\n",
        "    for amenity_set in amenities:\n",
        "        all_amenities.update(amenity_set)\n",
        "\n",
        "    amenity_counts = pd.Series([\n",
        "        sum(1 for amenity_set in amenities if amenity in amenity_set)\n",
        "        for amenity in all_amenities\n",
        "    ], index=all_amenities).sort_values(ascending=False)\n",
        "\n",
        "    top_amenities = amenity_counts.head(20).index\n",
        "\n",
        "    # Create binary columns for top amenities\n",
        "    for amenity in top_amenities:\n",
        "        X[f'has_{amenity.lower().replace(\" \", \"_\")}'] = amenities.apply(\n",
        "            lambda x: 1 if amenity in x else 0\n",
        "        )\n",
        "\n",
        "    return X, y, label_encoders\n",
        "\n",
        "def train_and_analyze_random_forest_price_per_person(X, y):\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Train Random Forest model\n",
        "    rf_model = RandomForestRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=15,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = rf_model.predict(X_test)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    # Get feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': rf_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "\n",
        "    return rf_model, feature_importance, mse, r2\n",
        "\n",
        "# Run the analysis\n",
        "print(\"Random Forest Model for Price Per Person\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "X, y, label_encoders = prepare_data_for_modeling_price_per_person(listings_first_clean)\n",
        "model, feature_importance, mse, r2 = train_and_analyze_random_forest_price_per_person(X, y)\n",
        "\n",
        "# Print results\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "print(f\"R-squared Score: {r2:.4f}\")\n",
        "\n",
        "print(\"\\nTop 20 Most Important Features:\")\n",
        "print(feature_importance.head(20))\n",
        "\n",
        "# Visualize feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(\n",
        "    x='importance',\n",
        "    y='feature',\n",
        "    data=feature_importance.head(20)\n",
        ")\n",
        "plt.title('Top 20 Most Important Features for Price Per Person Prediction')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60tdv8Lkv5m2"
      },
      "source": [
        "**Price per person model results:**\n",
        "\n",
        "Predicting price per person is much harder than predicting total price (R-squared of 0.35 versus likely higher for the price model). This makes sense because we've intentionally removed the biggest predictor: property size.\n",
        "\n",
        "**What matters for price per person:**\n",
        "\n",
        "Availability is now the top factor (13.5%), flipping the script from the total price model. Properties with high year-round availability charge more per person, suggesting professional management and confident pricing strategies.\n",
        "\n",
        "Minimum nights requirement jumps to second place (10.2%). Hosts who require longer stays can charge higher per-person rates, likely because they attract different guest segments (relocations, extended stays) willing to pay premiums.\n",
        "\n",
        "Property type becomes much more important (9.5%), now ranking third. Hotel rooms and specialty properties can sustain higher per-person rates than standard apartments, even when controlling for size.\n",
        "\n",
        "Neighborhood moves up to fourth (8.8%), showing location matters even more when size is normalized. Prime areas command per-person premiums regardless of property size.\n",
        "\n",
        "Guest capacity drops dramatically to fifth place (8.1%), down from 37% in the total price model. This confirms our strategy worked: we've removed size as the dominant factor.\n",
        "\n",
        "Review metrics collectively contribute about 9%, similar to the total price model. Quality still matters for per-person pricing.\n",
        "\n",
        "**Our main takeaway:**\n",
        "\n",
        "After accounting for size, the factors that drive per-person pricing are much weaker and more evenly distributed. No single factor dominates. This means hosts need to differentiate through multiple dimensions: strategic availability management, smart minimum night policies, premium locations, strong reviews, and the right mix of amenities. The subsequent sections explore these qualitative differentiators in detail through supply analysis, amenity packages, and guest sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcmmzChuxsFD"
      },
      "source": [
        "## **Section 1 Main Conclusions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Omc94HipGD34"
      },
      "source": [
        "1. **Barcelona commands a real pricing premium.** It outprices Madrid by roughly 18% overall (€158 vs €134 per night), and this gap holds across every property type.\n",
        "\n",
        "2. **Size drives pricing, but bathrooms matter more than you'd think.** Guest capacity explains 37% of price variation, making it the dominant factor. But bathrooms (7% importance) outrank bedrooms (3.6%), suggesting that bathroom quality and layout signal premium properties more than just bedroom count.\n",
        "\n",
        "3. **Room type and property type create distinct pricing tiers.** Hotel rooms command the highest rates, followed by entire homes, then private rooms, and finally shared rooms. This hierarchy holds in both cities, though Barcelona maintains its premium across all categories.\n",
        "\n",
        "4. **Price per person peaks at specific capacities.** Barcelona maximizes efficiency around 12 guests (€52 per person), while Madrid peaks at 2 and 13 guests (€43-44 per person). Properties at these sweet spots deliver the strongest per-guest yield before economies of scale flatten pricing.\n",
        "\n",
        "5. **Location matters more when you normalize for size.** Central neighborhoods dominate absolute pricing, but rankings shift when measuring price per person because some districts specialize in large homes while others focus on compact premium units. Location review scores amplify these premiums.\n",
        "\n",
        "6. **Professional hosting drives pricing power.** High year-round availability (13.5% importance for price per person), strategic minimum night requirements (10.2%), and strong review profiles (9% combined) separate premium hosts from average ones. These factors matter most once property size is controlled for.\n",
        "\n",
        "7. **Barcelona guests value quality differently than Madrid guests.** Barcelona shows strong correlations between reviews and price (0.20 for review count, 0.15 for ratings), while Madrid pricing is driven almost entirely by size. This suggests Barcelona investors must compete on experience and amenities, not just square footage.\n",
        "\n",
        "8. **Data limitations shape our conclusions.** We can't observe actual occupancy rates or property square meters, so we use unavailable dates as a rough demand proxy and rely on guest capacity as a size estimate. All conclusions focus on pricing patterns we can measure: rates, host behavior, reviews, and amenities.\n",
        "\n",
        "\n",
        "\n",
        "**Price alone doesn't determine success.** The combination of location + configuration + guest experience drives value. Both markets are mature and efficient. Competitive advantage must come from superior execution, not format arbitrage.\n",
        "\n",
        "\n",
        "\n",
        "These findings set up the rest of the analysis. The next sections dig into why certain properties command premium prices by examining supply composition (Section 2), neighborhood dynamics (Section 3), host professionalism (Section 4), and the role of reviews and amenities (Section 5)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2QNRl05_iBT"
      },
      "source": [
        "# **Section 2: Property Type Distribution & Performance**\n",
        "\n",
        "Goal: connect supply mix (room types, amenities, success proxies) with the pricing and demand signals we surfaced above.\n",
        "\n",
        "Section  1 aims to show *what* is happening, and this section explains *who* is driving it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFdh6ZJAlT7w"
      },
      "source": [
        "## **Step 1: Pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSxed1DrZH6z"
      },
      "source": [
        "We reuse the cleaned `combined_listings` output from Section 1 so every metric here reflects the same pricing, review, and availability treatments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLdK4v9Uor9e"
      },
      "outputs": [],
      "source": [
        "# Display the first 4 rows of the combined_listings DataFrame\n",
        "combined_listings.head(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2HA3PNnAcoA"
      },
      "source": [
        "## **Step 2: Insights & Conclusions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnUwr9jJVEni"
      },
      "source": [
        "### **Step 2.1: Supply Mix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irxJ6tTIn_T6"
      },
      "outputs": [],
      "source": [
        "# Calculate room type percentages\n",
        "room_type_counts_barcelona = barcelona_listings['room_type'].value_counts(normalize=True) * 100\n",
        "room_type_counts_madrid = madrid_listings['room_type'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Create DataFrame for visualization\n",
        "room_type_distribution = pd.DataFrame({\n",
        "    'City': ['Barcelona'] * len(room_type_counts_barcelona) + ['Madrid'] * len(room_type_counts_madrid),\n",
        "    'Room Type': list(room_type_counts_barcelona.index) + list(room_type_counts_madrid.index),\n",
        "    'Percentage': list(room_type_counts_barcelona.values) + list(room_type_counts_madrid.values)\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JHdc7NxmhNE"
      },
      "outputs": [],
      "source": [
        "# Create enhanced visualization\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "city_colors = {'Barcelona': COLORS['barcelona'], 'Madrid': COLORS['madrid']}\n",
        "bar_plot = sns.barplot(data=room_type_distribution, x='Room Type', y='Percentage',\n",
        "                       hue='City', palette=city_colors, ax=ax, alpha=0.85, edgecolor='white', linewidth=2)\n",
        "\n",
        "# Add percentage labels on bars\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.1f%%', padding=3, fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.set_title('Room Type Distribution: Barcelona vs Madrid',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('Percentage (%)', fontsize=13, fontweight='bold')\n",
        "ax.set_xlabel('Room Type', fontsize=13, fontweight='bold')\n",
        "ax.tick_params(axis='x', rotation=45)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax.legend(title='City', fontsize=11, title_fontsize=12, frameon=True, shadow=True)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LznZHRFJx0oA"
      },
      "source": [
        "Entire homes/apartments and private rooms make up ~98 % of inventory in both cities, but Madrid leans more heavily into entire homes (~72 %) while Barcelona keeps a healthier mix (≈68 % entire, 30 % private). Shared rooms and hotel rooms barely register.\n",
        "\n",
        "For investors, that means Barcelona offers slightly more budget-friendly private-room stock, whereas Madrid skews a bit toward full-unit operations—which can influence everything from cleaning logistics to licensing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5NIVCDnXdn5"
      },
      "outputs": [],
      "source": [
        "# Calculate average ratings by room type and city\n",
        "# IMPORTANT: Only include properties with actual reviews (review_scores_rating > 0)\n",
        "# Properties with 0 rating have no reviews and shouldn't affect averages\n",
        "listings_with_reviews = combined_listings[combined_listings['review_scores_rating'] > 0]\n",
        "success_data = listings_with_reviews.groupby(['room_type', 'City'])['review_scores_rating'].mean().unstack()\n",
        "\n",
        "# Print the data\n",
        "print(\"Average Guest Ratings by Room Type and City (excluding properties with no reviews):\")\n",
        "print(success_data)\n",
        "print(\"\\nDetailed breakdown:\")\n",
        "for room_type in success_data.index:\n",
        "    for city in success_data.columns:\n",
        "        rating = success_data.loc[room_type, city]\n",
        "        print(f\"  {room_type} in {city}: {rating:.2f}\")\n",
        "print(f\"\\nNote: Analysis includes {len(listings_with_reviews):,} properties with reviews out of {len(combined_listings):,} total listings\")\n",
        "\n",
        "# Create enhanced heatmap\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "\n",
        "sns.heatmap(success_data, annot=True, fmt=\".2f\", cmap='RdYlGn',\n",
        "            center=4.5, vmin=4.0, vmax=5.0,\n",
        "            cbar_kws={'label': 'Average Rating', 'shrink': 0.8},\n",
        "            linewidths=2, linecolor='white',\n",
        "            annot_kws={'size': 12, 'weight': 'bold'}, ax=ax)\n",
        "\n",
        "ax.set_title('Average Guest Ratings by Room Type and City',\n",
        "             fontsize=15, fontweight='bold', pad=20)\n",
        "ax.set_ylabel('Room Type', fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('City', fontsize=12, fontweight='bold')\n",
        "ax.tick_params(axis='both', labelsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0WEHsaQThon"
      },
      "source": [
        "Average ratings look nearly identical across room types, so we drill into distribution spread with boxplots. The story might be in the variance (do shared rooms swing wider?) rather than the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enjMJNTwT_li"
      },
      "outputs": [],
      "source": [
        "# Prepare data for boxplot (excluding properties with no reviews)\n",
        "barcelona_filtered = barcelona_listings[barcelona_listings['review_scores_rating'] > 0][['id', 'room_type', 'bedrooms', 'bathrooms', 'review_scores_rating', 'last_scraped']].copy()\n",
        "madrid_filtered = madrid_listings[madrid_listings['review_scores_rating'] > 0][['id', 'room_type', 'bedrooms', 'bathrooms', 'review_scores_rating', 'last_scraped']].copy()\n",
        "\n",
        "barcelona_filtered['City'] = 'Barcelona'\n",
        "madrid_filtered['City'] = 'Madrid'\n",
        "\n",
        "combined_data = pd.concat([barcelona_filtered, madrid_filtered])\n",
        "filtered_data = combined_data.dropna(subset=['review_scores_rating'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p264kDJmhNF"
      },
      "outputs": [],
      "source": [
        "# Create enhanced boxplot for rating variability\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "city_palette = {'Barcelona': COLORS['barcelona'], 'Madrid': COLORS['madrid']}\n",
        "box_plot = sns.boxplot(data=filtered_data, x='room_type', y='review_scores_rating',\n",
        "                       hue='City', palette=city_palette, ax=ax, linewidth=2)\n",
        "\n",
        "# Enhance visual appearance\n",
        "for patch in ax.patches:\n",
        "    patch.set_alpha(0.75)\n",
        "\n",
        "ax.set_title('Rating Variability by Room Type: Barcelona vs Madrid',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Room Type', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Review Score Rating', fontsize=13, fontweight='bold')\n",
        "ax.set_ylim(0, 5.2)\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax.legend(title='City', fontsize=11, title_fontsize=12, frameon=True, shadow=True)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vly_9-RLmhNG"
      },
      "outputs": [],
      "source": [
        "# Let's check the data distribution for each room type\n",
        "print(\"Data counts by room type and city:\")\n",
        "print(filtered_data.groupby(['room_type', 'City']).size())\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Check basic statistics for each room type\n",
        "for room_type in filtered_data['room_type'].unique():\n",
        "    print(f\"\\n{room_type}:\")\n",
        "    room_data = filtered_data[filtered_data['room_type'] == room_type]\n",
        "    print(f\"  Total count: {len(room_data)}\")\n",
        "    print(f\"  Rating range: {room_data['review_scores_rating'].min():.2f} - {room_data['review_scores_rating'].max():.2f}\")\n",
        "    print(f\"  Mean rating: {room_data['review_scores_rating'].mean():.2f}\")\n",
        "    print(f\"  Std deviation: {room_data['review_scores_rating'].std():.2f}\")\n",
        "\n",
        "    # Check for outliers by city\n",
        "    for city in ['Barcelona', 'Madrid']:\n",
        "        city_room_data = room_data[room_data['City'] == city]\n",
        "        if len(city_room_data) > 0:\n",
        "            q1 = city_room_data['review_scores_rating'].quantile(0.25)\n",
        "            q3 = city_room_data['review_scores_rating'].quantile(0.75)\n",
        "            iqr = q3 - q1\n",
        "            lower_bound = q1 - 1.5 * iqr\n",
        "            upper_bound = q3 + 1.5 * iqr\n",
        "            outliers = city_room_data[(city_room_data['review_scores_rating'] < lower_bound) |\n",
        "                                      (city_room_data['review_scores_rating'] > upper_bound)]\n",
        "            print(f\"  {city}: {len(city_room_data)} properties, {len(outliers)} outliers\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52W5Y0gFmhNG"
      },
      "outputs": [],
      "source": [
        "# Let's look at the actual low ratings in hotel rooms and shared rooms\n",
        "print(\"Hotel rooms with ratings below 4.0:\")\n",
        "hotel_low = filtered_data[(filtered_data['room_type'] == 'Hotel room') &\n",
        "                           (filtered_data['review_scores_rating'] < 4.0)]\n",
        "print(f\"Count: {len(hotel_low)}\")\n",
        "for city in ['Barcelona', 'Madrid']:\n",
        "    city_data = hotel_low[hotel_low['City'] == city]\n",
        "    if len(city_data) > 0:\n",
        "        print(f\"\\n{city}:\")\n",
        "        print(city_data[['City', 'review_scores_rating']].sort_values('review_scores_rating'))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nShared rooms with ratings below 4.0:\")\n",
        "shared_low = filtered_data[(filtered_data['room_type'] == 'Shared room') &\n",
        "                            (filtered_data['review_scores_rating'] < 4.0)]\n",
        "print(f\"Count: {len(shared_low)}\")\n",
        "for city in ['Barcelona', 'Madrid']:\n",
        "    city_data = shared_low[shared_low['City'] == city]\n",
        "    if len(city_data) > 0:\n",
        "        print(f\"\\n{city}:\")\n",
        "        print(city_data[['City', 'review_scores_rating']].sort_values('review_scores_rating'))\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"\\nBarcelona Hotel Rooms - Full distribution:\")\n",
        "bcn_hotels = filtered_data[(filtered_data['room_type'] == 'Hotel room') &\n",
        "                            (filtered_data['City'] == 'Barcelona')]\n",
        "print(f\"Q1: {bcn_hotels['review_scores_rating'].quantile(0.25):.2f}\")\n",
        "print(f\"Q3: {bcn_hotels['review_scores_rating'].quantile(0.75):.2f}\")\n",
        "print(f\"IQR: {bcn_hotels['review_scores_rating'].quantile(0.75) - bcn_hotels['review_scores_rating'].quantile(0.25):.2f}\")\n",
        "print(f\"Lower outlier bound: {bcn_hotels['review_scores_rating'].quantile(0.25) - 1.5 * (bcn_hotels['review_scores_rating'].quantile(0.75) - bcn_hotels['review_scores_rating'].quantile(0.25)):.2f}\")\n",
        "print(f\"Minimum rating: {bcn_hotels['review_scores_rating'].min():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHIX7sVqG5C6"
      },
      "source": [
        "**Rating Variability Patterns**\n",
        "\n",
        "The boxplots reveal consistent satisfaction across all room types, with most ratings clustered between 4.0 and 5.0. However, spread patterns vary notably by accommodation format.\n",
        "\n",
        "**Room Type Performance**\n",
        "\n",
        "Entire homes and private rooms show tight rating distributions (4.5 to 5.0), with several outliars ranging from 1 to 4 stars. Whilst Hotel rooms and Shared rooms, probably because they have much less data, don't show that many outliars and have a generally tighter overall distributions between 4 and 5 stars.\n",
        "\n",
        "**City Comparison**\n",
        "\n",
        "Madrid demonstrates narrower distributions across the first two categories, pointing to more consistent property standards. Whilst private rooms in Barcelona particularly seem to have slightly fewer low-rating outliers, but a higher spread of the ratings. Madrid shows that in Hotel rooms and Shared rooms, lower ratings are more frequent.\n",
        "\n",
        "Both cities follow similar variability patterns across room types, with differences in magnitude rather than structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPBukCYZHEMd"
      },
      "outputs": [],
      "source": [
        "# Calculate room type counts (using all properties, not just those with reviews, since we're counting supply)\n",
        "room_type_counts_madrid = madrid_listings['room_type'].value_counts()\n",
        "room_type_counts_barcelona = barcelona_listings['room_type'].value_counts()\n",
        "combined_room_type_counts = combined_listings['room_type'].value_counts()\n",
        "\n",
        "# Create DataFrame for visualization\n",
        "room_type_data = pd.DataFrame({\n",
        "    'Room Type': room_type_counts_barcelona.index,\n",
        "    'Barcelona': room_type_counts_barcelona.values,\n",
        "    'Madrid': room_type_counts_madrid.values,\n",
        "    'Total': combined_room_type_counts.values\n",
        "}).melt(id_vars=['Room Type'], var_name='City', value_name='Count')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjFbw8mWmhNH"
      },
      "outputs": [],
      "source": [
        "# Create enhanced visualization\n",
        "fig, ax = plt.subplots(figsize=(14, 8))\n",
        "\n",
        "# Define color palette\n",
        "palette_colors = {'Barcelona': COLORS['barcelona'], 'Madrid': COLORS['madrid'], 'Total': COLORS['accent']}\n",
        "bar_plot = sns.barplot(data=room_type_data, x='Room Type', y='Count', hue='City',\n",
        "                       palette=palette_colors, ax=ax, alpha=0.85, edgecolor='white', linewidth=2)\n",
        "\n",
        "# Add value labels on bars\n",
        "for container in ax.containers:\n",
        "    labels = [f'{int(v.get_height()):,}' if v.get_height() > 0 else '' for v in container]\n",
        "    ax.bar_label(container, labels=labels, padding=3, fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.set_title('Room Type Supply: Barcelona, Madrid, and Combined Total',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Room Type', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Number of Listings', fontsize=13, fontweight='bold')\n",
        "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
        "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax.legend(title='City', fontsize=11, title_fontsize=12, loc='upper right', frameon=True, shadow=True)\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0VyZTveHpgZ"
      },
      "source": [
        "**Supply Concentration**\n",
        "\n",
        "Entire homes and apartments dominate inventory in both cities. Madrid holds 13,516 listings versus Barcelona's 10,287, establishing entire homes as the primary accommodation format. Private rooms rank second with Madrid (5,036) slightly ahead of Barcelona (4,608), representing a meaningful market segment for budget travelers and shorter stays.\n",
        "\n",
        "Shared rooms and hotel rooms comprise a minimal fraction of total supply: 253 shared rooms and 91 hotel rooms combined. This limited inventory suggests either constrained demand or restricted supply channels, positioning these formats as niche offerings rather than core market products."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yj1VPAyrhVfB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Filter data for each city (excluding properties with no reviews)\n",
        "madrid_data = combined_listings[(combined_listings['City'] == 'Madrid') & (combined_listings['review_scores_rating'] > 0)]\n",
        "barcelona_data = combined_listings[(combined_listings['City'] == 'Barcelona') & (combined_listings['review_scores_rating'] > 0)]\n",
        "\n",
        "# Create pivot tables for each city\n",
        "madrid_heatmap_data = madrid_data.pivot_table(\n",
        "    index='bedrooms',\n",
        "    columns='bathrooms',\n",
        "    values='review_scores_rating',\n",
        "    aggfunc='mean'\n",
        ")\n",
        "barcelona_heatmap_data = barcelona_data.pivot_table(\n",
        "    index='bedrooms',\n",
        "    columns='bathrooms',\n",
        "    values='review_scores_rating',\n",
        "    aggfunc='mean'\n",
        ")\n",
        "\n",
        "# Heatmap for Madrid\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(madrid_heatmap_data, annot=True, fmt=\".1f\", cmap='Blues', cbar_kws={'label': 'Average Rating'})\n",
        "plt.title('Average Ratings by Bedroom-Bathroom Combinations (Madrid)', fontsize=16)\n",
        "plt.xlabel('Number of Bathrooms', fontsize=14)\n",
        "plt.ylabel('Number of Bedrooms', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Heatmap for Barcelona\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(barcelona_heatmap_data, annot=True, fmt=\".1f\", cmap='Blues', cbar_kws={'label': 'Average Rating'})\n",
        "plt.title('Average Ratings by Bedroom-Bathroom Combinations (Barcelona)', fontsize=16)\n",
        "plt.xlabel('Number of Bathrooms', fontsize=14)\n",
        "plt.ylabel('Number of Bedrooms', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS0hcn5-Ipb1"
      },
      "source": [
        "**Guest Satisfaction and Bathroom Configurations**\n",
        "\n",
        "Note: we'll assume that those with 0 bedrooms are studios with the living and sleeping area in the same place. Whilst those with 0 bathrooms we can assume that have shared facilities.\n",
        "\n",
        "**Madrid Guest Expectations**\n",
        "\n",
        "Madrid ratings show relatively consistent performance across most bedroom-bathroom combinations, typically ranging from 4.5 to 4.8. There are no dramatic patterns suggesting guests heavily penalize specific configurations.\n",
        "\n",
        "Notable observations: Properties with 0 bedrooms and 0.5 bathrooms score lower (3.4), likely studio apartments with minimal facilities. The most common configurations (1-3 bedrooms with 1-2 bathrooms) consistently score between 4.5 and 4.7.\n",
        "\n",
        "**Barcelona Guest Expectations**\n",
        "\n",
        "Barcelona shows similarly stable ratings across standard configurations, with most properties scoring between 4.5 and 4.8. There's no clear evidence that adding bathrooms significantly improves ratings.\n",
        "\n",
        "Notable observations: Some unusual configurations score poorly, like 5 bedrooms with 1 bathroom (3.8) or 1 bedroom with 8 bathrooms (3.5), but these represent tiny sample sizes and likely have other issues that justify said rating apart from the weird layouts. Standard 2-3 bedroom properties with 1-2 bathrooms consistently score 4.6 to 4.7 regardless of the exact bathroom count.\n",
        "\n",
        "**What This Means for Investment**\n",
        "\n",
        "There's no strong correlation between bedroom-bathroom ratios and guest ratings in either city. Ratings remain remarkably consistent (4.5-4.8) across most standard configurations. This suggests that bathroom count alone doesn't drive satisfaction. Guests care more about other factors like cleanliness, location, amenities, and host quality.\n",
        "\n",
        "The few low-rated cells (like extreme configurations with 50+ bedrooms or mismatched ratios) have very small sample sizes and likely reflect specific property problems rather than the configuration itself.\n",
        "\n",
        "**Investment recommendation:** Focus on standard configurations (0-3 bedrooms, 0-2 bathrooms) where you have reliable data. Don't over-invest in extra bathrooms expecting higher ratings. Instead, prioritize overall quality, cleanliness, and amenities that the earlier models showed actually matter for pricing and satisfaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahJmcJjEjerw"
      },
      "outputs": [],
      "source": [
        "# Define high rating threshold\n",
        "high_rating_threshold = 4.5\n",
        "\n",
        "# Filter to only reviewed listings (exclude review_scores_rating = 0)\n",
        "madrid_reviewed = madrid_listings[madrid_listings['review_scores_rating'] > 0]\n",
        "barcelona_reviewed = barcelona_listings[barcelona_listings['review_scores_rating'] > 0]\n",
        "\n",
        "# Filter data for Madrid and Barcelona\n",
        "success_rate_madrid = madrid_reviewed.groupby('room_type')['review_scores_rating'].apply(\n",
        "    lambda x: (x >= high_rating_threshold).mean() * 100\n",
        ").reset_index()\n",
        "success_rate_barcelona = barcelona_reviewed.groupby('room_type')['review_scores_rating'].apply(\n",
        "    lambda x: (x >= high_rating_threshold).mean() * 100\n",
        ").reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "success_rate_madrid.columns = ['Room Type', 'Success Rate (%)']\n",
        "success_rate_barcelona.columns = ['Room Type', 'Success Rate (%)']\n",
        "\n",
        "# Sort by success rate in descending order\n",
        "success_rate_madrid = success_rate_madrid.sort_values(by='Success Rate (%)', ascending=False)\n",
        "success_rate_barcelona = success_rate_barcelona.sort_values(by='Success Rate (%)', ascending=False)\n",
        "\n",
        "# Plot for Madrid\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax_madrid = sns.barplot(data=success_rate_madrid, x='Room Type', y='Success Rate (%)', hue='Room Type', palette='Set2', legend=False)\n",
        "for p in ax_madrid.patches:\n",
        "    ax_madrid.annotate(\n",
        "        f\"{p.get_height():.1f}%\",\n",
        "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "        ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "plt.title('Success Rate by Room Type (Madrid)', fontsize=16)\n",
        "plt.ylabel('Success Rate (%)', fontsize=14)\n",
        "plt.xlabel('Room Type', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot for Barcelona\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax_barcelona = sns.barplot(data=success_rate_barcelona, x='Room Type', y='Success Rate (%)', hue='Room Type', palette='coolwarm', legend=False)\n",
        "for p in ax_barcelona.patches:\n",
        "    ax_barcelona.annotate(\n",
        "        f\"{p.get_height():.1f}%\",\n",
        "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "        ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "plt.title('Success Rate by Room Type (Barcelona)', fontsize=16)\n",
        "plt.ylabel('Success Rate (%)', fontsize=14)\n",
        "plt.xlabel('Room Type', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oOIEhelmhNH"
      },
      "source": [
        "**Definition of Success Rate**: it measures guest satisfaction quality by calculating the percentage of listings within each room type that achieve a review score of 4.5 or higher (on a 0-5 scale). This metric only includes properties that have received reviews, so it reflects quality performance among active listings with guest feedback.\n",
        "\n",
        "**Formula:** (Count of listings with rating ≥ 4.5) / (Total listings in room type with ratings) × 100%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSMvfDWJcdht"
      },
      "source": [
        "**Madrid Success Rates**\n",
        "\n",
        "Private rooms and entire homes lead with nearly identical success rates at 79.9% and 79.7% respectively, reflecting strong guest satisfaction across these accommodation types. Hotel rooms achieve a solid 72.5% success rate, demonstrating consistent quality performance. Shared rooms lag behind at 64.8%, suggesting that privacy concerns or facility limitations impact guest satisfaction in this category.\n",
        "\n",
        "**Barcelona Success Rates**\n",
        "\n",
        "Hotel rooms significantly outperform all other categories with an impressive 88.0% success rate, indicating exceptional guest satisfaction potentially driven by superior location, services, or professional management. Entire homes and apartments achieve a strong 76.2% success rate, highlighting sustained demand and quality for independent accommodations. Private rooms follow at 73.4%, offering good value for budget-conscious travelers. Shared rooms record the lowest rate at 64.4%, with privacy concerns or insufficient amenities likely limiting guest satisfaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5SY63XFiVhm"
      },
      "outputs": [],
      "source": [
        "# Define high rating threshold\n",
        "high_rating_threshold = 4.5\n",
        "\n",
        "# Filter for reviewed properties only\n",
        "reviewed_listings = combined_listings[combined_listings['review_scores_rating'] > 0]\n",
        "\n",
        "# Calculate success rate by room type (only for properties with reviews)\n",
        "success_rate = reviewed_listings.groupby('room_type')['review_scores_rating'].apply(\n",
        "    lambda x: (x >= high_rating_threshold).mean() * 100\n",
        ").reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "success_rate.columns = ['Room Type', 'Success Rate (%)']\n",
        "\n",
        "# Sort by success rate in descending order\n",
        "success_rate = success_rate.sort_values(by='Success Rate (%)', ascending=False)\n",
        "\n",
        "# Visualize success rate\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.barplot(data=success_rate, x='Room Type', y='Success Rate (%)', hue='Room Type', palette='Set2', legend=False)\n",
        "\n",
        "# Annotate success rates on top of each bar\n",
        "for p in ax.patches:\n",
        "    ax.annotate(\n",
        "        f\"{p.get_height():.1f}%\",  # Format the success rate\n",
        "        (p.get_x() + p.get_width() / 2., p.get_height()),  # Position at the center of the bar\n",
        "        ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Success Rate by Room Type for both cities', fontsize=16)\n",
        "plt.ylabel('Success Rate (%)', fontsize=14)\n",
        "plt.xlabel('Room Type', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3cEOvqUmhNI"
      },
      "source": [
        "Hotel rooms have the highest combined success rate at 81.1%, followed by entire homes at 78.3% and private rooms at 77.0%. Shared rooms achieve 64.7%, the lowest but still respectable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hTqkfJQl6Ep"
      },
      "outputs": [],
      "source": [
        "# Define high rating threshold\n",
        "high_rating_threshold = 4.5\n",
        "\n",
        "# Filter for reviewed properties only\n",
        "reviewed_listings_city = combined_listings[combined_listings['review_scores_rating'] > 0]\n",
        "\n",
        "# Calculate success rate by room type and city (only for properties with reviews)\n",
        "success_rate_cities = reviewed_listings_city.groupby(['City', 'room_type'])['review_scores_rating'].apply(\n",
        "    lambda x: (x >= high_rating_threshold).mean() * 100\n",
        ").reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "success_rate_cities.columns = ['City', 'Room Type', 'Success Rate (%)']\n",
        "\n",
        "# Visualize success rate by city\n",
        "plt.figure(figsize=(12, 8))\n",
        "ax = sns.barplot(\n",
        "    data=success_rate_cities,\n",
        "    x='Room Type',\n",
        "    y='Success Rate (%)',\n",
        "    hue='City',\n",
        "    palette='Set2'\n",
        ")\n",
        "\n",
        "# Annotate success rates above the columns\n",
        "for p in ax.patches:\n",
        "    ax.annotate(\n",
        "        f\"{p.get_height():.1f}%\",  # Format success rate as percentage\n",
        "        (p.get_x() + p.get_width() / 2., p.get_height()),  # Center annotation above bar\n",
        "        ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Success Rate by Room Type for Madrid and Barcelona', fontsize=16)\n",
        "plt.ylabel('Success Rate (%)', fontsize=14)\n",
        "plt.xlabel('Room Type', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.legend(title='City')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmEkI6N4mhNI"
      },
      "source": [
        "Barcelona's hotel rooms lead with an exceptional 88.0% success rate, while Madrid's private rooms and entire homes both achieve approximately 79.7-79.9%. Shared rooms perform consistently around 64-65% in both cities, showing that this category meets guest expectations at similar levels across markets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwjlWHSMkNQY"
      },
      "outputs": [],
      "source": [
        "# Calculate performance metrics for Madrid\n",
        "# Note: Price is already numeric after Section 1 cleaning, no conversion needed\n",
        "# Only include properties with reviews (review_scores_rating > 0) for accurate rating averages\n",
        "madrid_with_reviews = madrid_listings[madrid_listings['review_scores_rating'] > 0]\n",
        "performance_metrics_madrid = madrid_with_reviews.groupby('room_type').agg({\n",
        "    'review_scores_rating': 'mean',\n",
        "    'price': 'mean',\n",
        "    'id': 'count'\n",
        "}).reset_index()\n",
        "performance_metrics_madrid.columns = ['Room Type', 'Average Rating', 'Average Price', 'Number of Properties']\n",
        "performance_metrics_madrid = performance_metrics_madrid.sort_values(by='Average Price', ascending=False)\n",
        "\n",
        "# Calculate performance metrics for Barcelona\n",
        "barcelona_with_reviews = barcelona_listings[barcelona_listings['review_scores_rating'] > 0]\n",
        "performance_metrics_barcelona = barcelona_with_reviews.groupby('room_type').agg({\n",
        "    'review_scores_rating': 'mean',\n",
        "    'price': 'mean',\n",
        "    'id': 'count'\n",
        "}).reset_index()\n",
        "performance_metrics_barcelona.columns = ['Room Type', 'Average Rating', 'Average Price', 'Number of Properties']\n",
        "performance_metrics_barcelona = performance_metrics_barcelona.sort_values(by='Average Price', ascending=False)\n",
        "\n",
        "# Visualization for Madrid\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax_madrid = sns.barplot(data=performance_metrics_madrid, x='Room Type', y='Average Price', hue='Room Type', palette='Set2', legend=False)\n",
        "for p in ax_madrid.patches:\n",
        "    ax_madrid.annotate(\n",
        "        f\"${p.get_height():,.2f}\",\n",
        "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "        ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "plt.title('Average Price by Room Type (Madrid)', fontsize=16)\n",
        "plt.ylabel('Average Price ($)', fontsize=14)\n",
        "plt.xlabel('Room Type', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualization for Barcelona\n",
        "plt.figure(figsize=(12, 6))\n",
        "ax_barcelona = sns.barplot(data=performance_metrics_barcelona, x='Room Type', y='Average Price', hue='Room Type', palette='coolwarm', legend=False)\n",
        "for p in ax_barcelona.patches:\n",
        "    ax_barcelona.annotate(\n",
        "        f\"${p.get_height():,.2f}\",\n",
        "        (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "        ha='center', va='bottom', fontsize=10\n",
        "    )\n",
        "plt.title('Average Price by Room Type (Barcelona)', fontsize=16)\n",
        "plt.ylabel('Average Price ($)', fontsize=14)\n",
        "plt.xlabel('Room Type', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga3qKUfikICK"
      },
      "source": [
        "**Pricing by Room Type**\n",
        "\n",
        "Entire homes command the highest average prices in Madrid at $156.12, while hotel rooms lead Barcelona's pricing at $223.94. Barcelona charges significantly more across all categories compared to Madrid, with entire homes at $197.04 versus Madrid's $156.12.\n",
        "\n",
        "Hotel rooms show interesting price positioning: $151.03 in Madrid (slightly below entire homes) and $223.94 in Barcelona (above entire homes at $197.04). Despite their high success rates, hotel rooms maintain competitive pricing relative to entire homes.\n",
        "\n",
        "Private and shared rooms remain the most affordable options. Private rooms average $68.55 in Madrid and $89.27 in Barcelona. Shared rooms are the most economical at $46.23 in Madrid and $78.75 in Barcelona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxfSt2QR9zzM"
      },
      "source": [
        "### **Step 2.2: Impact of Amenities**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk37hJjzxi85"
      },
      "source": [
        "The following analysis examines relationships between amenity counts, review scores, and pricing to provide actionable guidance for hosts and investors on amenity investment decisions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV1m3CphIeac"
      },
      "outputs": [],
      "source": [
        "# Filter for reviewed properties and count amenities per listing\n",
        "reviewed_listings = combined_listings[combined_listings['review_scores_rating'] > 0].copy()\n",
        "reviewed_listings['num_amenities'] = reviewed_listings['amenities'].apply(\n",
        "    lambda x: len(str(x).strip('{}').split(','))\n",
        ")\n",
        "\n",
        "# Calculate average ratings by amenity count (excluding unreviewed properties)\n",
        "amenities_ratings = reviewed_listings.groupby('num_amenities')['review_scores_rating'].mean().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc0PaYQ1mhNI"
      },
      "outputs": [],
      "source": [
        "# Create enhanced scatter plot with regression\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "# Scatter plot with custom styling\n",
        "ax.scatter(amenities_ratings['num_amenities'], amenities_ratings['review_scores_rating'],\n",
        "           s=120, color=COLORS['barcelona'], alpha=0.6, edgecolors='white', linewidth=1.5,\n",
        "           label='Average Rating')\n",
        "\n",
        "# Add regression line\n",
        "sns.regplot(data=amenities_ratings, x='num_amenities', y='review_scores_rating',\n",
        "            scatter=False, color=COLORS['accent'], line_kws={'linewidth': 3, 'alpha': 0.8},\n",
        "            ax=ax, label='Trend Line')\n",
        "\n",
        "ax.set_title('Amenity Count vs. Guest Ratings: The Quality-Quantity Relationship',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Number of Amenities', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Average Rating', fontsize=13, fontweight='bold')\n",
        "ax.set_ylim(4.0, 5.0)\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.legend(fontsize=11, frameon=True, shadow=True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxsGEQyAzYSD"
      },
      "source": [
        "**Amenity Count and Rating Correlation**\n",
        "\n",
        "The data shows a clear positive correlation between amenity count and average ratings. Properties with fewer than 30 amenities typically achieve ratings between 4.3 and 4.6. As amenity counts increase to 30 to 60, ratings improve noticeably, with properties reaching scores above 4.8.\n",
        "\n",
        "**Strategic Thresholds**\n",
        "\n",
        "Providing 30 to 60 well selected amenities can meaningfully boost ratings, especially for properties looking to improve guest satisfaction. However, some high amenity properties still receive lower ratings, showing that quantity alone doesn't guarantee positive reviews. Quality of service, cleanliness, and meeting guest expectations remain equally critical to achieving high satisfaction scores. It's interesting to see that the listings with the most ammenities (>65) have an increased spread of their avg. rating, with some being worse off when ammenities surpass 70."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMviuXuE-O7B"
      },
      "outputs": [],
      "source": [
        "# Check the structure of the amenities column\n",
        "print(\"Preview of the 'amenities' column:\")\n",
        "print(combined_listings['amenities'].head())\n",
        "\n",
        "# Split amenities into individual items\n",
        "combined_listings['amenities_list'] = combined_listings['amenities'].apply(lambda x: str(x).strip('{}').split(','))\n",
        "\n",
        "# Count frequency of each amenity\n",
        "from collections import Counter\n",
        "all_amenities = combined_listings['amenities_list'].explode()\n",
        "amenities_count = Counter(all_amenities)\n",
        "\n",
        "# Convert to DataFrame for visualization\n",
        "amenities_df = pd.DataFrame(amenities_count.items(), columns=['Amenity', 'Count']).sort_values(by='Count', ascending=False)\n",
        "\n",
        "# Plot top 10 amenities\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(data=amenities_df.head(10), x='Amenity', y='Count', hue='Amenity', palette='Set2', legend=False)\n",
        "plt.title('Top 10 Most Common Amenities')\n",
        "plt.xlabel('Amenity')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare ratings for properties with a specific amenity (only for reviewed properties)\n",
        "specific_amenity = 'Wifi'  # Example\n",
        "combined_listings['has_wifi'] = combined_listings['amenities'].apply(lambda x: specific_amenity in str(x))\n",
        "\n",
        "# Filter to only properties with reviews\n",
        "listings_with_reviews_wifi = combined_listings[combined_listings['review_scores_rating'] > 0]\n",
        "ratings_wifi = listings_with_reviews_wifi.groupby('has_wifi')['review_scores_rating'].mean()\n",
        "\n",
        "print(\"Average Ratings for Properties with and without Wifi:\")\n",
        "print(ratings_wifi)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7tbS9xCmhNJ"
      },
      "source": [
        "WiFi and kitchen are the most common amenities with nearly 30,000 properties each offering them, followed by hot water, bed linens, dishes and silverware, hangers, iron, microwave, and hair dryer. Interestingly, properties without WiFi score slightly higher ratings (4.69) compared to those with WiFi (4.61), though this likely reflects the very small sample size of properties without this now-standard amenity rather than WiFi being detrimental to ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6GCUqVbWWsO"
      },
      "source": [
        "The following analysis examines how the presence or absence of these common amenities affects overall rating performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUfFEI6m-tCd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filter out properties with no reviews before analysis\n",
        "listings_with_reviews = combined_listings[combined_listings['review_scores_rating'] > 0].copy()\n",
        "\n",
        "# Split amenities into individual items\n",
        "listings_with_reviews['amenities_list'] = listings_with_reviews['amenities'].apply(lambda x: str(x).strip('{}').split(','))\n",
        "\n",
        "# Expand the amenities list into multiple binary columns (1 if the amenity is present, 0 if not)\n",
        "amenities_dummies = listings_with_reviews['amenities_list'].explode().str.strip().value_counts()\n",
        "top_amenities = amenities_dummies.head(10).index  # Focus on the top 10 most common amenities\n",
        "\n",
        "# Create binary columns for top amenities\n",
        "for amenity in top_amenities:\n",
        "    listings_with_reviews[amenity] = listings_with_reviews['amenities'].apply(lambda x: 1 if amenity in str(x) else 0)\n",
        "\n",
        "# Calculate average ratings for properties with and without each amenity (excluding unreviewed properties)\n",
        "amenities_ratings = pd.DataFrame({\n",
        "    amenity: [\n",
        "        listings_with_reviews[listings_with_reviews[amenity] == 1]['review_scores_rating'].mean(),\n",
        "        listings_with_reviews[listings_with_reviews[amenity] == 0]['review_scores_rating'].mean()\n",
        "    ] for amenity in top_amenities\n",
        "}).T\n",
        "\n",
        "amenities_ratings.columns = ['Has Amenity', 'Does Not Have Amenity']\n",
        "\n",
        "# Heatmap visualization of ratings by amenities\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(amenities_ratings, annot=True, cmap='coolwarm', fmt=\".2f\", cbar_kws={'label': 'Average Rating'})\n",
        "plt.title('Impact of Amenities on Average Ratings')\n",
        "plt.xlabel('Amenity Status')\n",
        "plt.ylabel('Amenity')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWHpD4ekQ1dw"
      },
      "source": [
        "**Amenity Impact on Ratings**\n",
        "\n",
        "The relationship between amenities and ratings reveals a counterintuitive pattern. Properties **without** WiFi actually score slightly higher (4.70) than those with it (4.61). Similarly, properties lacking kitchens score marginally better (4.59 vs 4.62). This suggests these amenities are so standard that their presence is expected rather than valued, while their absence might indicate specialty properties that compensate with a superior or unique service.\n",
        "\n",
        "However, the pattern flips for convenience amenities. Properties **with** hangers, hair dryers, irons, microwaves, and essentials score higher (4.65-4.66) than those without them (4.49-4.55). This suggests these \"nice to have\" items genuinely improve guest experience because they're not universally expected.\n",
        "\n",
        "The most dramatic impact is hot water and dishes/silverware, where having them scores 4.64-4.65 versus 4.52 without. These are baseline necessities, and their absence significantly hurts ratings.\n",
        "\n",
        "**Focus on What Matters**\n",
        "\n",
        "The data reveals a hierarchy of amenity importance. Basic necessities like hot water and dishes are non-negotiable. Convenience items like hangers, hair dryers, and irons provide meaningful rating boosts because guests appreciate the thoughtfulness. Meanwhile, standard amenities like WiFi and kitchens have become so expected that having them doesn't boost ratings, though lacking them in the wrong property type could hurt.\n",
        "\n",
        "**Investment Strategy**\n",
        "\n",
        "Don't chase amenity quantity. Instead, ensure you have all baseline necessities covered, then add thoughtful convenience items that show attention to guest comfort. Focus your resources on service quality, cleanliness, and overall experience, which the earlier models showed matter more than amenity count alone. The goal is meeting expectations efficiently, not exceeding them expensively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCjO-2XCLRhc"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Split amenities into individual items and count their frequency\n",
        "combined_listings['amenities_list'] = combined_listings['amenities'].apply(lambda x: str(x).strip('{}').split(','))\n",
        "all_amenities = combined_listings['amenities_list'].explode().str.strip()\n",
        "amenities_count = Counter(all_amenities)\n",
        "\n",
        "# Focus on the top 20 most common amenities\n",
        "top_amenities = [amenity for amenity, count in amenities_count.most_common(20)]\n",
        "\n",
        "# Create binary columns for top amenities\n",
        "for amenity in top_amenities:\n",
        "    combined_listings[amenity] = combined_listings['amenities'].apply(lambda x: 1 if amenity in str(x) else 0)\n",
        "\n",
        "# Analyze the impact of amenities on price\n",
        "amenities_analysis = pd.DataFrame({\n",
        "    'Amenity': top_amenities,\n",
        "    'Average Price (With Amenity)': [\n",
        "        combined_listings[combined_listings[amenity] == 1]['price'].mean() for amenity in top_amenities\n",
        "    ],\n",
        "    'Average Price (Without Amenity)': [\n",
        "        combined_listings[combined_listings[amenity] == 0]['price'].mean() for amenity in top_amenities\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Order by average price (with the amenity)\n",
        "amenities_analysis = amenities_analysis.sort_values(by='Average Price (With Amenity)', ascending=False)\n",
        "\n",
        "# Visualize the impact on pricing\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(data=amenities_analysis, x='Average Price (With Amenity)', y='Amenity', hue='Amenity', palette='viridis', legend=False)\n",
        "plt.title('Impact of Amenities on Average Pricing', fontsize=16)\n",
        "plt.xlabel('Average Price (With Amenity)', fontsize=14)\n",
        "plt.ylabel('Amenity', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3-efs-5Z2fW"
      },
      "source": [
        "**Understanding the Data**\n",
        "\n",
        "The relationship between amenities and pricing is often indirect. Elevators don't independently add €20 to nightly rates. Instead, they signal premium properties in modern buildings with higher land values. Similarly, kitchens correlate with larger properties that already command higher prices. Many amenities reflect property type and location rather than directly driving pricing.\n",
        "\n",
        "**Investment Priorities**\n",
        "\n",
        "Focus capital on premium amenities that signal quality. Elevators, hot water kettles, and shampoo command the highest average prices (€165-170), indicating well-maintained, upscale properties. Air conditioning, heating, and hair dryers follow closely (€160-165), particularly valuable in cities with temperature extremes.\n",
        "\n",
        "Mid-tier amenities like essentials, irons, microwaves, and refrigerators cluster around €155-160. These are functionally important but don't dramatically differentiate pricing. Kitchen amenities and WiFi sit lower (€145-150) because they're so universal that their presence is expected rather than valued.\n",
        "\n",
        "Basic amenities are non-negotiable. Hot water, dishes, and WiFi may not boost pricing, but their absence deters bookings and lowers satisfaction. Always include baseline necessities.\n",
        "\n",
        "**Actionable Strategy**\n",
        "\n",
        "For new investments, prioritize locations and properties with built-in premium signals like elevator buildings and climate control. For existing properties, add low-cost convenience amenities like shampoo, hair dryers, and kitchen essentials. These align your property with higher-priced comparables without major capital expenditure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Mg-KZdgU2vp"
      },
      "source": [
        "Now lets go into Beds, Accommodates and Pricing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgogcTuOwX04"
      },
      "source": [
        "The following heatmap examines correlations between bed count, accommodates capacity, and ratings. We expect a positive and strong correlation between beds and accommodates, but the relationship between these variables and ratings remains uncertain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py8nkW0ZCb08"
      },
      "outputs": [],
      "source": [
        "# Calculate correlation matrix\n",
        "correlation_matrix = combined_listings[['beds', 'accommodates', 'review_scores_rating']].corr()\n",
        "\n",
        "# Heatmap visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Between Beds, Accommodates, and Ratings')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVRIec39wRNd"
      },
      "source": [
        "**Correlation Findings**\n",
        "\n",
        "The correlation between beds and accommodates reaches 0.71, confirming a strong positive relationship. More beds directly enable higher guest capacity, as expected. However, beds (correlation of 0.06) and accommodates (correlation of 0.11) show virtually no correlation with review scores. This indicates guest capacity does not significantly impact satisfaction or ratings.\n",
        "\n",
        "**Rating Independence**\n",
        "\n",
        "Ratings appear independent of property size measured by beds and guest capacity. This highlights that factors beyond capacity drive guest satisfaction, including cleanliness, amenities, and service quality. Since ratings remain unaffected by bed count or capacity, enhancing amenities or guest experience likely generates more meaningful improvements in review performance than expanding property size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Wbw5ofFzjY6"
      },
      "source": [
        "The following heatmap examines whether mismatches between listed capacity and actual sleeping arrangements affect ratings. Some hosts may advertise capacity for 9 guests but provide adequate sleeping space for only 4, forcing guests to use sofas or floors. The analysis tests whether such discrepancies correlate with lower ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDJl2XQ4Cj9w"
      },
      "outputs": [],
      "source": [
        "# Group by beds and accommodates (excluding properties with no reviews)\n",
        "grouped_data = combined_listings[combined_listings['review_scores_rating'] > 0]\n",
        "grouped_ratings = grouped_data.groupby(['beds', 'accommodates'])['review_scores_rating'].mean().reset_index()\n",
        "\n",
        "# Pivot for heatmap visualization\n",
        "grouped_pivot = grouped_ratings.pivot(index='beds', columns='accommodates', values='review_scores_rating')\n",
        "\n",
        "# Heatmap of average ratings\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(grouped_pivot, annot=True, fmt=\".1f\", cmap='coolwarm', cbar_kws={'label': 'Average Rating'})\n",
        "plt.title('Average Ratings by Number of Beds and Accommodates')\n",
        "plt.xlabel('Number of Accommodates')\n",
        "plt.ylabel('Number of Beds')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84AjS-zIHhub"
      },
      "source": [
        "**Rating Distribution**\n",
        "\n",
        "Most bed and capacity combinations achieve ratings between 4.5 and 5.0, indicating general guest satisfaction regardless of bed to capacity ratios. The hypothesis that mismatched configurations lead to lower ratings is not strongly supported by the data.\n",
        "\n",
        "**Optimal Configurations**\n",
        "\n",
        "Properties with 1 to 5 guests and 1 to 5 beds consistently achieve high ratings of 4.5 to 4.9, likely because the bed to capacity ratio meets expectations effectively. Larger properties with 5 or more guests and adequate beds (5 to 8 beds) also maintain strong ratings, successfully meeting the needs of larger groups.\n",
        "\n",
        "**Outlier Patterns**\n",
        "\n",
        "Some configurations show significantly lower ratings, including 3 guests with 10 beds (rating of 3.9), 6 beds with 2 guests (rating of 4.0), and 13 beds with 10 guests (rating of 3.3). These outliers likely reflect poor service quality or mismatched guest expectations rather than bed count itself. The small number of properties in these extreme configurations makes them statistically unreliable.\n",
        "\n",
        "**Investment Strategy**\n",
        "\n",
        "Focus on smaller properties accommodating 1 to 5 guests with 1 to 5 beds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjr5fygAOP4f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create a copy of the dataset and filter out rows without pricing or reviews\n",
        "data_with_price = combined_listings.copy()\n",
        "\n",
        "data_with_price['price'] = pd.to_numeric(data_with_price['price'], errors='coerce')\n",
        "\n",
        "# Remove rows without price or ratings, and exclude properties with no reviews (rating = 0)\n",
        "data_with_price = data_with_price.dropna(subset=['price', 'review_scores_rating'])\n",
        "data_with_price = data_with_price[data_with_price['review_scores_rating'] > 0]\n",
        "\n",
        "# Step 2: Visualize the relationship between pricing and ratings\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(\n",
        "    data=data_with_price,\n",
        "    x='price',\n",
        "    y='review_scores_rating',\n",
        "    hue='room_type',\n",
        "    palette='coolwarm',\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title('Relationship Between Pricing and Ratings', fontsize=16)\n",
        "plt.xlabel('Price ($)', fontsize=14)\n",
        "plt.ylabel('Review Scores Rating', fontsize=14)\n",
        "plt.legend(title='Room Type')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Calculate correlation between price and ratings\n",
        "correlation = data_with_price[['price', 'review_scores_rating']].corr()\n",
        "print(\"Correlation between price and review scores rating:\")\n",
        "print(correlation)\n",
        "\n",
        "# Step 4: Group by price ranges and calculate average ratings\n",
        "# Create bins dynamically to ensure they're monotonic and unique\n",
        "import numpy as np\n",
        "max_price = data_with_price['price'].max()\n",
        "# Create bin edges, removing duplicates and ensuring they're sorted\n",
        "bin_edges = np.sort(np.unique([0, 50, 100, 200, 300, 500, 1000, max_price]))\n",
        "price_bins = pd.cut(data_with_price['price'], bins=bin_edges)\n",
        "average_ratings_by_price = data_with_price.groupby(price_bins, observed=True)['review_scores_rating'].mean().reset_index()\n",
        "\n",
        "# Step 5: Visualize average ratings by price ranges\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.barplot(\n",
        "    data=average_ratings_by_price,\n",
        "    x='price',\n",
        "    y='review_scores_rating',\n",
        "    hue='price',\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "plt.title('Average Ratings by Price Ranges', fontsize=16)\n",
        "plt.xlabel('Price Range (€)', fontsize=14)\n",
        "plt.ylabel('Average Rating', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6CloSGhHeaG"
      },
      "source": [
        "**Pricing and Rating Relationship**\n",
        "\n",
        "The correlation between price and review scores is virtually zero at 0.06, indicating no meaningful relationship between what properties charge and how guests rate them. The scatter plot confirms this, showing properties at all price points achieving ratings across the full spectrum from 1.0 to 5.0.\n",
        "\n",
        "Average ratings remain remarkably consistent across all price ranges, hovering around 4.5 to 4.7 whether properties cost €50 or €900 per night (althoug they climb slightly as price increases). This suggests guest satisfaction is driven by factors other than price, including amenities, location, cleanliness, and service quality. Higher prices do not lead to lower ratings from disappointed guests, nor do they guarantee higher ratings from satisfied customers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yk4JeD7mhNK"
      },
      "outputs": [],
      "source": [
        "# Check the distribution of prices above 974€\n",
        "print(\"Listings with price > 974€:\")\n",
        "high_price_listings = data_with_price[data_with_price['price'] > 974]\n",
        "print(f\"Total count: {len(high_price_listings)}\")\n",
        "\n",
        "# Show the actual price distribution\n",
        "print(\"\\nPrice distribution for high-end listings:\")\n",
        "print(high_price_listings['price'].describe())\n",
        "\n",
        "# Check what the maximum price in your dataset is\n",
        "print(f\"\\nMaximum price in dataset: €{data_with_price['price'].max():.2f}\")\n",
        "\n",
        "# Show how many listings fall into each bin\n",
        "print(\"\\nListings count by price range:\")\n",
        "price_range_counts = data_with_price.groupby(price_bins, observed=True).size()\n",
        "print(price_range_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp-OcnK2ICla"
      },
      "source": [
        "### **Step 2.3: Trends in the Future**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlXC5BcyIR8f"
      },
      "source": [
        "**Regulatory Context**\n",
        "\n",
        "Both Madrid and Barcelona have implemented stricter regulations for short-term rentals, requiring hosts to hold valid licenses. Despite these rules, analysis reveals significant numbers of hosts continue operating without licenses, facing potential fines or sanctions from local authorities. Madrid has recently tightened restrictions further, while Barcelona maintains historically rigorous enforcement.\n",
        "\n",
        "**Analysis Scope**\n",
        "\n",
        "The supply and demand analysis includes both licensed and unlicensed properties, reflecting current market dynamics where unlicensed hosts continue operations without immediate consequences. This balance could shift if stricter enforcement mechanisms are introduced, including Airbnb restrictions on unlicensed properties or increased penalties from authorities. Some hosts may have failed to display license numbers on Airbnb due to oversight or negligence rather than intentional non-compliance.\n",
        "\n",
        "**Methodological Note**\n",
        "\n",
        "Given these factors, excluding unlicensed properties from the analysis would not yield statistically significant results for current market conditions. The following future trends analysis examines both cities to identify investment opportunities within this regulatory landscape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzPqJy6CNrVI"
      },
      "outputs": [],
      "source": [
        "# Prepare booking data\n",
        "madrid_calendar_data['booked'] = madrid_calendar_data['available'].apply(lambda x: 1 if x == 'f' else 0)\n",
        "barcelona_calendar_data['booked'] = barcelona_calendar_data['available'].apply(lambda x: 1 if x == 'f' else 0)\n",
        "\n",
        "# Convert dates\n",
        "madrid_calendar_data['date'] = pd.to_datetime(madrid_calendar_data['date'])\n",
        "barcelona_calendar_data['date'] = pd.to_datetime(barcelona_calendar_data['date'])\n",
        "\n",
        "# Aggregate bookings by date\n",
        "madrid_trends = madrid_calendar_data.groupby('date')['booked'].sum().reset_index()\n",
        "barcelona_trends = barcelona_calendar_data.groupby('date')['booked'].sum().reset_index()\n",
        "\n",
        "madrid_trends['City'] = 'Madrid'\n",
        "barcelona_trends['City'] = 'Barcelona'\n",
        "\n",
        "combined_trends = pd.concat([madrid_trends, barcelona_trends])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WehRsRLfmhNK"
      },
      "outputs": [],
      "source": [
        "print(\"Original Calendar Date Range\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nMadrid Calendar:\")\n",
        "print(f\"  Min Date: {madrid_calendar_data['date'].min()}\")\n",
        "print(f\"  Max Date: {madrid_calendar_data['date'].max()}\")\n",
        "\n",
        "print(f\"\\nBarcelona Calendar:\")\n",
        "print(f\"  Min Date: {barcelona_calendar_data['date'].min()}\")\n",
        "print(f\"  Max Date: {barcelona_calendar_data['date'].max()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2SBQJa7mhNK"
      },
      "outputs": [],
      "source": [
        "# Let's verify what we're actually counting\n",
        "print(\"DATA VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Check the calendar data structure\n",
        "print(\"\\nCalendar data 'available' column values:\")\n",
        "print(f\"  't' (available) count: {(madrid_calendar_data['available'] == 't').sum():,}\")\n",
        "print(f\"  'f' (not available/booked) count: {(madrid_calendar_data['available'] == 'f').sum():,}\")\n",
        "\n",
        "# Check what we're actually summing\n",
        "print(f\"\\nTotal 'booked' flags (where available='f'): {madrid_calendar_data['booked'].sum():,}\")\n",
        "\n",
        "# Check one example listing\n",
        "sample_listing = madrid_calendar_data['listing_id'].iloc[0]\n",
        "sample_data = madrid_calendar_data[madrid_calendar_data['listing_id'] == sample_listing]\n",
        "print(f\"\\nExample listing {sample_listing}:\")\n",
        "print(f\"  Total calendar entries: {len(sample_data)}\")\n",
        "print(f\"  Unavailable days (booked=1): {sample_data['booked'].sum()}\")\n",
        "print(f\"  Available days (booked=0): {(sample_data['booked'] == 0).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6HVQ4MxmhNK"
      },
      "source": [
        "When we sum 'booked' across all listings and dates, we get:\n",
        "  - Total LISTING-DAYS that are unavailable (blocked/booked)\n",
        "  - NOT the number of individual bookings or reservations\n",
        "  - Each property contributes its unavailable days to the total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx_hZLgomhNK"
      },
      "outputs": [],
      "source": [
        "# Create enhanced time series visualization\n",
        "fig, ax = plt.subplots(figsize=(16, 8))\n",
        "\n",
        "city_palette = {'Madrid': COLORS['madrid'], 'Barcelona': COLORS['barcelona']}\n",
        "\n",
        "for city, color in city_palette.items():\n",
        "    city_data = combined_trends[combined_trends['City'] == city]\n",
        "    ax.plot(city_data['date'], city_data['booked'],\n",
        "            color=color, linewidth=2.5, alpha=0.85, label=city, marker='o', markersize=3)\n",
        "\n",
        "ax.set_title('Future Booking Trends: Madrid vs Barcelona',\n",
        "             fontsize=16, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('Date', fontsize=13, fontweight='bold')\n",
        "ax.set_ylabel('Number of Bookings', fontsize=13, fontweight='bold')\n",
        "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{int(x):,}'))\n",
        "ax.grid(True, alpha=0.3, linestyle='--')\n",
        "ax.legend(fontsize=12, frameon=True, shadow=True, loc='upper left')\n",
        "\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZzpFD9dLgi4"
      },
      "source": [
        "**Data Limitations**\n",
        "\n",
        "We're trying to predict future demand by looking at when rooms are available or unavailable. When a room shows as unavailable, we treat it as \"booked.\" But there's a problem: rooms can be unavailable for at least two reasons, either a customer booked it, or the owner chose not to rent it out that day. We can't tell which is which from our data.\n",
        "\n",
        "This is a weakness in our analysis. However, our overall findings should still be useful. We're looking at many properties and bookings, so the few rooms that owners keep for themselves probably don't change the big picture much. The patterns we see should reflect real market behavior, but we need to remember this limitation exists.\n",
        "\n",
        "Additionally, our data shows booking lead time patterns rather than pure demand trends. Our calendar data covers September 2025 to September 2026. Dates at the beginning of this period show higher booking numbers simply because people have had more time to book them in advance. Dates further out (mid 2026) show fewer bookings because most travelers haven't planned that far ahead yet. This creates an artificial decline that doesn't reflect actual demand drops, but rather normal booking behavior where people book closer trips first. This limits how useful this data can be for us.\n",
        "\n",
        "**Booking Timeline Patterns**\n",
        "\n",
        "The high numbers at the start of our timeline reflect normal booking lead times, where properties for September 2025 were booked months in advance. As we move through the calendar, we see seasonal patterns emerge. Spring 2026 (March to May) shows bookings leveling off and starting to climb, indicating tourist season is beginning. Summer 2026 (June to August) has another peak, which makes sense since that's when most people take vacations. The lower numbers toward the end of our timeline (approaching September 2026) simply mean those dates haven't been booked yet, not that demand will be lower.\n",
        "\n",
        "**City Comparison**\n",
        "\n",
        "Madrid has more bookings than Barcelona throughout the year. This might be because Madrid is bigger and attracts both business travelers and tourists all year long, or due to Barcelona's short-term rental limits being stricter. Both cities show similar up-and-down patterns, meaning they follow the same seasonal tourism cycles. The declining trend toward September 2026 in both cities reflects booking lead time, as fewer people have made reservations that far in advance yet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3xfK7OpmhNK"
      },
      "source": [
        "Lets now divide the demand by room type!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkCp5KD8pxO3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Merge calendar data with listings data to include room_type\n",
        "madrid_calendar_data = madrid_calendar_data.merge(\n",
        "    madrid_listings[['id', 'room_type']], left_on='listing_id', right_on='id', how='left'\n",
        ")\n",
        "barcelona_calendar_data = barcelona_calendar_data.merge(\n",
        "    barcelona_listings[['id', 'room_type']], left_on='listing_id', right_on='id', how='left'\n",
        ")\n",
        "\n",
        "# Filter booked properties\n",
        "madrid_calendar_data['booked'] = madrid_calendar_data['available'].apply(lambda x: 1 if x == 'f' else 0)\n",
        "barcelona_calendar_data['booked'] = barcelona_calendar_data['available'].apply(lambda x: 1 if x == 'f' else 0)\n",
        "\n",
        "# Convert the date column to a datetime format\n",
        "madrid_calendar_data['date'] = pd.to_datetime(madrid_calendar_data['date'])\n",
        "barcelona_calendar_data['date'] = pd.to_datetime(barcelona_calendar_data['date'])\n",
        "\n",
        "# Group by date and room type to count the number of bookings\n",
        "madrid_trends_room = madrid_calendar_data.groupby(['date', 'room_type'])['booked'].sum().reset_index()\n",
        "barcelona_trends_room = barcelona_calendar_data.groupby(['date', 'room_type'])['booked'].sum().reset_index()\n",
        "\n",
        "# Plot future booking trends by room type for Madrid\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.lineplot(data=madrid_trends_room, x='date', y='booked', hue='room_type', marker='o', palette='Set2')\n",
        "plt.title('Future Booking Trends by Room Type in Madrid', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Number of Bookings', fontsize=14)\n",
        "plt.legend(title='Room Type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot future booking trends by room type for Barcelona\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.lineplot(data=barcelona_trends_room, x='date', y='booked', hue='room_type', marker='o', palette='Set2')\n",
        "plt.title('Future Booking Trends by Room Type in Barcelona', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=14)\n",
        "plt.ylabel('Number of Bookings', fontsize=14)\n",
        "plt.legend(title='Room Type')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP557P7hmhNL"
      },
      "outputs": [],
      "source": [
        "# VERIFICATION: Check Barcelona room type distribution (SUPPLY)\n",
        "barcelona_room_supply = barcelona_listings['room_type'].value_counts()\n",
        "barcelona_room_supply_pct = barcelona_listings['room_type'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"Barcelona Room Type SUPPLY Distribution:\")\n",
        "print(\"\\nAbsolute counts:\")\n",
        "print(barcelona_room_supply)\n",
        "print(\"\\nPercentages:\")\n",
        "print(barcelona_room_supply_pct)\n",
        "\n",
        "# Check Madrid room type distribution (SUPPLY)\n",
        "madrid_room_supply = madrid_listings['room_type'].value_counts()\n",
        "madrid_room_supply_pct = madrid_listings['room_type'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"\\n\\nMadrid Room Type SUPPLY Distribution:\")\n",
        "print(\"\\nAbsolute counts:\")\n",
        "print(madrid_room_supply)\n",
        "print(\"\\nPercentages:\")\n",
        "print(madrid_room_supply_pct)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHjLBaF0mhNL"
      },
      "outputs": [],
      "source": [
        "# VERIFICATION: Check Barcelona room type DEMAND (bookings)\n",
        "barcelona_demand_by_room = barcelona_trends_room.groupby('room_type')['booked'].sum()\n",
        "barcelona_demand_pct = (barcelona_demand_by_room / barcelona_demand_by_room.sum() * 100)\n",
        "\n",
        "print(\"Barcelona Room Type DEMAND Distribution (Total Bookings):\")\n",
        "print(\"\\nAbsolute counts:\")\n",
        "print(barcelona_demand_by_room)\n",
        "print(\"\\nPercentages:\")\n",
        "print(barcelona_demand_pct)\n",
        "\n",
        "# Check Madrid room type DEMAND (bookings)\n",
        "madrid_demand_by_room = madrid_trends_room.groupby('room_type')['booked'].sum()\n",
        "madrid_demand_pct = (madrid_demand_by_room / madrid_demand_by_room.sum() * 100)\n",
        "\n",
        "print(\"\\n\\nMadrid Room Type DEMAND Distribution (Total Bookings):\")\n",
        "print(\"\\nAbsolute counts:\")\n",
        "print(madrid_demand_by_room)\n",
        "print(\"\\nPercentages:\")\n",
        "print(madrid_demand_pct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Usq5NoDSQAJC"
      },
      "source": [
        "**Room Type Demand Patterns**\n",
        "\n",
        "Entire homes and private rooms dominate bookings in both cities, accounting for over 99% of demand. In Barcelona, entire homes capture 67.7% of bookings while private rooms take 31.4%. Madrid shows a similar pattern with entire homes at 73.4% and private rooms at 25.6%. Shared rooms and hotel rooms barely register, each accounting for less than 1% of bookings combined.\n",
        "\n",
        "**Seasonal Trends and Booking Lead Time**\n",
        "\n",
        "The booking patterns follow the same lead time issue we saw earlier. September 2025 shows high numbers because people booked those dates months in advance. Dates further out in 2026 show lower numbers simply because people haven't booked that far ahead yet. Even with this lead time effect, we can still spot seasonal patterns. Spring 2026 (March to May) and summer 2026 (June to August) show slight increases, confirming these are popular travel times. This graph mainly allows us to compare between different room types, but doesn't support reliable seasonal predictions since we can't safely estimate how bookings will evolve.\n",
        "\n",
        "**Barcelona Market Balance**\n",
        "\n",
        "Barcelona's market shows near-perfect supply-demand alignment. Private rooms represent 30.6% of supply and generate 31.4% of demand, a difference of only 0.8%. Entire homes mirror this balance, accounting for 68.3% of supply and 67.7% of demand. This tight match suggests the market has naturally adjusted to guest preferences.\n",
        "\n",
        "The investment implication is clear: both room types perform well in Barcelona, but there's no significant undersupply creating an obvious opportunity. Investors should focus on execution quality, location, and amenities rather than betting on room type gaps that don't exist. Private rooms may still offer advantages in terms of lower setup costs and operating expenses, but not because of unmet demand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVLGEyvYmhNL"
      },
      "outputs": [],
      "source": [
        "# Filter data for each city from listings (not reviews)\n",
        "madrid_data = combined_listings[combined_listings['City'] == 'Madrid'].copy()\n",
        "barcelona_data = combined_listings[combined_listings['City'] == 'Barcelona'].copy()\n",
        "\n",
        "# Create pivot tables using availability_365 as percentage\n",
        "madrid_heatmap_data = madrid_data.pivot_table(\n",
        "    index='bedrooms',\n",
        "    columns='bathrooms',\n",
        "    values='availability_365',\n",
        "    aggfunc='mean'\n",
        ") / 365 * 100  # Convert to percentage\n",
        "\n",
        "barcelona_heatmap_data = barcelona_data.pivot_table(\n",
        "    index='bedrooms',\n",
        "    columns='bathrooms',\n",
        "    values='availability_365',\n",
        "    aggfunc='mean'\n",
        ") / 365 * 100  # Convert to percentage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igjx3bKwFuqX"
      },
      "outputs": [],
      "source": [
        "# Create pivot tables for number of listings\n",
        "madrid_count_data = madrid_data.pivot_table(\n",
        "    index='bedrooms',\n",
        "    columns='bathrooms',\n",
        "    values='id',\n",
        "    aggfunc='count'\n",
        ")\n",
        "\n",
        "barcelona_count_data = barcelona_data.pivot_table(\n",
        "    index='bedrooms',\n",
        "    columns='bathrooms',\n",
        "    values='id',\n",
        "    aggfunc='count'\n",
        ")\n",
        "\n",
        "# Heatmap for number of listings in Madrid\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(madrid_count_data, annot=True, fmt=\".0f\", cmap='Greens')\n",
        "plt.title('Number of Listings by Bedroom-Bathroom Combinations (Madrid)', fontsize=16)\n",
        "plt.xlabel('Number of Bathrooms', fontsize=14)\n",
        "plt.ylabel('Number of Bedrooms', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Heatmap for number of listings in Barcelona\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(barcelona_count_data, annot=True, fmt=\".0f\", cmap='Greens')\n",
        "plt.title('Number of Listings by Bedroom-Bathroom Combinations (Barcelona)', fontsize=16)\n",
        "plt.xlabel('Number of Bathrooms', fontsize=14)\n",
        "plt.ylabel('Number of Bedrooms', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK9jWwpvmhNL"
      },
      "source": [
        "The following analysis examines occupancy rates by bedroom/bathroom combinations. Due to data limitations where unavailable dates may reflect either bookings or owner decisions, results contain some noise. A minimum threshold of 15 properties per combination is established to avoid bias from uncommon property types that could skew results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRSp38TWmhNL"
      },
      "outputs": [],
      "source": [
        "# Now create availability heatmaps but mask combinations with few listings\n",
        "listing_threshold = 15  # Minimum number of listings to consider data reliable\n",
        "\n",
        "# Align the count data with heatmap data indices\n",
        "madrid_count_aligned = madrid_count_data.reindex_like(madrid_heatmap_data)\n",
        "barcelona_count_aligned = barcelona_count_data.reindex_like(barcelona_heatmap_data)\n",
        "\n",
        "# Create masks for combinations with few listings\n",
        "madrid_mask = madrid_count_aligned < listing_threshold\n",
        "barcelona_mask = barcelona_count_aligned < listing_threshold\n",
        "\n",
        "# Create availability heatmaps with masks\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(madrid_heatmap_data, annot=True, fmt=\".1f\", cmap='Purples',\n",
        "            mask=madrid_mask,\n",
        "            cbar_kws={'label': 'Availability %'})\n",
        "plt.title('Availability Percentage - Madrid (≥15 listings only)', fontsize=16)\n",
        "plt.xlabel('Number of Bathrooms', fontsize=14)\n",
        "plt.ylabel('Number of Bedrooms', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(barcelona_heatmap_data, annot=True, fmt=\".1f\", cmap='Purples',\n",
        "            mask=barcelona_mask,\n",
        "            cbar_kws={'label': 'Availability %'})\n",
        "plt.title('Availability Percentage - Barcelona (≥15 listings only)', fontsize=16)\n",
        "plt.xlabel('Number of Bathrooms', fontsize=14)\n",
        "plt.ylabel('Number of Bedrooms', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCMBm0cxIm_r"
      },
      "source": [
        "Lower availability values indicate better performance because they mean the property is unavailable more often (either booked or intentionally blocked). The number of listings tells us how competitive a configuration is and whether the sample size is large enough to trust any pattern.\n",
        "\n",
        "**Madrid Market**\n",
        "\n",
        "Madrid is heavily concentrated in standard layouts. The 1 bedroom / 1 bathroom category dominates the entire market with approximately **9,815 listings**, far more than any other configuration. The next major clusters are 2 bedroom / 1 bathroom (around 1,992 listings) and 2 bedroom / 2 bathroom (around 1,555 listings).\n",
        "\n",
        "Availability values for mainstream configurations (1 to 3 bedrooms, 1 to 2 bathrooms) fall within a **narrow band of roughly 4.5 to 4.8**, with only small differences between them. This indicates that bedroom and bathroom configuration has **minimal influence** on occupancy for typical investor-friendly property types. The very lowest availability values (around 4.1 to 4.3) occur in rare, small-sample combinations, and therefore should not drive investment decisions.\n",
        "\n",
        "Madrid's data shows stable performance across standard units. Large properties (4+ bedrooms) sometimes show lower availability in isolated cells, but the listing counts are too small to be reliable. Scarcity appears to help some of these categories, but not consistently enough to support a strategic bet.\n",
        "\n",
        "**Barcelona Market**\n",
        "\n",
        "Barcelona also exhibits strong concentration in standard layouts, but with a more balanced spread across 1 to 3 bedroom categories. The largest cluster is **1 bedroom / 1 bathroom (around 5,340 listings)**, followed by **2 bedrooms / 1 bathroom (around 2,531)**. Importantly, **3 bedrooms / 2 bathrooms (around 1,311)** is a meaningful, well-represented segment in Barcelona, much more than in Madrid, making it a viable mainstream category rather than a niche.\n",
        "\n",
        "Availability values in Barcelona range from **4.3 to 4.7** for almost all common bedroom and bathroom combinations. This extremely tight band reflects **consistent occupancy performance across typical units**. Bathroom count has only marginal effects in Barcelona. Differences of 0.1 on the availability scale are not large enough to be considered strategic. As in Madrid, large configurations with few listings display more volatility but are unreliable for decision-making.\n",
        "\n",
        "**The Big Picture**\n",
        "\n",
        "Standard configurations dominate supply in both cities, and they all perform similarly in terms of availability. The data does *not* support strong claims that specific bathroom counts or exotic layouts meaningfully improve occupancy. The slight variations visible in the heatmaps are small, and many of the lowest availability cells are driven by rare categories with insufficient sample sizes.\n",
        "\n",
        "Scarcity alone does not guarantee superior performance. In Madrid, some rare large units look better on paper, but the patterns are unstable and expensive to enter. In Barcelona, scarcity has no consistent positive effect at all. The structural demand in both markets is shaped by mainstream travel patterns: short stays, couples, families, and small groups, not by luxury layouts.\n",
        "\n",
        "**What This Means for Investors**\n",
        "\n",
        "In Madrid, the most attractive risk-adjusted opportunities are in the **2 bedroom categories**. Both 2 bed / 1 bath and 2 bed / 2 bath sit in large, proven segments with stable performance and noticeably less saturation than the hyper-competitive 1 bed / 1 bath market. They offer broad guest appeal without the drawbacks of rare, capital-intensive formats. The small differences in availability (around 4.6 to 4.7) are not decisive, so price, location, and execution should drive the choice between 1 or 2 bathrooms.\n",
        "\n",
        "In Barcelona, investors should avoid the extremely competitive **1 bed / 1 bath** market but also avoid overspending on luxury bathroom upgrades. The strongest, most balanced segments are **2 to 3 bedroom units**, particularly **2 bed / 1 bath**, **3 bed / 1 bath**, and **3 bed / 2 bath**, which all show stable availability around 4.5 to 4.6 and have robust listing counts confirming real market depth. These configurations serve families and groups, a large segment of leisure-driven Barcelona demand, without falling into niche territory or unnecessary amenity inflation.\n",
        "\n",
        "Overall, the optimal strategy is to position within the broad, high-demand middle of each market rather than chasing rare outliers or overcrowded entry-level segments. These categories offer the best balance of occupancy stability, competition, and capital requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsVyeullUPa3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure 'date' column is in object format and convert it to datetime for filtering\n",
        "madrid_calendar_data['date'] = pd.to_datetime(madrid_calendar_data['date'], errors='coerce')\n",
        "barcelona_calendar_data['date'] = pd.to_datetime(barcelona_calendar_data['date'], errors='coerce')\n",
        "\n",
        "# Filter for the past year\n",
        "one_year_ago = pd.Timestamp.now() - pd.DateOffset(years=1)\n",
        "madrid_last_year = madrid_calendar_data[madrid_calendar_data['date'] >= one_year_ago]\n",
        "barcelona_last_year = barcelona_calendar_data[barcelona_calendar_data['date'] >= one_year_ago]\n",
        "\n",
        "# Filter booked properties (assuming 'available' column has 'f' for booked)\n",
        "madrid_last_year['booked'] = madrid_last_year['available'].apply(lambda x: 1 if x == 'f' else 0)\n",
        "barcelona_last_year['booked'] = barcelona_last_year['available'].apply(lambda x: 1 if x == 'f' else 0)\n",
        "\n",
        "# Merge calendar data with listings to get room type\n",
        "madrid_with_room_type = madrid_last_year.merge(madrid_listings[['id', 'room_type']], left_on='listing_id', right_on='id', how='left')\n",
        "barcelona_with_room_type = barcelona_last_year.merge(barcelona_listings[['id', 'room_type']], left_on='listing_id', right_on='id', how='left')\n",
        "\n",
        "# Calculate occupancy metrics by room type\n",
        "# For each room type, we need: total unavailable days, total possible days, and occupancy rate\n",
        "\n",
        "# Madrid metrics\n",
        "madrid_metrics = madrid_with_room_type.groupby('room_type_x').agg({\n",
        "    'booked': 'sum',  # Total unavailable days\n",
        "    'listing_id': 'count'  # Total listing-days (each row is one listing-day)\n",
        "}).reset_index()\n",
        "madrid_metrics['occupancy_rate'] = (madrid_metrics['booked'] / madrid_metrics['listing_id'] * 100).round(2)\n",
        "madrid_metrics['num_properties'] = madrid_with_room_type.groupby('room_type_x')['listing_id'].nunique().values\n",
        "madrid_metrics.columns = ['Room Type', 'Total Unavailable Days', 'Total Listing-Days', 'Occupancy Rate (%)', 'Number of Properties']\n",
        "\n",
        "# Barcelona metrics\n",
        "barcelona_metrics = barcelona_with_room_type.groupby('room_type_y').agg({\n",
        "    'booked': 'sum',\n",
        "    'listing_id': 'count'\n",
        "}).reset_index()\n",
        "barcelona_metrics['occupancy_rate'] = (barcelona_metrics['booked'] / barcelona_metrics['listing_id'] * 100).round(2)\n",
        "barcelona_metrics['num_properties'] = barcelona_with_room_type.groupby('room_type_y')['listing_id'].nunique().values\n",
        "barcelona_metrics.columns = ['Room Type', 'Total Unavailable Days', 'Total Listing-Days', 'Occupancy Rate (%)', 'Number of Properties']\n",
        "\n",
        "# Create comparison dataframe with occupancy rates\n",
        "combined_demand = pd.DataFrame({\n",
        "    'Room Type': madrid_metrics['Room Type'],\n",
        "    'Occupancy Rate Madrid (%)': madrid_metrics['Occupancy Rate (%)'],\n",
        "    'Occupancy Rate Barcelona (%)': barcelona_metrics['Occupancy Rate (%)'],\n",
        "    'Properties Madrid': madrid_metrics['Number of Properties'],\n",
        "    'Properties Barcelona': barcelona_metrics['Number of Properties']\n",
        "})\n",
        "\n",
        "# Display the comparison\n",
        "print(\"OCCUPANCY RATE COMPARISON BY ROOM TYPE\")\n",
        "print(\"=\" * 80)\n",
        "print(combined_demand.to_string(index=False))\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Note: Occupancy Rate = (Unavailable Days / Total Days) × 100\")\n",
        "print(\"Higher rate = Better performance (more days booked/blocked)\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU8E-AyemhNM"
      },
      "outputs": [],
      "source": [
        "# Prepare data for visualization\n",
        "occupancy_melted = combined_demand.melt(\n",
        "    id_vars='Room Type',\n",
        "    value_vars=['Occupancy Rate Madrid (%)', 'Occupancy Rate Barcelona (%)'],\n",
        "    var_name='City',\n",
        "    value_name='Occupancy Rate (%)'\n",
        ")\n",
        "occupancy_melted['City'] = occupancy_melted['City'].str.replace('Occupancy Rate ', '').str.replace(' (%)', '')\n",
        "\n",
        "# Create dual visualization: Occupancy Rate + Property Count\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "fig.suptitle(\"Room Type Performance Analysis (Sep 2025 - Sep 2026)\", fontsize=18, fontweight='bold', y=1.02)\n",
        "\n",
        "# Plot 1: Occupancy Rate Comparison\n",
        "city_colors = {'Madrid': COLORS['madrid'], 'Barcelona': COLORS['barcelona']}\n",
        "bar_plot1 = sns.barplot(data=occupancy_melted, x='Room Type', y='Occupancy Rate (%)', hue='City',\n",
        "                        palette=city_colors, ax=ax1, alpha=0.85, edgecolor='white', linewidth=2)\n",
        "\n",
        "ax1.set_title('Occupancy Rate by Room Type', fontsize=14, fontweight='bold', pad=15)\n",
        "ax1.set_ylabel(\"Occupancy Rate (%)\", fontsize=12, fontweight='bold')\n",
        "ax1.set_xlabel(\"Room Type\", fontsize=12, fontweight='bold')\n",
        "ax1.set_ylim(0, 100)\n",
        "ax1.tick_params(axis='x', rotation=45)\n",
        "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax1.legend(title='City', fontsize=10)\n",
        "\n",
        "# Add value labels on bars\n",
        "for container in ax1.containers:\n",
        "    labels = [f'{v.get_height():.1f}%' if v.get_height() > 0 else '' for v in container]\n",
        "    ax1.bar_label(container, labels=labels, padding=3, fontsize=9, fontweight='bold')\n",
        "\n",
        "# Plot 2: Number of Properties (for context)\n",
        "properties_melted = combined_demand.melt(\n",
        "    id_vars='Room Type',\n",
        "    value_vars=['Properties Madrid', 'Properties Barcelona'],\n",
        "    var_name='City',\n",
        "    value_name='Number of Properties'\n",
        ")\n",
        "properties_melted['City'] = properties_melted['City'].str.replace('Properties ', '')\n",
        "\n",
        "bar_plot2 = sns.barplot(data=properties_melted, x='Room Type', y='Number of Properties', hue='City',\n",
        "                        palette=city_colors, ax=ax2, alpha=0.85, edgecolor='white', linewidth=2)\n",
        "\n",
        "ax2.set_title('Supply: Number of Properties by Type', fontsize=14, fontweight='bold', pad=15)\n",
        "ax2.set_ylabel(\"Number of Properties\", fontsize=12, fontweight='bold')\n",
        "ax2.set_xlabel(\"Room Type\", fontsize=12, fontweight='bold')\n",
        "ax2.tick_params(axis='x', rotation=45)\n",
        "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
        "ax2.legend(title='City', fontsize=10)\n",
        "\n",
        "# Add value labels on bars\n",
        "for container in ax2.containers:\n",
        "    labels = [f'{int(v.get_height()):,}' if v.get_height() > 0 else '' for v in container]\n",
        "    ax2.bar_label(container, labels=labels, padding=3, fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"• Occupancy Rate = Percentage of days that are unavailable (booked or blocked)\")\n",
        "print(\"• Higher occupancy = Better performance for that room type\")\n",
        "print(\"• Number of Properties = Total supply in each category\")\n",
        "print(\"• High occupancy + Low supply = Potential investment opportunity\")\n",
        "print(\"• Low occupancy + High supply = Saturated/competitive market\")\n",
        "print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePt83qSrmhNM"
      },
      "source": [
        "We can see:\n",
        "1. Madrid outperforms Barcelona by 1-10 percentage points across all room types (42% vs 37% for entire homes).\n",
        "\n",
        "2. Room type has minimal impact on occupancy within each city, all types cluster within 3% of each other."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ETY1SQcmhNM"
      },
      "source": [
        "## Section 2 Main Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snaDF2QGUHWd"
      },
      "source": [
        "**1. Supply Structure and Market Maturity**\n",
        "\n",
        "Both markets are dominated by standardized formats. Entire homes and private rooms account for 98% of inventory in both cities. Madrid leans more toward entire homes (72% of supply, 13,516 listings) while Barcelona is slightly more balanced (68% entire homes, 30% private rooms). This concentration means competition happens in mainstream segments, not niche formats. Hotel rooms and shared rooms are statistically irrelevant for investment decisions.\n",
        "\n",
        "**2. Room Type Performance: Quality Over Category**\n",
        "\n",
        "Average ratings cluster tightly between 4.5 and 5.0 across all room types, making mean scores poor differentiators. The real separation appears in success rates (properties achieving 4.5+ ratings):\n",
        "\n",
        "- Barcelona hotel rooms lead at 88% success rate, benefiting from professional operations and prime locations\n",
        "- Entire homes and private rooms perform similarly across both cities (73-80% success rates)\n",
        "- Shared rooms consistently underperform (64-65% success rates), reflecting structural disadvantages rather than poor execution\n",
        "\n",
        "**3. Supply-Demand Balance: No Obvious Gaps**\n",
        "\n",
        "Both cities show near-perfect alignment between supply and demand by room type. Entire homes capture 68-73% of bookings and represent 68-72% of supply. Private rooms account for 26-31% of bookings and 27-31% of supply. The market has naturally adjusted. There is no undersupplied room type to exploit. Any investment thesis built on \"private rooms are underserved\" or \"entire homes are oversaturated\" contradicts the data.\n",
        "\n",
        "**4. Occupancy Reality: Madrid Outperforms, Room Type Doesn't Matter Much**\n",
        "\n",
        "Madrid achieves 4-5 percentage points higher occupancy than Barcelona across all room types (42% vs 37% for entire homes). Within each city, room type makes minimal difference. Occupancy rates cluster within 3% of each other regardless of format. This means location, pricing, and execution quality drive occupancy far more than room type selection.\n",
        "\n",
        "**5. Amenities: Necessary but Not Sufficient**\n",
        "\n",
        "Ratings improve with amenity count up to roughly 30-60 amenities, then flatten. More amenities cannot rescue a poorly located or poorly managed property. The pattern breaks down into tiers:\n",
        "\n",
        "- Baseline amenities (WiFi, kitchen, hot water, dishes) are expected. Their presence doesn't boost ratings, but their absence significantly hurts performance.\n",
        "- Convenience amenities (hangers, hair dryer, iron, microwave, essentials) correlate with higher ratings. These are low-cost additions with measurable impact.\n",
        "- Premium amenities (elevator, A/C, heating, shampoo, workspace) appear in higher-priced listings, but this reflects building quality and location rather than the amenity itself adding value.\n",
        "\n",
        "**6. Size and Price Are Decoupled from Guest Satisfaction**\n",
        "\n",
        "Beds and guest capacity correlate strongly with each other (0.71) but show virtually no relationship with ratings (0.06-0.11). Price also shows near-zero correlation with ratings (0.06). Translation: guests don't rate properties higher because they're bigger or more expensive. They rate based on whether the property meets expectations for cleanliness, functionality, and experience.\n",
        "\n",
        "**7. Configuration Optimization Is Overrated**\n",
        "\n",
        "Heatmaps show near-flat availability across common configurations (1-3 bedrooms, 1-2 bathrooms). Availability differences of 0.1-0.2 points are not strategically meaningful. The few cells showing exceptional performance have tiny sample sizes or represent edge cases. Don't over-invest in extra bathrooms expecting meaningful occupancy or rating improvements. The data doesn't support it.\n",
        "\n",
        "**8. Investment Implications**\n",
        "\n",
        "**Madrid:** The 1 bedroom / 1 bathroom segment is brutally competitive with 9,815 listings. Better risk-adjusted opportunities exist in 2 bedroom configurations (either 1 or 2 bathrooms), which show stable performance with less saturation. The market rewards standard family-friendly units, not luxury upgrades.\n",
        "\n",
        "**Barcelona:** No room type arbitrage exists. Success requires execution quality in prime locations, not betting on format gaps. The strongest segments are 2-3 bedroom units (particularly 2 bed / 1 bath and 3 bed / 2 bath), which serve families and groups without falling into oversaturated studio territory or overpriced luxury segments.\n",
        "\n",
        "**Cross-City Pattern:** The winning strategy is \"mainstream configuration + strong operations + smart amenity baseline,\" not chasing rare layouts or amenity overkill. Both markets are mature and balanced. Structural arbitrage opportunities don't exist. Competitive advantage must come from disciplined acquisition, location selection, and operations that consistently meet guest expectations.\n",
        "\n",
        "Important note: This section eliminates common investor fantasies: exploiting room type gaps, betting on exotic configurations, or winning through amenity arms races. The market has already optimized around mainstream formats and guest preferences. If you want an edge, it must come from superior execution in property selection, pricing strategy, and guest experience delivery, not from format arbitrage that the data proves doesn't exist."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 3. Geographic Analysis**"
      ],
      "metadata": {
        "id": "CcbBf4k8Vzpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use this section to compare Madrid and Barcelona from a geographic point of view. We want to:\n",
        "- find micro-markets (clusters) inside each city.\n",
        "- measure how price behaves with distance to the city center.\n",
        "- see how density (many listings close together) affects price and availability.\n",
        "- show interactive maps to explore results.\n",
        "\n",
        "\n",
        "**Notes/Assumptions:**\n",
        "- **We use the cleaned dataframe from Section 1** (`combined_listings` or `listings_first_clean`) so we don't repeat cleaning.\n",
        "- **We assume that the median latitude and longitude represent the “city center”.**  \n",
        "   This is a simple and robust way to estimate the center, but real city centers may not be perfectly located at the statistical median.\n",
        "- **We assume distance affects price in a mostly monotonic way.**  \n",
        "   In reality, some areas outside the pure center may also be premium (e.g., beaches in Barcelona or specific tourist corridors).\n",
        "- **We assume K-Means is a reasonable way to detect spatial micro-markets.**  \n",
        "   K-Means does not use neighbourhood borders or socio-economic data, but it gives us objective location-based clusters.\n",
        "- **We assume 8 clusters per city is enough for interpretation.**  \n",
        "   This is not the “optimal” number, but it is easy to understand and present. More clusters would make reading results harder.\n",
        "- **We assume tile-based density (rounding lat/lon) is a good approximation.**  \n",
        "   This creates simple grid cells that help us measure how many listings exist in small areas. It is not a perfect measure of real population or tourism demand."
      ],
      "metadata": {
        "id": "RWMLtgmnV087"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Imports and simple checks"
      ],
      "metadata": {
        "id": "K4yi2ehEYdxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import folium\n",
        "from folium.plugins import MarkerCluster\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "# Use of cleaned data prepared by in Section 1\n",
        "if 'combined_listings' in globals():\n",
        "    df = combined_listings.copy()\n",
        "elif 'listings_first_clean' in globals():\n",
        "    df = listings_first_clean.copy()\n",
        "else:\n",
        "    raise RuntimeError(\"Cannot find `combined_listings` or `listings_first_clean`. Run Section 1 first.\")\n",
        "\n",
        "# Split by city\n",
        "madrid = df[df['City'] == 'Madrid'].copy()\n",
        "barcelona = df[df['City'] == 'Barcelona'].copy()\n",
        "\n",
        "print(f\"Madrid listings: {len(madrid):,}\")\n",
        "print(f\"Barcelona listings: {len(barcelona):,}\")\n"
      ],
      "metadata": {
        "id": "z0TlOgTjYqXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We confirmed the cleaned dataset exists and prepared subsets divided by city so all comparisons are fair."
      ],
      "metadata": {
        "id": "prqkOIBFY63b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Spatial clustering"
      ],
      "metadata": {
        "id": "jhDJ7O-5Y8iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We cluster coordinates to find spatial micro-markets in each city\n",
        "def cluster_city_simple(gdf, k=8, random_state=42):\n",
        "    g = gdf.dropna(subset=['latitude','longitude']).copy()\n",
        "    coords = g[['longitude','latitude']].values\n",
        "    scaler = StandardScaler()\n",
        "    coords_scaled = scaler.fit_transform(coords)\n",
        "    kmeans = KMeans(n_clusters=k, random_state=random_state, n_init='auto')\n",
        "    labels = kmeans.fit_predict(coords_scaled)\n",
        "    g['cluster'] = labels\n",
        "    # centroids in original coords\n",
        "    centroids = scaler.inverse_transform(kmeans.cluster_centers_)\n",
        "    centroids_df = pd.DataFrame(centroids, columns=['longitude','latitude'])\n",
        "    centroids_df['cluster'] = range(k)\n",
        "    return g, centroids_df\n",
        "\n",
        "madrid_k, madrid_centroids = cluster_city_simple(madrid, k=8)\n",
        "barca_k,  barca_centroids  = cluster_city_simple(barcelona, k=8)\n",
        "print(\"Clusters created: Madrid\", madrid_k['cluster'].nunique(), \"Barcelona\", barca_k['cluster'].nunique())\n"
      ],
      "metadata": {
        "id": "kNINqRavZH8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use k=8 to keep clusters easy to explain."
      ],
      "metadata": {
        "id": "D6ISTJcvZPPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cluster_summary(g):\n",
        "    return (g.groupby('cluster')\n",
        "             .agg(n_listings=('id','count'),\n",
        "                  avg_price=('price','mean'),\n",
        "                  median_price=('price','median'),\n",
        "                  avg_price_pp=('price_per_person','mean'))\n",
        "             .reset_index().sort_values('avg_price', ascending=False))\n",
        "\n",
        "madrid_cluster_summary = cluster_summary(madrid_k)\n",
        "barca_cluster_summary  = cluster_summary(barca_k)\n",
        "\n",
        "print(\"Madrid cluster summary (top):\")\n",
        "display(madrid_cluster_summary.round(2))\n",
        "print(\"Barcelona cluster summary (top):\")\n",
        "display(barca_cluster_summary.round(2))\n"
      ],
      "metadata": {
        "id": "34BFKXlZZY_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We summarize clusters, seeing how many listings are there and the average prices per cluster."
      ],
      "metadata": {
        "id": "qXYve6lsZb_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1: Conclusion**\n",
        "By creating 8 clusters per city, we basically divided both Madrid and Barcelona into “mini-markets” based only on location. This is useful because prices are not random across the map—they concentrate in certain areas. What we found is that Barcelona has more compact premium clusters, meaning that expensive listings tend to be grouped around specific tourist-heavy areas (like the Gothic Quarter or Eixample). Madrid, on the other hand, shows a more spread-out structure: we still have expensive clusters, but they are mixed with mid-priced ones and tend to cover a larger area of the city.\n",
        "\n",
        "This tells us that Barcelona is more segmented and tourism-driven, while Madrid is more mixed and less concentrated. For investors, this means choosing exactly which cluster you want to enter is important, because performance can change a lot even if two listings are not far apart."
      ],
      "metadata": {
        "id": "MGfIDSgnZkAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Central vs non-central behavior"
      ],
      "metadata": {
        "id": "VDaLcw4vZwoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Haversine function to get distance in km\n",
        "def haversine_array(lon1, lat1, lon2, lat2):\n",
        "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
        "    c = 2 * np.arcsin(np.sqrt(a))\n",
        "    return 6371 * c\n",
        "\n",
        "# Estimate city center as median lat/lon of listings (simple and robust)\n",
        "center_madrid = (madrid_k['latitude'].median(), madrid_k['longitude'].median())\n",
        "center_barca  = (barca_k['latitude'].median(),  barca_k['longitude'].median())\n",
        "\n",
        "# Compute distances\n",
        "madrid_k['dist_km'] = haversine_array(madrid_k['longitude'].values, madrid_k['latitude'].values,\n",
        "                                     center_madrid[1], center_madrid[0])\n",
        "barca_k['dist_km']  = haversine_array(barca_k['longitude'].values, barca_k['latitude'].values,\n",
        "                                     center_barca[1], center_barca[0])\n",
        "\n",
        "# Define zones (central <=2km, near 2-5km, periphery >5km)\n",
        "bins = [-1, 2, 5, 1e6]\n",
        "labels = ['central','near','periphery']\n",
        "madrid_k['zone'] = pd.cut(madrid_k['dist_km'], bins=bins, labels=labels)\n",
        "barca_k['zone']  = pd.cut(barca_k['dist_km'], bins=bins, labels=labels)\n"
      ],
      "metadata": {
        "id": "OH9RLJrLaD-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compute distance to city center (haversine) and define zones, based on average distances."
      ],
      "metadata": {
        "id": "xf0C0uaOaGzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def zone_stats(g):\n",
        "    return g.groupby('zone').agg(\n",
        "        n_listings=('id','count'),\n",
        "        avg_price=('price','mean'),\n",
        "        median_price=('price','median'),\n",
        "        avg_price_pp=('price_per_person','mean')\n",
        "    ).reset_index()\n",
        "\n",
        "print(\"Madrid zone stats:\")\n",
        "display(zone_stats(madrid_k).round(2))\n",
        "print(\"Barcelona zone stats:\")\n",
        "display(zone_stats(barca_k).round(2))\n"
      ],
      "metadata": {
        "id": "8O0AC_Dnaq04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe zone stats and compare them."
      ],
      "metadata": {
        "id": "-yWGH3Zgash4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(9,5))\n",
        "plt.scatter(madrid_k['dist_km'], madrid_k['price'], s=8, alpha=0.25, label='Madrid')\n",
        "plt.scatter(barca_k['dist_km'], barca_k['price'], s=8, alpha=0.25, label='Barcelona')\n",
        "plt.xlabel('Distance to Center (km)')\n",
        "plt.ylabel('Price (€)')\n",
        "plt.title('Price vs Distance to Center: Madrid vs Barcelona')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gcPUABhAayb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We plot price vs distance for both cities, using simple scatter and median trend."
      ],
      "metadata": {
        "id": "f5D3-f7sazXL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2: Conclusion**\n",
        "Measuring distance to the center helped us quantify how much “centrality” actually affects price. As expected, the closer you are to the center, the more expensive listings get. But the interesting part is how differently this happens in each city.\n",
        "\n",
        "In Madrid, prices drop almost immediately once you move outside the core. The “central” zone (within 2 km) has a clear premium, but the “near” zone (2–5 km) already loses a lot of value. Barcelona behaves differently: prices remain high even at 3–5 km away, probably because many important tourist areas are not strictly in the geometric center.\n",
        "\n",
        "This means Barcelona offers profitable opportunities slightly outside the center, while Madrid strongly rewards ultra-central properties. Investors targeting Madrid need to be precise with location; investors in Barcelona have more flexibility while still capturing strong demand."
      ],
      "metadata": {
        "id": "1VZzJIjabDib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Density vs performance"
      ],
      "metadata": {
        "id": "1SymTlAPbK9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tile the map by rounding lat/lon\n",
        "def make_grid(g, precision=3):\n",
        "    g2 = g.copy()\n",
        "    g2['lat_tile'] = g2['latitude'].round(precision)\n",
        "    g2['lon_tile'] = g2['longitude'].round(precision)\n",
        "    grid = g2.groupby(['lat_tile','lon_tile']).agg(\n",
        "        n_listings=('id','count'),\n",
        "        median_price=('price','median'),\n",
        "        avg_availability=('availability_365','mean')\n",
        "    ).reset_index()\n",
        "    return grid\n",
        "\n",
        "madrid_grid = make_grid(madrid_k, precision=3)\n",
        "barca_grid  = make_grid(barca_k, precision=3)\n",
        "\n",
        "print(\"Top Madrid tiles by listings:\")\n",
        "display(madrid_grid.nlargest(8,'n_listings').round(2))\n",
        "print(\"Top Barcelona tiles by listings:\")\n",
        "display(barca_grid.nlargest(8,'n_listings').round(2))\n"
      ],
      "metadata": {
        "id": "SwjTBWEZbgEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We divide the city into small grid tiles by rounding latitude and longitude, and then measure how many listings and what median prices appear in each tile to understand how local density affects performance."
      ],
      "metadata": {
        "id": "7kkrIuD9bQcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def density_corr(grid):\n",
        "    return grid['n_listings'].corr(grid['median_price']), grid['n_listings'].corr(grid['avg_availability'])\n",
        "\n",
        "madrid_corr_price, madrid_corr_av = density_corr(madrid_grid)\n",
        "barca_corr_price, barca_corr_av = density_corr(barca_grid)\n",
        "\n",
        "print(\"Madrid: corr(listings, median_price) =\", round(madrid_corr_price,3), \"corr(listings, availability) =\", round(madrid_corr_av,3))\n",
        "print(\"Barcelona:\", \"corr(listings, median_price) =\", round(barca_corr_price,3), \"corr(listings, availability) =\", round(barca_corr_av,3))\n"
      ],
      "metadata": {
        "id": "DmOk_lvxb6SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We find the correlations between density and price/availability."
      ],
      "metadata": {
        "id": "h9lT-tqNb805"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3: Conclusion**\n",
        "By dividing the city into small grid tiles of around 100 meters and counting how many listings fall into each tile, we can understand how crowded different areas are. When we compared density with median price, we found an important difference between cities.\n",
        "\n",
        "In Madrid, high density seems to push prices down, which suggests listings in crowded zones face heavy competition. This can also explain why availability is higher in these dense areas: hosts may struggle more to fill their calendar because guests have too many options.\n",
        "\n",
        "In Barcelona, it’s almost the opposite: some of the densest tiles are also the most expensive ones. That means being surrounded by many other listings is not a bad thing there—those areas are simply very strong tourist magnets and supply is high because demand is even higher.\n",
        "\n",
        "For investors, this means:\n",
        "\n",
        "- In Madrid, be careful with very dense areas—they may lower your revenue potential.\n",
        "\n",
        "- In Barcelona, density can be a sign of a healthy high-demand micro-market."
      ],
      "metadata": {
        "id": "TCNTVxiYb_tU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Maps and visual output"
      ],
      "metadata": {
        "id": "KUqumqc4ciSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AI-helped. prompt: create a simple interactive map and save it as HTML\n",
        "def make_map(g, centroids, center, fname):\n",
        "    m = folium.Map(location=[center[0], center[1]], zoom_start=12)\n",
        "    # add centroids\n",
        "    for _, r in centroids.iterrows():\n",
        "        folium.CircleMarker(location=[r['latitude'], r['longitude']],\n",
        "                            radius=6, color='black', fill=True).add_to(m)\n",
        "    # add sample listings\n",
        "    sample = g.sample(min(2000, len(g)), random_state=42)\n",
        "    mc = MarkerCluster().add_to(m)\n",
        "    for _, r in sample.iterrows():\n",
        "        folium.CircleMarker(location=[r['latitude'], r['longitude']],\n",
        "                            radius=3,\n",
        "                            popup=f\"Price: €{r['price']:.0f} | Cluster: {int(r['cluster'])}\",\n",
        "                            fill=True).add_to(mc)\n",
        "    m.save(fname)\n",
        "    return m\n",
        "\n",
        "madrid_map = make_map(madrid_k, madrid_centroids, (madrid_k['latitude'].median(), madrid_k['longitude'].median()), \"madrid_clusters.html\")\n",
        "barca_map  = make_map(barca_k,  barca_centroids,  (barca_k['latitude'].median(),  barca_k['longitude'].median()),  \"barcelona_clusters.html\")\n",
        "\n",
        "print(\"Maps saved: madrid_clusters.html and barcelona_clusters.html (open them in browser)\")\n"
      ],
      "metadata": {
        "id": "mbs_Xckjcm-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a folium map with cluster centroids and a sample of listings."
      ],
      "metadata": {
        "id": "hKIA8k76cyhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AI-helped: Do neighbourhood choropleths for Madrid and Barcelona\n",
        "\n",
        "# 1. Prepare neighbourhood stats for Madrid\n",
        "madrid_nb_stats = (\n",
        "    madrid_k\n",
        "    .groupby('neighbourhood_cleansed')\n",
        "    .agg(avg_price=('price','mean'))\n",
        "    .reset_index()\n",
        ")\n",
        "display(madrid_neighbourhoods_geo.head())\n",
        "\n",
        "madrid_geo_merged = madrid_neighbourhoods_geo.merge(\n",
        "    madrid_nb_stats,\n",
        "    left_on='neighbourhood',\n",
        "    right_on='neighbourhood_cleansed',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 2. Create Madrid choropleth\n",
        "madrid_map_nb = folium.Map(\n",
        "    location=[madrid_k['latitude'].median(), madrid_k['longitude'].median()],\n",
        "    zoom_start=12\n",
        ")\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=madrid_geo_merged.to_json(),\n",
        "    data=madrid_geo_merged,\n",
        "    columns=['neighbourhood', 'avg_price'],\n",
        "    key_on='feature.properties.neighbourhood',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name='Average Price (Madrid Neighbourhoods)'\n",
        ").add_to(madrid_map_nb)\n",
        "\n",
        "madrid_map_nb.save(\"madrid_neighbourhoods_choropleth.html\")\n",
        "print(\"Saved: madrid_neighbourhoods_choropleth.html\")\n",
        "\n",
        "\n",
        "\n",
        "# 3. Prepare neighbourhood stats for Barcelona\n",
        "barca_nb_stats = (\n",
        "    barca_k\n",
        "    .groupby('neighbourhood_cleansed')\n",
        "    .agg(avg_price=('price','mean'))\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "display(barcelona_neighbourhoods_geo.head())\n",
        "\n",
        "barca_geo_merged = barcelona_neighbourhoods_geo.merge(\n",
        "    barca_nb_stats,\n",
        "    left_on='neighbourhood',\n",
        "    right_on='neighbourhood_cleansed',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# 4. Create Barcelona choropleth\n",
        "barca_map_nb = folium.Map(\n",
        "    location=[barca_k['latitude'].median(), barca_k['longitude'].median()],\n",
        "    zoom_start=12\n",
        ")\n",
        "\n",
        "folium.Choropleth(\n",
        "    geo_data=barca_geo_merged.to_json(),\n",
        "    data=barca_geo_merged,\n",
        "    columns=['neighbourhood', 'avg_price'],\n",
        "    key_on='feature.properties.neighbourhood',\n",
        "    fill_opacity=0.7,\n",
        "    line_opacity=0.2,\n",
        "    legend_name='Average Price (Barcelona Neighbourhoods)'\n",
        ").add_to(barca_map_nb)\n",
        "\n",
        "barca_map_nb.save(\"barcelona_neighbourhoods_choropleth.html\")\n",
        "print(\"Saved: barcelona_neighbourhoods_choropleth.html\")\n"
      ],
      "metadata": {
        "id": "PMcWEaN4dfYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We created neighbourhood choropleths for both Madrid and Barcelona. Both maps are exported as: \"madrid_neighbourhoods_choropleth.html\" and \"barcelona_neighbourhoods_choropleth.html\" and can be opened directly in the browser."
      ],
      "metadata": {
        "id": "Ori_fcYpeUrO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4: Conclusions**\n",
        "The interactive maps helped us validate all the patterns we saw in the numbers. In the Madrid map, clusters are more spread out and you can clearly see the difference between the city core and the rest. In the Barcelona map, high-price clusters appear more concentrated and form a tight ring around the main tourist districts.\n",
        "\n",
        "These maps also make it easier to visually compare cluster boundaries, identify hotspots, and even spot anomalies in the data. Choropleth maps (based on neighbourhoods) give a more “official” geographic structure."
      ],
      "metadata": {
        "id": "h-drvKZUe4e8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Conclusions (Section 3)"
      ],
      "metadata": {
        "id": "h0jD-_5pfcp0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After studying the geographic patterns of both cities, we can say that location explains a big part of the differences in pricing and attractiveness inside Madrid and Barcelona. Even though both cities are strong tourism hubs, they behave differently once we look at them block by block instead of treating the whole city as a single market.\n",
        "\n",
        "**1. Micro-markets are real and matter a lot.**  \n",
        "The K-Means clustering showed that both cities break into smaller “hot zones” where hosts achieve way better performance than the rest. In Barcelona these premium pockets are more concentrated and closer to the traditional tourist districts. In Madrid, high-value clusters exist too, but they are more spread out and mixed with medium-priced ones. This means that investors should not rely only on city averages but instead decide exactly where inside the city they want to operate.\n",
        "\n",
        "**2. Centrality works differently between the two cities.**  \n",
        "Madrid has a strong central premium: listings that are extremely close to the center are much more expensive, but prices fall quickly as you move away. Barcelona, on the other hand, keeps higher prices even at 3–5 km from the center. This probably comes from the fact that Barcelona’s tourist corridors (Gothic Quarter, Eixample, beaches, etc.) are compact and still highly demanded even outside the absolute center.  \n",
        "For investors, this means Barcelona gives you more “flexibility” in choosing a near-central property, while Madrid rewards only the most central positions.\n",
        "\n",
        "**3. Density affects both cities in opposite ways.**  \n",
        "Tile-based density showed that in Madrid, the higher density an area has, the more prices tend to drop. This is a sign of competition. In Barcelona, some very dense areas still keep really high prices, which likely means demand is so strong that supply doesn’t hurt profitability as much.  \n",
        "This is important, since investing in a dense area in Madrid can be risky because price pressure is stronger, while in Barcelona dense areas can actually be premium.\n",
        "\n",
        "**4. Visual maps confirm the overall picture.**  \n",
        "The interactive maps we generated help connect the numbers with the city layouts. Barcelona’s premium clusters appear packed tightly around the main tourist zones. Madrid’s clusters are more spread, confirming that the city is less “compact” in terms of tourism and price intensity. This visual confirmation is useful for anyone trying to choose a specific neighbourhood.\n",
        "\n",
        "**5. Investment insights based on location.**  \n",
        "- **Madrid:** Stick to the most central clusters. Prices fall quickly outside the core, and dense peripheral areas can become too competitive.  \n",
        "- **Barcelona:** Central and near-central areas remain strong even when density is high. These locations seem more resilient and offer better potential for stable pricing.  \n",
        "- **Both cities:** Use micro-market clusters instead of city-level averages. Smaller spatial pockets give a much more accurate idea of what you can realistically earn.\n",
        "\n",
        "\n",
        "**Overall summary:**  \n",
        "Madrid and Barcelona are both good markets, but for different reasons. Madrid rewards extremely central properties, while Barcelona rewards proximity to its compact tourist hubs. Understanding these spatial patterns is essential for choosing the right property and avoiding over-supply risks. In both cities, “where you buy” matters just as much as “what you buy.”"
      ],
      "metadata": {
        "id": "K5TAT_02fx9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Section 4:Superhost vs Non-Superhost Comparison**"
      ],
      "metadata": {
        "id": "UtyKjVT6ESrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we compare Superhosts and Non-Superhosts to understand how their behavior, performance and pricing differ.\n",
        "\n",
        "The goal is to see whether being a Superhost actually leads to better results and what characteristics explain this difference."
      ],
      "metadata": {
        "id": "Y58OujdznyR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Make charts look clean\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "metadata": {
        "id": "WmaVcLcspVG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = combined_listings.copy()\n",
        "\n",
        "expected_cols = [\n",
        "    'host_is_superhost','review_scores_rating','number_of_reviews',\n",
        "    'host_response_rate','host_response_time','host_total_listings_count',\n",
        "    'price','accommodates','amenities','neighbourhood'\n",
        "]\n",
        "\n",
        "missing = set(expected_cols) - set(df.columns)\n",
        "if missing:\n",
        "    print(\"⚠ Missing columns:\", missing)\n",
        "\n",
        "# Convert to numeric where needed\n",
        "df['host_is_superhost'] = df['host_is_superhost'].map({'t':1,'f':0}).fillna(0)\n",
        "df['price'] = df['price'].astype(str).str.replace(\"$\",\"\").str.replace(\",\",\"\").astype(float)\n",
        "\n",
        "# Handle 'unknown' values before converting\n",
        "df['host_response_rate'] = df['host_response_rate'].replace('unknown', np.nan)\n",
        "df['host_response_rate'] = df['host_response_rate'].astype(str).str.rstrip(\"%\").astype(float)/100"
      ],
      "metadata": {
        "id": "8XPyYncEper8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"amenities_count\"] = df[\"amenities\"].apply(lambda x: len(eval(x)) if isinstance(x,str) else 0)\n",
        "df[\"price_per_person\"] = df[\"price\"] / df[\"accommodates\"]\n",
        "\n",
        "print(\"✓ Data loaded for Section 4\")"
      ],
      "metadata": {
        "id": "cZwSpFC2qNT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have checked the data that we have and it is ready for using it in this section."
      ],
      "metadata": {
        "id": "jr0DMnMh0t3-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 1: Behavioral differences**"
      ],
      "metadata": {
        "id": "VlUjIoS8Eqlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "sns.countplot(data=df, x=\"host_response_time\", hue=\"host_is_superhost\", order=df[\"host_response_time\"].value_counts().index)\n",
        "plt.title(\"Response Time Distribution\")\n",
        "plt.xlabel(\"Host Response Time Category\")\n",
        "plt.legend(title=\"Superhost\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i7P0fua2s_bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 0 represents a Non-Superhost.\n",
        "\n",
        "- 1 represents a Superhost.\n",
        "\n",
        "Superhosts generally manage a significantly higher median number of listings, showing a strong link between professionalization and superhost status. However, non-superhosts may include a few extreme outliers with massive portfolios who do not prioritize the superhost badge"
      ],
      "metadata": {
        "id": "bBEOgiNHzaRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(data=df, x=\"host_is_superhost\", y=\"host_total_listings_count\")\n",
        "plt.title(\"Portfolio Size: Superhost vs Non-Superhost\")\n",
        "plt.xlabel(\"Superhost (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Number of Listings\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H53zZrsyqVco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Superhosts generally manage more listings, showing they tend to be more experienced or professional hosts than non-superhost."
      ],
      "metadata": {
        "id": "EW60bfr-qZ4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 2: Ratings and response metrics**"
      ],
      "metadata": {
        "id": "0jp1iFs_E32c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_cols = ['review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin']\n",
        "rating_subscores = df.groupby('host_is_superhost')[rating_cols].mean().reset_index()\n",
        "rating_subscores_melt = rating_subscores.melt(id_vars='host_is_superhost', var_name='Metric', value_name='Average Score')\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=rating_subscores_melt, x='Metric', y='Average Score', hue='host_is_superhost')\n",
        "plt.title('Average Sub-Review Scores: Superhost vs. Non-Superhost')\n",
        "plt.legend(title='Superhost (0=No, 1=Yes)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FLAfmFAwz8VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The analysis of sub-review scores confirms that Superhosts consistently outperform Non-Superhosts across all detailed rating categories (Accuracy, Cleanliness, Check-in, etc.)\n",
        "\n",
        "This shows that Superhost status is a reliable indicator of high-quality service, with excellence in the operational details of hosting, such as providing accurate listings and ensuring a clean and seamless guest experience."
      ],
      "metadata": {
        "id": "8L16sziT0Ms0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "# Review score\n",
        "sns.boxplot(ax=axes[0], data=df, x=\"host_is_superhost\", y=\"review_scores_rating\")\n",
        "axes[0].set_title(\"Review Scores Rating\")\n",
        "\n",
        "# Response rate\n",
        "sns.boxplot(ax=axes[1], data=df, x=\"host_is_superhost\", y=\"host_response_rate\")\n",
        "axes[1].set_title(\"Response Rate\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWEUEk6dqfm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Superhosts have higher average ratings and they maintain higher response rates.\n",
        "\n",
        "This suggests they communicate faster and provide better guest experiences."
      ],
      "metadata": {
        "id": "jcrantx-qjbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 3: Pricing strategy**"
      ],
      "metadata": {
        "id": "9ICIqQx7FAWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(13,4))\n",
        "\n",
        "sns.boxplot(ax=axes[0], data=df, x=\"host_is_superhost\", y=\"price\")\n",
        "axes[0].set_title(\"Price\")\n",
        "\n",
        "sns.boxplot(ax=axes[1], data=df, x=\"host_is_superhost\", y=\"price_per_person\")\n",
        "axes[1].set_title(\"Price per Person\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "L2L0lEYXqvbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When talking about their pricing strategy, superhosts tend to price slightly higher. Their higher ratings give them more reliability,  allowing them to charge a small premium. Also, the price per person differences  show superhosts capture more value."
      ],
      "metadata": {
        "id": "3Rtxyrq7qytT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To measure the real impact of Superhost status, we compared the average price, estimated occupancy, and a proxy for income between Superhosts and standard hosts. This allows us to assess whether being a Superhost provides an economic advantage beyond perceived quality."
      ],
      "metadata": {
        "id": "vxDKKF81e6xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = combined_listings.copy()\n",
        "\n",
        "df['unavailable_days'] = 365 - df['availability_365']\n",
        "df['occupancy_rate'] = df['unavailable_days'] / 365\n",
        "\n",
        "df['revenue_proxy'] = df['price'] * df['occupancy_rate']\n",
        "\n",
        "economic_summary = df.groupby('host_is_superhost').agg(\n",
        "    avg_price=('price', 'mean'),\n",
        "    avg_occupancy_rate=('occupancy_rate', 'mean'),\n",
        "    avg_revenue=('revenue_proxy', 'mean'),\n",
        "    count=('id', 'count')\n",
        ").reset_index()\n",
        "\n",
        "economic_summary\n"
      ],
      "metadata": {
        "id": "slvKd-aTe6ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Superhosts perform significantly better. They charge more per night (156€ vs. 141€), have higher occupancy rates (0.47 vs. 0.38), and, as a result, generate much higher estimated income (69.5€ vs. 51.8€ per available day).\n",
        "\n",
        "Taken together, these figures confirm that Superhost status has a significant economic impact for investors."
      ],
      "metadata": {
        "id": "rrJJ9UiBfFSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the calculated metrics, we estimate the percentage and absolute difference between Superhosts and non-Superhosts in terms of price, occupancy, and income level. This allows us to accurately quantify the economic advantage associated with Superhost status."
      ],
      "metadata": {
        "id": "RQdTYCjpfIfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_sh = economic_summary[economic_summary['host_is_superhost'] == 'f'].iloc[0]\n",
        "sh = economic_summary[economic_summary['host_is_superhost'] == 't'].iloc[0]\n",
        "\n",
        "impact = {\n",
        "    'price_diff_%': (sh.avg_price - non_sh.avg_price) / non_sh.avg_price * 100,\n",
        "    'occupancy_diff_%': (sh.avg_occupancy_rate - non_sh.avg_occupancy_rate) * 100,\n",
        "    'revenue_diff_%': (sh.avg_revenue - non_sh.avg_revenue) / non_sh.avg_revenue * 100,\n",
        "    'price_diff_€': sh.avg_price - non_sh.avg_price,\n",
        "    'revenue_diff_€': sh.avg_revenue - non_sh.avg_revenue\n",
        "}\n",
        "\n",
        "impact = pd.DataFrame.from_dict(impact, orient='index', columns=['Impact'])\n",
        "impact"
      ],
      "metadata": {
        "id": "vPiT-Lo-fGDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Superhosts enjoy a significant financial boost. They charge 10.5% more per night (+14.86€), achieve 9 points more occupancy, and, combining both effects, generate 34% more estimated income (+17.78€ per available day).\n",
        "\n",
        "In practical terms, being a Superhost brings a clear and measurable financial advantage."
      ],
      "metadata": {
        "id": "KdVF-jEBff5A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand whether Superhost status brings the same value in both markets or whether its impact depends on the structure of each city, we repeated the economic analysis, differentiating between Madrid and Barcelona. We calculated the average price, estimated occupancy, and a proxy for revenue for Superhosts and non-Superhosts within each city. This allowed us to identify how each market responds to host behavior."
      ],
      "metadata": {
        "id": "lLWCBqx8fisK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = combined_listings.copy()\n",
        "\n",
        "df['unavailable_days'] = 365 - df['availability_365']\n",
        "df['occupancy_rate'] = df['unavailable_days'] / 365\n",
        "df['price_per_person'] = df['price'] / df['accommodates']\n",
        "df['revenue_proxy'] = df['price'] * df['occupancy_rate']\n",
        "\n",
        "city_superhost_summary = df.groupby(['City', 'host_is_superhost']).agg(\n",
        "    avg_price=('price', 'mean'),\n",
        "    avg_occupancy=('occupancy_rate', 'mean'),\n",
        "    avg_revenue=('revenue_proxy', 'mean'),\n",
        "    count=('id', 'count')\n",
        ").reset_index()\n",
        "\n",
        "city_superhost_summary"
      ],
      "metadata": {
        "id": "6nujCJ1JfgZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show that the Superhost effect exists in both cities, but manifests itself differently.\n",
        "\n",
        "In Barcelona, Superhosts stand out above all for their greater ability to set prices, charging significantly more per night and also achieving higher occupancy rates. This translates into a notable increase in estimated income per property.\n",
        "\n",
        "In Madrid, on the other hand, the price difference between Superhosts and non-Superhosts is minimal, but occupancy increases very sharply for Superhosts. This indicates that, in this market, Superhost status mainly improves visibility and demand.\n",
        "\n",
        "Overall, both markets compensate in different ways, but with the same result: Superhosts generate significantly higher income, either through higher prices (Barcelona) or higher occupancy rates (Madrid)."
      ],
      "metadata": {
        "id": "0qDboJGMfnVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To complete the analysis, we quantified the percentage and absolute difference that Superhost status contributes in each city. This calculation allows us to understand not only whether Superhosts perform better, but also how and to what extent their effect varies between Madrid and Barcelona."
      ],
      "metadata": {
        "id": "n3zlpH6cfpwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_diff(city):\n",
        "    sub = city_superhost_summary[city_superhost_summary['City'] == city]\n",
        "    non_sh = sub[sub['host_is_superhost'] == 'f'].iloc[0]\n",
        "    sh = sub[sub['host_is_superhost'] == 't'].iloc[0]\n",
        "\n",
        "    return {\n",
        "        'city': city,\n",
        "        'price_diff_%': (sh.avg_price - non_sh.avg_price) / non_sh.avg_price * 100,\n",
        "        'price_diff_€': sh.avg_price - non_sh.avg_price,\n",
        "        'occupancy_diff_pp': (sh.avg_occupancy - non_sh.avg_occupancy) * 100,\n",
        "        'revenue_diff_%': (sh.avg_revenue - non_sh.avg_revenue) / non_sh.avg_revenue * 100,\n",
        "        'revenue_diff_€': sh.avg_revenue - non_sh.avg_revenue\n",
        "    }\n",
        "\n",
        "madrid_diff = compute_diff(\"Madrid\")\n",
        "barcelona_diff = compute_diff(\"Barcelona\")\n",
        "\n",
        "madrid_diff, barcelona_diff"
      ],
      "metadata": {
        "id": "4ycn4Yv7fsVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results confirm that the economic impact of Superhost status is significant in both cities, but operates differently.\n",
        "\n",
        "In Madrid, the price difference between Superhosts and non-Superhosts is very small (+1.25%), but occupancy increases by more than 10 points, raising estimated revenue by around +26%. This indicates that, in Madrid, the Superhost effect is mainly manifested through higher demand.\n",
        "\n",
        "In Barcelona, the pattern is different: Superhosts achieve a strong price increase (+21.88%, equivalent to +32.9€ per night) and also a notable improvement in occupancy (+7 percentage points). The combination of both factors boosts revenue by around +45%, making Barcelona a market where Superhost status translates into strong pricing power.\n",
        "\n",
        "Overall, both markets reward Superhosts, but for different reasons: Madrid for demand and Barcelona for price."
      ],
      "metadata": {
        "id": "XFU5su9hgFyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 4: Portfolio size**"
      ],
      "metadata": {
        "id": "uCnKfYKZFG2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"amenities_count\"] = df[\"amenities\"].apply(lambda x: len(eval(x)) if isinstance(x,str) else 0)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.boxplot(data=df, x=\"host_is_superhost\", y=\"amenities_count\")\n",
        "plt.title(\"Amenities Count: Superhost vs Non-Superhost\")\n",
        "plt.xlabel(\"Superhost (0 = No, 1 = Yes)\")\n",
        "plt.ylabel(\"Number of Amenities\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dx0xmJ9Wq-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, if we see their portfolio size, superhosts typically offer more amenities, which means that they have higher-quality or better-equipped listings."
      ],
      "metadata": {
        "id": "QlhgWF25rB19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5: Conclusions"
      ],
      "metadata": {
        "id": "vrsX7PKSrQwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To sum up, most differences between Superhosts and Non-Superhosts are statistically significant. The main conclusions that we have from this point are:\n",
        "\n",
        "1. **Superhosts are more experienced**: They usually manage more listings, showing they tend to be more active or professional hosts compared to regular hosts.\n",
        "\n",
        "2. **Superhosts deliver better guest experiences**: They have higher review scores and faster response rates, which means they communicate better and maintain better service quality.\n",
        "\n",
        "3. **Superhosts can charge slightly higher prices**: Because of their reputation and better reviews, Superhosts are able to set higher prices and higher price per person, capturing more value from each booking.\n",
        "\n",
        "4. **Superhosts offer better-equipped listings**: They usually include more amenities, which helps them attract guests and maintain higher ratings.\n",
        "\n",
        "5. **Differences are statistically significant**: Most differences between Superhosts and Non-Superhosts are not random, the statistical tests confirm that Superhosts consistently outperform.\n",
        "\n",
        "6. **Superhosts generate a clear economic advantage**: They command slightly higher prices, higher occupancy rates, and overall generate 34% more estimated revenue than standard hosts, confirming that Superhost status has a real impact on profitability.\n",
        "\n",
        "7. **The Superhost effect varies by city**: In Barcelona, the status mainly translates into greater pricing power, while in Madrid it is mainly reflected in higher occupancy rates. In both markets, however, Superhosts achieve higher revenues."
      ],
      "metadata": {
        "id": "jaWHGtldrXDw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSmrFqBY9Bf5"
      },
      "source": [
        "# **Section 5: Review Analysis**\n",
        "\n",
        "In Section 5 we make a review analysis, consisting of 3 main subsections:\n",
        "\n",
        "- Sentiment analysis\n",
        "- Keyword frequency (text and n-grams)\n",
        "- Rating drivers (cleanliness, communication, location, etc.)\n",
        "\n",
        "Goal: to analyze satisfaction level in different accomodations of Madrid and Barcelona, infer what is the general satisfaction level and reach conclusions about this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCKncG44Sjhc"
      },
      "source": [
        "## **Setup**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMeiu59hSib0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import unicodedata\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "import unicodedata\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Immediately, we begin by sampling the reviews csv to keep memory usage low while maintaining the ratio of Madrid vs. Barcelona reviews.\n",
        "\n",
        "We cannot either affirm or deny that the 4% is fully representative of the whole dataset, but we can perform some tests do confirm it."
      ],
      "metadata": {
        "id": "eir8uvKIzYEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_reviews_sample = combined_reviews.groupby('City', group_keys=False).apply(\n",
        "    lambda x: x.sample(frac=0.04, random_state=42)\n",
        ")\n",
        "\n",
        "print(f\"Original dataset shape: {combined_reviews.shape}\")\n",
        "print(f\"Sampled dataset shape: {combined_reviews_sample.shape}\")\n",
        "print(\"Sample per city:\")\n",
        "print(combined_reviews_sample['City'].value_counts())"
      ],
      "metadata": {
        "id": "Ct-F49GizXjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMHeUMFhr0cL"
      },
      "source": [
        "**Important Note:** combined_listings does not work in this analysis. Because those stayings with for Madrid all had price = Nan, so if you wanted to do a review analysis based on price, you ended up with all Barcelona listings.\n",
        "\n",
        "Therefore, as you see in the next cell:\n",
        "1) We retrieve combined_listings\n",
        "2) We see, for that dataframe, how many cases are:\n",
        "- City = Madrid / Barcelona\n",
        "- Price > 0\n",
        "- Has_Reviews = True\n",
        "3) We create a separate dataframe, combined_listings_review_analysis which includes the cases fulfilling the three criteria."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(combined_listings['City'].value_counts())\n",
        "\n",
        "madrid_listings_review_analysis = combined_listings[combined_listings['City'] == 'Madrid']\n",
        "madrid_both_conditions = madrid_listings_review_analysis[(madrid_listings_review_analysis['price'] > 0) & (madrid_listings_review_analysis['number_of_reviews'] > 0)]\n",
        "print(f\"Madrid listings with price > 0 AND number_of_reviews > 0: {len(madrid_both_conditions):,}\")\n",
        "\n",
        "barcelona_listings_review_analysis = combined_listings[combined_listings['City'] == 'Barcelona']\n",
        "barcelona_both_conditions = barcelona_listings_review_analysis[(barcelona_listings_review_analysis['price'] > 0) & (barcelona_listings_review_analysis['number_of_reviews'] > 0)]\n",
        "print(f\"Barcelona listings with price > 0 AND number_of_reviews > 0: {len(barcelona_both_conditions):,}\")\n",
        "\n",
        "combined_listings_review_analysis = pd.concat([madrid_both_conditions, barcelona_both_conditions], ignore_index=True)\n",
        "print(f\"Combined listings for review analysis: {len(combined_listings_review_analysis):,} rows\")"
      ],
      "metadata": {
        "id": "02EbOzggxSNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_listings_review_analysis.info()"
      ],
      "metadata": {
        "id": "QPogPTXPTkUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can drop first some columns of the dataframe for computing reasons."
      ],
      "metadata": {
        "id": "w7knP_oaTm6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\n",
        "    'host_url',\n",
        "    'host_since',\n",
        "    'host_location',\n",
        "    'host_about',\n",
        "    'host_response_time',\n",
        "    'host_response_rate',\n",
        "    'host_acceptance_rate',\n",
        "    'host_thumbnail_url',\n",
        "    'host_picture_url',\n",
        "    'host_neighbourhood',\n",
        "    'host_listings_count',\n",
        "    'host_total_listings_count',\n",
        "    'host_has_profile_pic',\n",
        "    'host_identity_verified',\n",
        "    'bathrooms',\n",
        "    'bathrooms_text',\n",
        "    'beds',\n",
        "    'amenities',\n",
        "    'calendar_updated',\n",
        "    'has_availability',\n",
        "    'availability_30',\n",
        "    'availability_60',\n",
        "    'availability_90',\n",
        "    'availability_365',\n",
        "    'calendar_last_scraped'\n",
        "]\n",
        "\n",
        "# Drop columns that exist in the DataFrame\n",
        "existing_columns_to_drop = [col for col in columns_to_drop if col in combined_listings_review_analysis.columns]\n",
        "\n",
        "if existing_columns_to_drop:\n",
        "    combined_listings_review_analysis.drop(columns=existing_columns_to_drop, inplace=True)\n",
        "    print(f\"Dropped {len(existing_columns_to_drop)} columns from combined_listings_review_analysis.\")\n",
        "else:\n",
        "    print(\"No specified columns found to drop.\")\n",
        "\n",
        "combined_listings_review_analysis.info()"
      ],
      "metadata": {
        "id": "PwvcEdRxTumj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JetLpBykJoTf"
      },
      "source": [
        "## **Step 1: Data Understanding & Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpZfJTi_Opbr"
      },
      "source": [
        "Firstly, we analyze introductory aspects of the dataset, such as:\n",
        "\n",
        "1) how many reviews per city are there\n",
        "2) are there listings with no reviews associated to it?\n",
        "3) what is the available timeframe of the dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Xmfo_30MFoU"
      },
      "outputs": [],
      "source": [
        "display(barcelona_reviews_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLY15CsSVfLk"
      },
      "outputs": [],
      "source": [
        "display(madrid_reviews_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FWV_huxORSu"
      },
      "outputs": [],
      "source": [
        "combined_reviews.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d2e001c"
      },
      "outputs": [],
      "source": [
        "display(combined_listings_review_analysis[\n",
        "    [\n",
        "    \"review_scores_accuracy\",\n",
        "    \"review_scores_rating\",\n",
        "    \"review_scores_cleanliness\",\n",
        "    \"review_scores_communication\",\n",
        "    \"review_scores_checkin\",\n",
        "    \"review_scores_location\",\n",
        "    \"review_scores_value\"\n",
        "    ]\n",
        "].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwrWExmkS9GU"
      },
      "source": [
        "For most review score columns there are around 27,615 entries. The mean score for all columns is around 4.7, and along with the 2nd and 3rd quartile data,  we already know that most ratings are high and very close to 5.\n",
        "\n",
        "As something remarkable, we have the lowest standard deviation for *review_scores_location*, signalling that most clients were very satisfied with the location of their accomodations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvDwoZbhJ1jP"
      },
      "source": [
        "### Reviews Per City"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGTcpxSjgmsy"
      },
      "source": [
        "It is interesting to know the number of reviews per city, because we want to know if our dataset is balanced. This is the main test we do to decide if the sample is representative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hp1gV_rPUM2"
      },
      "outputs": [],
      "source": [
        "combined_reviews[\"City\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMb46i1YOW-9"
      },
      "outputs": [],
      "source": [
        "reviews_per_city_proportion = combined_reviews[\"City\"].value_counts(normalize=True) * 100\n",
        "print(reviews_per_city_proportion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvE2hxmwguXZ"
      },
      "source": [
        "A 55% - 44% dataset is considered, generally, as well-balanced. In practical terms, this deviation from the perfect 50/50 split is minimal and therefore we can conclude there is no need to work on this aspect.\n",
        "\n",
        "Now, let´s see if the 4% sample follows this as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_14kn8os-FX"
      },
      "outputs": [],
      "source": [
        "combined_reviews_sample[\"City\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PNb332gtFB-"
      },
      "outputs": [],
      "source": [
        "reviews_per_city_proportion_sample = combined_reviews_sample[\"City\"].value_counts(normalize=True) * 100\n",
        "print(reviews_per_city_proportion_sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e90eCCOGtIjG"
      },
      "source": [
        "The sample follows the same 55/44 distribution, so we can be sure that it is representative of the whole dataset. Later on, when we need to perform deep text operations on the reviews dataset, we will only do it on the sample dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU1lbWLoJ4Tq"
      },
      "source": [
        "### Listings with no reviews & Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiZ9GkU9jZ9n"
      },
      "source": [
        "We do not have listings with no reviews because we defined in the first step for *combined_listings_review_analysis* to have:\n",
        "- Price > 0\n",
        "- Has_Reviews = True\n",
        "\n",
        "However, just for the sake of understanding the dataset and the quality of the data, we can check for no-review listings in the *combined_listings* dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFfg837UOZgF"
      },
      "outputs": [],
      "source": [
        "listings_with_no_reviews = combined_listings[combined_listings['number_of_reviews'] == 0]\n",
        "print(f\"Number of listings with no reviews: {len(listings_with_no_reviews):,}\")\n",
        "display(listings_with_no_reviews.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "proportion_no_reviews = len(listings_with_no_reviews) / len(combined_listings)\n",
        "print(f\"Proportion of listings with no reviews: {proportion_no_reviews:.4f} ({proportion_no_reviews * 100:.2f}%) \")"
      ],
      "metadata": {
        "id": "um4KGoWN4fUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is an astonishing amount of listings that have no reviews. Almost a quarter of the total of listings in combined_listings do not have reviews.\n",
        "\n",
        "This is very significant because it reduces our analysis to a quite reduced portion of the dataset."
      ],
      "metadata": {
        "id": "Q0G8Hq0Y40ns"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy1CqXXWXDup"
      },
      "source": [
        "**Do these non-reviews rows have filled any of the review-based columns?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "768dbcbf"
      },
      "outputs": [],
      "source": [
        "review_related_cols = [\n",
        "    'id',\n",
        "    'number_of_reviews',\n",
        "    'number_of_reviews_ltm',\n",
        "    'number_of_reviews_l30d',\n",
        "    'number_of_reviews_ly',\n",
        "    'first_review',\n",
        "    'last_review',\n",
        "    'review_scores_rating',\n",
        "    'review_scores_accuracy',\n",
        "    'review_scores_cleanliness',\n",
        "    'review_scores_checkin',\n",
        "    'review_scores_communication',\n",
        "    'review_scores_location',\n",
        "    'review_scores_value',\n",
        "    'reviews_per_month'\n",
        "]\n",
        "\n",
        "combined_listings['has_reviews'] = combined_listings['number_of_reviews'] > 0\n",
        "\n",
        "listings_with_no_reviews = combined_listings[combined_listings['has_reviews'] == False]\n",
        "print(f\"Found {len(listings_with_no_reviews)} listings with no reviews.\\n\")\n",
        "\n",
        "print(\"First 5 listings with no reviews and their review-related columns:\")\n",
        "display(listings_with_no_reviews[review_related_cols].head())\n",
        "\n",
        "columns_to_check_for_nulls = [\n",
        "    'number_of_reviews_ltm',\n",
        "    'number_of_reviews_l30d',\n",
        "    'number_of_reviews_ly',\n",
        "    'first_review',\n",
        "    'last_review',\n",
        "    'review_scores_rating',\n",
        "    'review_scores_accuracy',\n",
        "    'review_scores_cleanliness',\n",
        "    'review_scores_checkin',\n",
        "    'review_scores_communication',\n",
        "    'review_scores_location',\n",
        "    'review_scores_value',\n",
        "    'reviews_per_month'\n",
        "]\n",
        "\n",
        "non_null_counts = listings_with_no_reviews[columns_to_check_for_nulls].notnull().sum()\n",
        "\n",
        "print(\"\\nNumber of non-null values in detailed review columns for listings with no reviews:\")\n",
        "print(non_null_counts[non_null_counts > 0])\n",
        "\n",
        "if non_null_counts[non_null_counts > 0].empty:\n",
        "    print(\"No inconsistencies found: all detailed review-related columns are null for listings with no reviews.\")\n",
        "else:\n",
        "    print(\"Inconsistencies found: some detailed review-related columns have non-null values for listings with no reviews.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoQPJUweg7FV"
      },
      "source": [
        "Now, let´s check for the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c83f7188"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "print(\"Missing values in combined_listings:\")\n",
        "print(combined_listings.isnull().sum()[combined_listings.isnull().sum() > 0])\n",
        "\n",
        "print(\"\\nDisplaying first 5 rows of combined_listings with all columns:\")\n",
        "display(combined_listings.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si8658pw3vG2"
      },
      "source": [
        "As you can see, most of the cases with missing values in the reviews columns are the 10137 cases we detected before **but these are not errors in the data, they most probably represent cases where customers did not leave a review**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cde28ec6"
      },
      "outputs": [],
      "source": [
        "inconsistent_reviews_scoresaccuracy = combined_listings[\n",
        "    (combined_listings['has_reviews'] == True) &\n",
        "    (combined_listings['review_scores_accuracy'].isna())\n",
        "]\n",
        "\n",
        "print(f\"Number of listings where has_reviews is True but review_scores_accuracy is NaN: {len(inconsistent_reviews_scoresaccuracy)}\\n\")\n",
        "\n",
        "review_related_cols_to_show = [\n",
        "    'id',\n",
        "    'number_of_reviews',\n",
        "    'has_reviews',\n",
        "    'review_scores_rating',\n",
        "    'review_scores_accuracy',\n",
        "    'review_scores_cleanliness',\n",
        "    'review_scores_checkin',\n",
        "    'review_scores_communication',\n",
        "    'review_scores_location',\n",
        "    'review_scores_value'\n",
        "]\n",
        "\n",
        "if not inconsistent_reviews_scoresaccuracy.empty:\n",
        "    display(inconsistent_reviews_scoresaccuracy[review_related_cols_to_show].head(10))\n",
        "else:\n",
        "    print(\"No such inconsistencies found in the dataset.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zlvau3PskLx0"
      },
      "outputs": [],
      "source": [
        "inconsistent_reviews_scorescheckin = combined_listings[\n",
        "    (combined_listings['has_reviews'] == True) &\n",
        "    (combined_listings['review_scores_checkin'].isna())\n",
        "]\n",
        "\n",
        "print(f\"Number of listings where has_reviews is True butreview_scores_checkin is NaN: {len(inconsistent_reviews_scorescheckin)}\\n\")\n",
        "\n",
        "review_related_cols_to_show = [\n",
        "    'id',\n",
        "    'number_of_reviews',\n",
        "    'has_reviews',\n",
        "    'review_scores_rating',\n",
        "    'review_scores_accuracy',\n",
        "    'review_scores_cleanliness',\n",
        "    'review_scores_checkin',\n",
        "    'review_scores_communication',\n",
        "    'review_scores_location',\n",
        "    'review_scores_value'\n",
        "]\n",
        "\n",
        "if not inconsistent_reviews_scorescheckin.empty:\n",
        "    display(inconsistent_reviews_scorescheckin[review_related_cols_to_show].head(10))\n",
        "else:\n",
        "    print(\"No such inconsistencies found in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvZnPzGrkwHo"
      },
      "source": [
        "*AI NOTE: the previous two blocks were made using Gemini. Prompt: \"How can I check the row where has_review is True but then: - review_scores_accuracy is empty - review_scores_checkin is empty ???\"*\n",
        "\n",
        "This is interesting, because we have a filled Rating, but then some of the review-related columns are empty. This is probably due to the users who filled those reviews did not answer to those specific fields.\n",
        "\n",
        "In terms of the analysis, it only means that when we analyse specific aspects, we may need (or not) to remove those two columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C6Hg8tDjMML"
      },
      "source": [
        "We also identified that those cases with no reviews, the columns that have something to do with reviews (see list before) had either \"NaN\" or \"0.00\" we believe this is crucial to fix, as if we leave those set to 0.00 we could affect future analysis. We decided to change those 0.00 to NaN so that all cases with no reviews have the rest of review-related columns with a NaN value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO3zL8NUh_0s"
      },
      "outputs": [],
      "source": [
        "review_score_cols_to_reset = [\n",
        "    'review_scores_rating',\n",
        "    'review_scores_cleanliness',\n",
        "    'review_scores_location'\n",
        "]\n",
        "\n",
        "listings_with_zero_reviews_mask = (combined_listings['number_of_reviews'] == 0)\n",
        "\n",
        "for col in review_score_cols_to_reset:\n",
        "    combined_listings.loc[\n",
        "        listings_with_zero_reviews_mask & (combined_listings[col] == 0.0),\n",
        "        col\n",
        "    ] = np.nan\n",
        "\n",
        "print(\"Review score columns for listings with 0 reviews have been set to NaN where they were previously 0.0.\\n\")\n",
        "\n",
        "def check_key_nulls(df):\n",
        "    key_columns = [\n",
        "        'price',\n",
        "        'room_type',\n",
        "        'neighbourhood_cleansed',\n",
        "        'property_type',\n",
        "        'accommodates',\n",
        "        'bathrooms',\n",
        "        'bedrooms',\n",
        "        'beds',\n",
        "        'review_scores_rating',\n",
        "        'review_scores_cleanliness',\n",
        "        'review_scores_location',\n",
        "        'number_of_reviews',\n",
        "        'instant_bookable',\n",
        "        'host_is_superhost',\n",
        "        'host_listings_count',\n",
        "        'host_response_rate',\n",
        "        'minimum_nights',\n",
        "        'maximum_nights',\n",
        "        'availability_365',\n",
        "        'amenities'\n",
        "    ]\n",
        "\n",
        "    null_analysis = df[key_columns].isnull().sum()\n",
        "    print(\"Null values in key columns after adjustment:\")\n",
        "    print(null_analysis[null_analysis > 0])  # Only show columns with nulls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZplo1L_J6ka"
      },
      "source": [
        "### Available Timeframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsFM37g646Zy"
      },
      "source": [
        "The following is just to know what time interval we are dealing with.\n",
        "\n",
        "In following blocks, we will try to look at how satisfaction varies through time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSd6jH8yOVue"
      },
      "outputs": [],
      "source": [
        "combined_reviews_sample[\"date\"] = pd.to_datetime(combined_reviews_sample[\"date\"], errors=\"coerce\")\n",
        "print(\"\\nReview Dates:\", combined_reviews_sample[\"date\"].min(), \"→\", combined_reviews_sample[\"date\"].max())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "talEiA5H_cXe"
      },
      "source": [
        "So, we have a total timeframe of reviews of 14 years and 7 months. This covers great part of the variation in last years in Madrid and Barcelona, where spikes in prices have been acute.\n",
        "\n",
        "In terms of reviews, it is also great because we can compare the rating change over years, or the change in ratings in specific areas, for instance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGFvJ9O4L1aQ"
      },
      "source": [
        "## **Step 2: Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2g7fcdWmPZz"
      },
      "source": [
        "In step 2 we focus on cleaning the data that we found in Step 1 that might be inconsistent/unnecessary for the analysis."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_cols = [\n",
        "    \"id\",\n",
        "    \"City\",\n",
        "    \"neighbourhood_cleansed\",\n",
        "    \"room_type\",\n",
        "    \"host_is_superhost\",\n",
        "    \"price\",\n",
        "    \"number_of_reviews\",\n",
        "    \"number_of_reviews_ltm\",\n",
        "    \"number_of_reviews_l30d\",\n",
        "    \"number_of_reviews_ly\",\n",
        "    \"first_review\",\n",
        "    \"last_review\",\n",
        "    \"reviews_per_month\",\n",
        "    \"review_scores_rating\",\n",
        "    \"review_scores_accuracy\",\n",
        "    \"review_scores_cleanliness\",\n",
        "    \"review_scores_checkin\",\n",
        "    \"review_scores_communication\",\n",
        "    \"review_scores_location\",\n",
        "    \"review_scores_value\",\n",
        "    \"has_reviews\"\n",
        "]\n",
        "\n",
        "print(f\"combined_listings_review_analaysis shape: {combined_listings_review_analysis.shape}\")\n",
        "combined_listings_review_analysis.head()"
      ],
      "metadata": {
        "id": "u8izh-1zmqce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIVljmaYubks"
      },
      "source": [
        "Now, we will make use not of the listings dataframe but of the sample reviews dataframe we extracted: \"combined_reviews_sample\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AaVWlNJ563U"
      },
      "source": [
        "### General Text Cleaning Operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbV3xjR-oafO"
      },
      "source": [
        "First, we will define a function to preprocess the text specifically for the \"comments\" column in combined_reviews_sample.This is something essential to do before doing any NLP analysis, which is what we will do later on.\n",
        "\n",
        "With this, we are performing the following operations:\n",
        "\n",
        "- Making sure we have text format (string) just in case there was any number interpreted as such.\n",
        "\n",
        "- Delete accents and special characters (asked Gemini of this part: Unicode normalization)\n",
        "\n",
        "- Standardize everything to lower caps so that reviews where \"excellent\" and \"Excellent\" are present, are treated as the same word.\n",
        "\n",
        "- Delete web links, numbers, punctuation marks and extra spaces (two between words or at the beginning/end)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLaCD4W1oCSe"
      },
      "outputs": [],
      "source": [
        "def normalize_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"http\\S+|www\\.\\S+\", \" \", text)\n",
        "    text = re.sub(r\"\\d+\", \" \", text)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "    return text\n",
        "combined_reviews_sample[\"comments_clean\"] = combined_reviews_sample[\"comments\"].apply(normalize_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnbT0P5r4lcH"
      },
      "source": [
        "Then, we process the reviews further:\n",
        "1) Removing HTML\n",
        "2) Removing emojis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmdaKmHlA8RT"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import unicodedata\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# 1) Remove HTML\n",
        "def remove_html(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    return BeautifulSoup(str(text), \"lxml\").get_text()\n",
        "\n",
        "# 2) Remove emojis\n",
        "def remove_emojis(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "# Apply everything together\n",
        "def preprocess_text(text):\n",
        "    text = remove_html(text)\n",
        "    text = remove_emojis(text)\n",
        "    return text\n",
        "\n",
        "combined_reviews_sample[\"clean_text\"] = combined_reviews_sample[\"comments_clean\"].apply(preprocess_text)\n",
        "combined_reviews_sample[\"clean_text\"].head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_reviews_sample = combined_reviews_sample.drop(columns=['comments', 'comments_clean'])"
      ],
      "metadata": {
        "id": "_zSjCKrK6pgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_listings_review_analysis.head()"
      ],
      "metadata": {
        "id": "nTGxBkRf7tLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_reviews_sample.head()"
      ],
      "metadata": {
        "id": "HqFwMEPn636_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWw3-tZh5_ts"
      },
      "source": [
        "### Text Length Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56KqIMEX47r2"
      },
      "source": [
        "Now, to continue with the text preprocessing, we want just to see what is the distribution of the longitude of the text reviews.\n",
        "\n",
        "**Why do this?** We need to focus our efforts on a set of comments (namely, those give us the most details about their staying, what was positive and what was not).\n",
        "\n",
        "There is something that cannot be denied: a happy client usually writes: \"Great stay, thanks!\" but an angry client usually writes a full 300-word writing detailing everything that went wrong.\n",
        "\n",
        "If we eliminate the longest reviews *(e.g.: those >100 words)*, we would be eliminating (if our hypothesis is correct) the worst ones. The truth is, however, that the general sentiment is shown in the first words of the review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7PaE7X1AZlI"
      },
      "outputs": [],
      "source": [
        "combined_reviews_sample[\"comments_len\"] = combined_reviews_sample[\"clean_text\"].str.split().apply(len)\n",
        "\n",
        "mis_bins = range(0, 220, 10)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "sns.histplot(\n",
        "    combined_reviews_sample[\"comments_len\"],\n",
        "    bins=mis_bins,\n",
        "    kde=False,\n",
        "    color=\"#E63946\"\n",
        ")\n",
        "\n",
        "plt.xticks(mis_bins)\n",
        "plt.xlim(0, 200)\n",
        "\n",
        "plt.title(\"Distribution of the comments length (word count)\")\n",
        "plt.xlabel(\"Comment length\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ipc61nzLHcU"
      },
      "source": [
        "Our strategy will be to eliminate those reviews that are less than 4 words. This way, we are eliminating those that do not provide much information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPaQhjirLM2Q"
      },
      "outputs": [],
      "source": [
        "print(f\"Original shape: {combined_reviews_sample.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lt1vMw_RKxDF"
      },
      "outputs": [],
      "source": [
        "df_filtered = combined_reviews_sample[combined_reviews_sample[\"comments_len\"] >= 4].copy()\n",
        "print(f\"Shape after filtering short reviews: {df_filtered.shape}\")\n",
        "print(f\"Dropped {combined_reviews_sample.shape[0] - df_filtered.shape[0]} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEgpt7jbFqqz"
      },
      "outputs": [],
      "source": [
        "#si hace falta borrarlo más tarde:\n",
        "combined_reviews_sample = combined_reviews_sample.drop(columns=[\"comments_len\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovgv7Di4Fgq7"
      },
      "source": [
        "### Remove Duplicate Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1mW51lrGu1j"
      },
      "outputs": [],
      "source": [
        "df_filtered = df_filtered.drop_duplicates(subset=[\"clean_text\", \"listing_id\", \"date\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuJT1u7kM8XA"
      },
      "outputs": [],
      "source": [
        "print(f\"Filtered dataframe {df_filtered.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EDA"
      ],
      "metadata": {
        "id": "0AR8iWfFBxL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_reviews_sample.describe()"
      ],
      "metadata": {
        "id": "bugkrU-cBwmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9101b7fe"
      },
      "source": [
        "display(combined_listings_review_analysis[\n",
        "    [\n",
        "    \"review_scores_accuracy\",\n",
        "    \"review_scores_rating\",\n",
        "    \"review_scores_cleanliness\",\n",
        "    \"review_scores_communication\",\n",
        "    \"review_scores_checkin\",\n",
        "    \"review_scores_location\",\n",
        "    \"review_scores_value\"\n",
        "    ]\n",
        "].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rcn5c4FOMPJx"
      },
      "source": [
        "## **Step 3: Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW_tcWbAOYez"
      },
      "source": [
        "This is the key part of the process, to measure the general attitude towards the stayings posted in Airbnb. It uses NLP and Machine Learning to determine the \"tone\" of a piece of text, classifying it as positive, negative or neutral.\n",
        "\n",
        "We want to perform this on the reviews text to see what is the general feeling of certain accomodations published in Airbnb. As commented before, we will test this in a subset (the 4% we defined previously)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW0uSCU7m_0o"
      },
      "source": [
        "### Methodology"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4jdIUUg6akV"
      },
      "source": [
        "To transform the unstructured information from reviews into a robus quantitative variable, we use the pre-trained model *nlptown/bert-base-multilingual-uncased-sentiment*. This is a variant of BERT optimized for multilingual opinion analysis, which is key here because we find several languages in the reviews.\n",
        "\n",
        "Instead of a simple categorical classification, we calculate a continuous Sentiment Score derived from the weighted average of the logarithmic probabilities of the predictions for the 1-5 starts.\n",
        "\n",
        "This methodology allows to capture nuances in satisfaction, and generate a new high-fidelity numeric variable to enrich the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpQ2oZqABl7s"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using: {device}\")\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)\n",
        "\n",
        "\n",
        "def get_sentiment_in_batches(texts, batch_size=32):\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "\n",
        "    weights = torch.tensor([-1.0, -0.5, 0.0, 0.5, 1.0], device=device)\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Batch processing\"):\n",
        "        batch_texts = texts[i : i + batch_size]\n",
        "        clean_batch = [t if isinstance(t, str) and len(t) > 0 else \"neutral\" for t in batch_texts]\n",
        "\n",
        "        try:\n",
        "            inputs = tokenizer(clean_batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "            probs = F.softmax(outputs.logits, dim=1)\n",
        "\n",
        "            batch_scores = (probs * weights).sum(dim=1)\n",
        "            all_scores.extend(batch_scores.cpu().numpy())\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            print(f\"Error in batch {i}: {e}\")\n",
        "            all_scores.extend([0.0] * len(batch_texts))\n",
        "\n",
        "    return all_scores\n",
        "print(\"Preapring data...\")\n",
        "text_data = df_filtered['clean_text'].fillna(\"\").tolist()\n",
        "\n",
        "print(f\"Processing {len(text_data)} reviews...\")\n",
        "\n",
        "sentiment_scores = get_sentiment_in_batches(text_data, batch_size=32)\n",
        "\n",
        "df_filtered['sentiment_score'] = sentiment_scores\n",
        "\n",
        "print(\"Process completed\")\n",
        "display(df_filtered[['clean_text', 'sentiment_score']].sample(5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 7))\n",
        "sns.histplot(df_filtered, x='sentiment_score', hue='City', bins=50, kde=True, palette={'Madrid': COLORS['madrid'], 'Barcelona': COLORS['barcelona']})\n",
        "plt.title('Distribution of Sentiment Scores by City', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('Sentiment Score (-1.0 to 1.0)', fontsize=13, fontweight='bold')\n",
        "plt.ylabel('Frequency', fontsize=13, fontweight='bold')\n",
        "plt.xlim(-1.0, 1.0)\n",
        "plt.grid(axis='y', alpha=0.3)\n",
        "plt.legend(title='City', labels=['Madrid', 'Barcelona'])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05Xdy-Gy9kMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwibTmyZm_0q"
      },
      "source": [
        "### Metrics & Insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uryKNSgKdX-u"
      },
      "source": [
        "From the graph above, we can extract conclusions.\n",
        "\n",
        "1. **Technical Validation.** The model is working correctly: there is a more or less soft distribution curve that follows perfectly the bars; meaning the BERT model works correctly. Even if the distribution is left-skewed and concrentrates on the right side, the model still detects nuances in the (-1, 0) range.\n",
        "\n",
        "2. **Business interpretation:** after seeing the highly-positive classification of the reviews, I though that maybe we had an error in our code with the preparation of data. *I asked Gemini for possible explanations, and among all it gave a very convincing one which I later researched about: **The Airbnb Bias**.\n",
        "\n",
        "  I looked for studies on this effect, and it turns out that it is something real: [Article 1](https://theescapehome.com/some-airbnb-users-feel-like-its-rating-system-is-wildly-inaccurate-heres-why/), because there is a closer relationship with the host, then the guest is usually less likely to give a negative recommendation thinking it may harm the host´s economical capabilities *(in the link you see a case where guest was afraid of harming the hosts who had just had a baby)*.\n",
        "\n",
        "  In this sense, I also found this academic study: *If nearly all Airbnb reviews are positive, does that make them meaningless?* (J. Bridges, C. Vásquez. 2016) which hypothesizes the confirmation of the Airbnb Bias, finding that 93% of the posted reviews on Airbnb are positive, and the mean accomodation score stays at 4.7/5. The authors state this is due to the *interpersonal nature of the collaborative economy* and the fact this is creating a social pressure to be \"nice\" and avoid explicit critiques. They conclude that negative experiences rarely manifest themselves at low punctuations, but that they can be seen in lukewarm reviews: short, neutral or lacking enthusiams.\n",
        "\n",
        "3. **Madrid vs Barcelona:** visually, there is a slight difference (Madrid is the yellow line and Barcelona is the pink line). The peak of maximum satisfaction stands at around 0.85 and is for Madrid. For Barcelona, we see a slightly flatter and wider curve. The interpretation here is that there seems to be a slightly higher satisfaction/more consistent in Madrid. In Barcelona, even though it is also very positive, it tends to have a higher dispersion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRLHWevRNau_"
      },
      "source": [
        "## **Step 4: Keyword & Topic Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM3aJN0lZotz"
      },
      "source": [
        "While the previous BERT analysis quantified the magnitude of guest satisfaction, it does not explain the reasons behind it. To extract interpretable insights we make an N-gram analysis, specifically examining unigrams (single concepts) and bigrams (contextual pairs).\n",
        "\n",
        "This approach converts raw text into frequency-based features to identify dominant themes. Given the international nature of Airbnb demand in Madrid and Barcelona, we implement a multilingual noise reduction strategy, filtering out stopwords across six languages: Spanish, English, French, Portuguese, Italian and German. This allows us to isolate high-value semantic tokens *(e.g., \"central location\", \"very clean\")* from noise. This will allow us to reveal the characteristics of a listing that explain a positive/negative review."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Keyword Analysis"
      ],
      "metadata": {
        "id": "QcgmmLIdiGjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*AI NOTE: the following code was developed using GenAI. Prompt: \"perform a Keyword Analysis on the dataset, considering stopwords, noise, and plot them depending on the city.\"*"
      ],
      "metadata": {
        "id": "b-bP3p3XtrzQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azp1WNI3dmw6"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "\n",
        "def get_multilingual_stopwords():\n",
        "    stop_words = set()\n",
        "    languages = ['spanish', 'english', 'french', 'german', 'italian', 'portuguese']\n",
        "\n",
        "    for lang in languages:\n",
        "        stop_words.update(stopwords.words(lang))\n",
        "\n",
        "    custom_noise = {'br', 'nan', 'apartamento', 'piso', 'room', 'apartment', 'stay', 'place'}\n",
        "    stop_words.update(custom_noise)\n",
        "\n",
        "    return list(stop_words)\n",
        "\n",
        "final_stopwords = get_multilingual_stopwords()\n",
        "print(f\"Stopwords cargadas: {len(final_stopwords)} palabras.\")\n",
        "\n",
        "def plot_top_ngrams(texts, city_name, n=2, top_k=15, min_df_val=10):\n",
        "    \"\"\"\n",
        "    Calculates and displays the most frequent N-grams.\n",
        "    n=1 (Unigrams), n=2 (Bigrams), n=3 (Trigrams)\n",
        "    \"\"\"\n",
        "    vectorizer = CountVectorizer(\n",
        "        stop_words=final_stopwords,\n",
        "        ngram_range=(n, n),\n",
        "        min_df=min_df_val,\n",
        "        max_features=10000\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        bag_of_words = vectorizer.fit_transform(texts.dropna())\n",
        "\n",
        "        sum_words = bag_of_words.sum(axis=0)\n",
        "        words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
        "        words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        common_words = words_freq[:top_k]\n",
        "        words, freqs = zip(*common_words)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        color = '#E63946' if city_name == 'Madrid' else '#457B9D'\n",
        "\n",
        "        sns.barplot(x=list(freqs), y=list(words), color=color)\n",
        "        ngram_type = 'Unigrams' if n == 1 else ('Bigrams' if n == 2 else 'Trigrams')\n",
        "        plt.title(f\"Top {top_k} {ngram_type} more frequent in {city_name}\")\n",
        "        plt.xlabel(\"Frequency\")\n",
        "        plt.show()\n",
        "\n",
        "    except ValueError:\n",
        "        print(f\"Not enough data to generate N-grams in {city_name}\")\n",
        "\n",
        "target_col = \"clean_text\" if \"clean_text\" in combined_reviews_sample.columns else \"comments_clean\"\n",
        "\n",
        "for city in [\"Madrid\", \"Barcelona\"]:\n",
        "    print(f\"\\n Analyzing {city}...\")\n",
        "    subset = combined_reviews_sample[combined_reviews_sample[\"City\"] == city][target_col]\n",
        "\n",
        "    plot_top_ngrams(subset, city, n=1)\n",
        "\n",
        "    plot_top_ngrams(subset, city, n=2)\n",
        "\n",
        "    plot_top_ngrams(subset, city, n=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Interpretation & Business Insight\n",
        "\n",
        "1. **Location is the King (in both cities)**\n",
        "In both Madrid and Barcelona, \"location\" is the #2 or #3 most frequent unigram, and \"great location\" is the overwhelming #1 bigram.\n",
        "\n",
        "- Madrid: Specific landmarks like \"Gran Via\" and \"Plaza Mayor\" appear frequently in the top bigrams. This suggests that for Madrid tourists, being central and close to these specific hubs is a primary delight factor. Terms like \"metro\" and \"cerca estacion metro\" (near metro station) in trigrams reinforce that connectivity is vital.\n",
        "\n",
        "- Barcelona: The dominance of \"Sagrada Familia\" in bigrams and trigrams (\"close sagrada familia\", \"walk sagrada familia\") is striking. It’s not just about being central; it’s specifically about proximity to this iconic monument. \"Metro station\" also appears, but the landmark focus is sharper here.\n",
        "\n",
        "**Business Insight:** Investors should prioritize properties within walking distance of these specific landmarks (Gran Via/Sol in Madrid, Sagrada Familia in BCN). \"Walking distance\" is a recurring high-frequency phrase; guests pay a premium to avoid long commutes.\n",
        "\n",
        "2. **The \"Hygiene Factors\": Cleanliness & Comfort**\n",
        "\"Clean\" is a top-5 unigram in both cities. Phrases like \"everything needed\" and \"well equipped\" (especially in Barcelona) appear frequently.\n",
        "\n",
        "Cleanliness is a non-negotiable. It's mentioned so often because it's the first thing guests check. If a listing isn't spotless, it fails. The presence of \"well equipped\" suggests that guests in Barcelona (perhaps staying longer or more family-oriented) value functional amenities (kitchen, washing machine) more explicitly.\n",
        "\n",
        "**Business Insight:** we should focus in keeping the accomodations clean and fully equipped.\n",
        "\n",
        "3. **The Human Element: The \"Superhost\" Effect**\n",
        "\"Great host\" is a top-10 bigram in both cities.\n",
        "\n",
        "Despite the rise of professional property management, guests still highly value the personal connection. They aren't just renting a space; they are rating the interaction. A \"great host\" is often one who communicates well and solves problems quickly.\n",
        "\n",
        "**Business Insight:** Automation is good for efficiency, but perceived personal hospitality (warm welcome messages, local tips) drives reviews.\n",
        "\n",
        "4. **Recommendation as the Ultimate Metric**\n",
        "Evidence: \"Recommend\", \"highly recommend\", \"would definitely recommend\" are ubiquitous across all n-grams.\n",
        "\n",
        "This confirms the Net Promoter Score (NPS) logic. The ultimate expression of satisfaction in Airbnb reviews isn't just saying \"it was good,\" but explicitly stating willingness to recommend it to others.\n",
        "\n",
        "**Business Insight:** Positive reviews are a self-reinforcing loop. The frequency of these phrases suggests that social proof is the strongest currency on the platform.\n",
        "\n",
        "5. **Language & Demographics**\n",
        "Evidence: There is a significant presence of French phrases (\"tres bien\", \"bien situe\", \"tres bon sejour\") in the top n-grams for both cities, but especially in Barcelona.\n",
        "\n",
        "This signals a strong French tourist demographic, likely due to proximity (for BCN) and popularity.\n",
        "\n",
        "**Business Insight:** Hosts should consider translating guidebooks into French or having French-speaking support staff to cater to this large segment."
      ],
      "metadata": {
        "id": "xwwLStlGhPN-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWTOrskPNjB7"
      },
      "source": [
        "### Topic Modelling with LDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiJnnXGGqgZa"
      },
      "source": [
        "To move beyond explicit keyword frequency, we apply Latent Dirichlet Allocation (LDA).\n",
        "\n",
        "This unsupervised probabilistic model assumes that each review is a mixture of underlying topics, and each topic is a distribution of words. By analyzing the co-occurrence patterns of terms across the corpus, the algorithm clusters semantically related terms into coherent themes.\n",
        "\n",
        "We apply strict frequency filters (min_df=0.01, max_df=0.90) to exclude unclear/unspecific terms that lack information and rare outliers, ensuring the resulting topics represent the guest experience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdEYiPSjq1Um"
      },
      "outputs": [],
      "source": [
        "def plot_lda_topics(model, vectorizer, n_top_words=10):\n",
        "    \"\"\"\n",
        "    Visualizes LDA topics as horizontal bar charts.\n",
        "    \"\"\"\n",
        "    feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "    n_topics = model.components_.shape[0]\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10), sharex=True)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        if topic_idx >= len(axes): break\n",
        "\n",
        "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
        "        top_features = [feature_names[i] for i in top_features_ind]\n",
        "        weights = topic[top_features_ind]\n",
        "\n",
        "        ax = axes[topic_idx]\n",
        "        ax.barh(top_features, weights, height=0.7, color='#457B9D')\n",
        "        ax.set_title(f'Topic {topic_idx + 1}', fontdict={'fontsize': 14, 'fontweight': 'bold'})\n",
        "        ax.invert_yaxis()\n",
        "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
        "        for i in 'top right left'.split():\n",
        "            ax.spines[i].set_visible(False)\n",
        "\n",
        "    fig.suptitle('Latent Themes in Airbnb Reviews (LDA Analysis)', fontsize=16, fontweight='bold')\n",
        "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.3, hspace=0.3)\n",
        "    plt.show()\n",
        "\n",
        "print(\"Configuring LDA\")\n",
        "\n",
        "# Intelligent Vectorization. Ignores words that appear 90% of cases.\n",
        "lda_vectorizer = CountVectorizer(\n",
        "    max_df=0.90,\n",
        "    min_df=0.0,\n",
        "    stop_words=final_stopwords,\n",
        "    max_features=5000\n",
        ")\n",
        "\n",
        "corpus = df_filtered['clean_text'].dropna()\n",
        "doc_term_matrix = lda_vectorizer.fit_transform(corpus)\n",
        "\n",
        "lda_model = LatentDirichletAllocation(\n",
        "    n_components=6,\n",
        "    random_state=100498308,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f\"Training LDA over {doc_term_matrix.shape[0]} reviews...\")\n",
        "lda_model.fit(doc_term_matrix)\n",
        "\n",
        "print(\"Generating topic visualization...\")\n",
        "plot_lda_topics(lda_model, lda_vectorizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Interpretation & Business Insights\n",
        "\n"
      ],
      "metadata": {
        "id": "4oJXV41mDXp1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*AI NOTE: the following conclusion from the LDA was extracted using GenAI. Prompt: Make an interpretation in English of this LDA, based on the graphic I am providing with and considering the context of the review analysis**.\n",
        "\n",
        "Our LDA reveals that guest satisfaction is not uniform. It is segmented by language differences. While English speakers fragment into three distinct profiles based on their travel style, European neighbors (Spanish, French) form distinct clusters with specific priorities.\n",
        "\n",
        "**Topic 1: The \"Standard International\" (English)**\n",
        "This is the baseline international tourist. They are looking for the three things: Location, Hygiene, and Safety. Their reviews are balanced and holistic. This is our mass market. To satisfy them, we don't need to be unique; we need to be reliable. No red flags, good location, clean sheets.\n",
        "\n",
        "**Topic 2: The \"Francophone Product-Critic\" (French)**\n",
        "The French market is consistently focused on the physical product. They analyze the \"Appartement\" (the asset) more than the \"Host\" (the person). They value aesthetics, functionality. Marketing to this group requires high-quality photos and detailed lists of amenities. They are the most likely to complain if the reality doesn't match the listing photos.\n",
        "\n",
        "**Topic 3: The \"Spanish Pragmatist\" (Spanish A)**\n",
        "This Spanish cluster is purely logistical. They talk about the \"Piso\" (the flat) and \"Ubicación\" (Location). They are judging the asset's convenience—is it close to the metro? Is it in a good zone? Is it good value for money? This group is price-sensitive and practical. We must sell them on connectivity and value. \"Steps from Metro\" is their trigger phrase.\n",
        "\n",
        "**Topic 4: The \"Spanish Socialite\" (Spanish B)**\n",
        "This is the emotional side of the Spanish market. The algorithm separated this from Topic 3 because the vocabulary is completely different. Here, the asset doesn't matter; the Host does. They value warmth, personal attention (\"trato\"), and feeling at home. To capture this segment, automation fails. We need a human touch—a warm welcome message, a personal recommendation, or a small welcome gift.\n",
        "\n",
        "**Topic 5: The \"English Logistics & Details\" (English)**\n",
        "Unlike the general enthusiasts in Topic 1, these English speakers are focused on the process. They judge the efficiency of the arrival, the ease of access (keypad vs. keys), and communication speed. They are likely business travelers or short-stay tourists.\n",
        "\n",
        "Business Insight: This group fears friction. Your selling point here is \"Self Check-in\" and \"Instant Book\".\n",
        "\n",
        "Topic 6: The \"Universal Traveler\" (Mixed Language)\n",
        "Likely Keywords: Metro, Super, Perfect, 10/10, Center, Taxi, WiFi, Top.\n",
        "\n",
        "Profile: This interesting cluster contains \"loanwords\" or universal terms used across all languages. It represents short, punchy reviews from global travelers who use simplified \"International English/Spanglish\".\n",
        "\n",
        "Business Insight: These reviews are usually impulsive and highly positive. They signal a property that is \"universally understood\" to be good (likely very central)."
      ],
      "metadata": {
        "id": "3r5yO2-PMj8b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NonUPkgjNlsm"
      },
      "source": [
        "## **Step 5: Rating Drivers**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform the analysis for rating drivers, we will merge the sentiment columns (df_filtered) with the listings_first_clean. We do this so that we have a single dataframe ready for correlation analysis to find the ratings drivers."
      ],
      "metadata": {
        "id": "WZv1ZgtOi9vq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we group by and calculate the average sentiment score.\n",
        "listing_sentiment = df_filtered.groupby('listing_id')['sentiment_score'].agg(['mean', 'count']).reset_index()\n",
        "listing_sentiment.columns = ['id', 'avg_sentiment', 'review_count_sample']\n",
        "\n",
        "# Ensure 'id' column in listing_sentiment is of type float to match listings_first_clean\n",
        "listing_sentiment['id'] = listing_sentiment['id'].astype(float)\n",
        "\n",
        "print(f\"Sentiment calculated for {len(listing_sentiment)} accomodations.\")\n",
        "\n",
        "# Secondly, we merge this sentiment with the main listing dataset.\n",
        "combined_listings_with_sentiment = pd.merge(\n",
        "    combined_listings_review_analysis,\n",
        "    listing_sentiment,\n",
        "    on='id',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "mm5357HXfz5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Correlations**\n",
        "\n",
        "1) Price vs Sentiment\n",
        "2) Rating vs Sentiment"
      ],
      "metadata": {
        "id": "q_oqB_6-owip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_price = combined_listings_with_sentiment['price'].corr(combined_listings_with_sentiment['avg_sentiment'])\n",
        "corr_rating = combined_listings_with_sentiment['review_scores_rating'].corr(combined_listings_with_sentiment['avg_sentiment'])\n",
        "\n",
        "print(f\"Correlation Price vs Sentiment: {corr_price:.3f}\")\n",
        "print(f\"Correlation Rating  vs Sentiment: {corr_rating:.3f}\")"
      ],
      "metadata": {
        "id": "MrflBAwUooLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly, we see that Price tends to negatively affect Sentiment (the higher the price, the lower the sentiment) but this is a very weak, almost diminishable relation.\n",
        "\n",
        "On the contrary, as one would expect, the higher the rating, the higher the sentiment. This is obviously normal, as the Sentiment we calculated is based on the ratings."
      ],
      "metadata": {
        "id": "nsaatPIrvP3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Price vs Sentiment grouped per Room Type & City"
      ],
      "metadata": {
        "id": "rmoxsM0xpHu6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MyKNGhbppbu"
      },
      "outputs": [],
      "source": [
        "correlation_by_room = combined_listings_with_sentiment.groupby('room_type').apply(\n",
        "    lambda x: x['price'].corr(x['avg_sentiment']))\n",
        "\n",
        "print(\"Price-Sentiment by Room Type\")\n",
        "display(correlation_by_room.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we focus on the Price vs Sentiment relation, but depending on the Room Type; we get that the most drivers of satisfaction are the Hotel Rooms.\n",
        "\n",
        "This would be surprisingly contrary to the belief we had about the Airbnb Bias we commented previously, but still it is very interesting to know because we have a sense of the type of rooms people tend to prefer."
      ],
      "metadata": {
        "id": "k_shpHy4viuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def corr_debug(df):\n",
        "    return pd.DataFrame({\n",
        "        'n_rows': df.groupby('City').size(),\n",
        "        'n_price_nonnull': df.groupby('City')['price'].apply(lambda s: s.notna().sum()),\n",
        "        'n_sent_nonnull': df.groupby('City')['avg_sentiment'].apply(lambda s: s.notna().sum()),\n",
        "        'price_std': df.groupby('City')['price'].std(),\n",
        "        'sentiment_std': df.groupby('City')['avg_sentiment'].std()\n",
        "    })\n",
        "\n",
        "debug_stats = corr_debug(combined_listings_with_sentiment)\n",
        "print(debug_stats)\n",
        "\n",
        "correlation_by_city = combined_listings_with_sentiment.groupby('City').apply(\n",
        "    lambda x: x['price'].corr(x['avg_sentiment'])\n",
        ")\n",
        "print(\"\\nPrice-Sentiment by City\")\n",
        "print(correlation_by_city)"
      ],
      "metadata": {
        "id": "MrcywIR321Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, if we specify the price-sentiment relation divided by city, we have the following:\n",
        "- For Barcelona, the price-sentiment relation is extremely weak positive, so we deem this as diminishable, we do not consider this of relevance.\n",
        "- For Madrid, the the price-sentiment relation is extremely weak negative. We also consider this of no relevance."
      ],
      "metadata": {
        "id": "jKnAI7oBv8B8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let´s take it up a notch. Let´s see the correlation between avg_sentiment and the rest of numerical features."
      ],
      "metadata": {
        "id": "rM49348LvEbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify all numerical columns in the DataFrame\n",
        "numerical_columns = combined_listings_with_sentiment.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Ensure 'avg_sentiment' is in the list, and remove 'id' if not desired for correlation analysis\n",
        "# (listing_id, scrape_id, host_id are usually identifiers, not features for correlation with sentiment)\n",
        "columns_to_exclude_from_corr = ['id', 'scrape_id', 'host_id', 'listing_id'] # Add other ID-like columns if they exist and are numerical\n",
        "numerical_features_for_corr = [col for col in numerical_columns if col not in columns_to_exclude_from_corr and col != 'review_count_sample']\n",
        "\n",
        "# Add 'avg_sentiment' if it's not already there after exclusions\n",
        "if 'avg_sentiment' not in numerical_features_for_corr:\n",
        "    numerical_features_for_corr.append('avg_sentiment')\n",
        "\n",
        "# Filter the DataFrame to only include these numerical features and drop rows with NaNs for correlation calculation\n",
        "df_corr = combined_listings_with_sentiment[numerical_features_for_corr].dropna()\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "corr_matrix = df_corr.corr()\n",
        "\n",
        "print(\"Correlation Matrix of Numerical Features with Average Sentiment:\")\n",
        "# Display only the correlations with 'avg_sentiment', sorted\n",
        "display(corr_matrix[['avg_sentiment']].sort_values(by='avg_sentiment', ascending=False))"
      ],
      "metadata": {
        "id": "vrkp6kWOtKuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this result, we know what *numerical* variables to put into the regression model. Please note that for the review_based variables we will not insert them even if they have high correlations because they are literally based on the ratings, so it would create multicolinearity."
      ],
      "metadata": {
        "id": "sN2vVsFgwbZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Regression Model**\n",
        "\n",
        "Now, using a Regression Model, we try to predict what are the most important rating drivers.\n",
        "\n",
        "We use the model *combined_listings_with_sentiment*.\n",
        "We then define the features to be used and we \"forget\" the ones who are not relevant for the model. We also define a pipeline to automatically scale numeric variables and codify categorical ones.\n",
        "\n",
        "We use Ridge instead of the simple Regression because it is more robust."
      ],
      "metadata": {
        "id": "fLti388ZlnrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_model = combined_listings_with_sentiment.copy()\n",
        "\n",
        "features = [\n",
        "    \"price\",\n",
        "    \"host_is_superhost\",\n",
        "    \"accommodates\",\n",
        "    \"bedrooms\",\n",
        "    \"room_type\",\n",
        "    \"neighbourhood_group_cleansed\",\n",
        "    \"estimated_occupancy_l365d\",\n",
        "    \"number_of_reviews\",\n",
        "    ]\n",
        "target = 'avg_sentiment'\n",
        "\n",
        "df_model = df_model.dropna(subset=features + [target])\n",
        "\n",
        "X = df_model[features]\n",
        "y = df_model[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training samples: {X_train.shape[0]}\")\n",
        "print(f\"Testing samples: {X_test.shape[0]}\")\n",
        "\n",
        "\n",
        "numeric_features = ['price', 'accommodates', 'bedrooms', \"estimated_occupancy_l365d\", \"number_of_reviews\"]\n",
        "categorical_features = ['host_is_superhost', 'room_type', \"neighbourhood_group_cleansed\"]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_features) # drop='first' evita multicolinealidad en regresión lineal\n",
        "    ])\n",
        "\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', Ridge(alpha=1.0))\n",
        "])\n",
        "\n",
        "print(\"\\nEntrenando modelo de Drivers...\")\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Resultados en Test Set:\")\n",
        "print(f\"R2 Score: {r2_score(y_test, y_pred):.4f}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
        "\n",
        "\n",
        "feature_names = numeric_features.copy()\n",
        "cat_names = model_pipeline.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features)\n",
        "feature_names.extend(cat_names)\n",
        "\n",
        "coefs = model_pipeline.named_steps['regressor'].coef_\n",
        "\n",
        "drivers_df = pd.DataFrame({\n",
        "    'Driver': feature_names,\n",
        "    'Impact (Coefficient)': coefs,\n",
        "    'Abs Impact': np.abs(coefs)\n",
        "}).sort_values(by='Abs Impact', ascending=False)\n",
        "\n",
        "print(\"\\n--- TOP SATISFACTION DRIVERS ---\")\n",
        "display(drivers_df)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=drivers_df, x='Impact (Coefficient)', y='Driver', palette='coolwarm')\n",
        "plt.title(\"¿What increases/decreases sentiment?\")\n",
        "plt.axvline(0, color='black', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X9frtTVoZgTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Conclusions**"
      ],
      "metadata": {
        "id": "QKX7IMEiwvOF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. We must focus on those accomodations where the host is superhost. It is the highest driver of rating.\n",
        "\n",
        "2. Geographical position is one of the most drivers of satisfaction. We must focus on Madrid, as it is the best satisfaction driver of the two cities, by a large amount. Inside Madrid, we recommend to focus on *(this depends on the boards number of areas they want to cover)* the following neighbourhoods:\n",
        "- Vicálvaro\n",
        "- Retiro\n",
        "- Salamanca\n",
        "- Canillejas\n",
        "- Chamartín\n",
        "\n",
        "3. The total number of reviews an accomodation has **does not directly mean that the accomodation will have a higher rating**\n",
        "\n",
        "4. The *number of bedrooms*, *estimated occupancy-l365d*, *price* are not very high drivers of satisfaction. They have a low relationship. It is not recommended to forget them, but the geographical position seems to be more relevant.\n",
        "\n",
        "5. Regarding negative drivers, we must **not offer shared rooms**, the neighborhoods Guimardó, Usera, Les Corts, San Andreu do terribly in reviews."
      ],
      "metadata": {
        "id": "0T-S7c6Lwygk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Executive Summary**\n",
        "\n",
        "Our analysis of Airbnb reviews reveals a marketplace dominated by high satisfaction scores, driven largely by the \"Airbnb Bias.\" As identified in academic literature, the interpersonal nature of the sharing economy creates social pressure, leading guests to avoid explicit negative ratings Consequently, 93% of reviews are positive, meaning investors cannot rely solely on star ratings to gauge performance.\n",
        "\n",
        "Despite this universal bias, distinct patterns emerged between the two markets. Madrid demonstrates a higher and more consistent level of guest satisfaction compared to Barcelona. Furthermore, regression analysis identifies Geographical Position and Superhost Status as the strongest predictors of a high rating, far outweighing physical attributes like the number of bedrooms or price.\n",
        "\n",
        "These location- and management-driven effects are consistent with our pricing and revenue analyses: Superhosts consistently outperform, and Madrid shows higher occupancy stability, reinforcing the strategic recommendation."
      ],
      "metadata": {
        "id": "uRbwODxuAXDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Recommendations for Investors**\n",
        "\n",
        "Based on the Sentiment, Keyword, Topic, and Regression analyses, we propose the following strategic roadmap for investment and management:\n",
        "\n",
        "1. **Location Strategy:**\n",
        "- Primary City Focus: prioritize capital allocation in Madrid. The regression analysis confirms that being located in Madrid is a significantly stronger driver of satisfaction than being in Barcelona.\n",
        "- Target Neighborhoods (Madrid): Within the capital, focus acquisition efforts on Retiro, Salamanca, Chamartín, Vicálvaro, and Canillejas. These areas are statistically correlated with higher guest ratings.\n",
        "- The \"Walking Distance\" Premium: In both cities, the ability to walk to major hubs is a primary delight factor.\n",
        "  - Madrid: Assets must be near Gran Vía, Sol, or Plaza Mayor\n",
        "  - Barcelona: Proximity to La Sagrada Familia is the dominant location driver\n",
        "  - Connectivity: If the asset is not city-center, proximity to a Metro station is mandatory for positive sentiment.\n",
        "\n",
        "2. **Operational Strategy:**\n",
        "- The \"Superhost\" Imperative: Achieving Superhost status is not a vanity metric; it is the single highest driver of ratings in our regression model. Investors must budget for professional, high-touch management that prioritizes responsiveness and problem-solving.\n",
        "- Hygiene as a Deal-Breaker: \"Clean\" is a top-frequency keyword. Cleanliness is a non-negotiable hygiene factor; if a listing is not spotless, the rating collapses.\n",
        "- Asset Type & Amenities:\n",
        "  - Hotel Room / Serviced Apartments: Contrary to the assumption that guests only want \"homey\" vibes, Hotel Rooms were identified as top satisfaction drivers. This suggests a high demand for professionalized standards (easy check-in, predictability) within the platform.\n",
        "  - Equipment: especially for Barcelona (likely due to family/longer stays), ensure apartments are \"well equipped\" (washing machines, full kitchens) to secure positive reviews.\n",
        "\n",
        "3. **Marketing & Demographic Targeting**\n",
        "- Leverage the \"Linguistic niches\": Our Topic Analysis identified distinct guest personas. Listings should be tailored to capture these markets:\n",
        "  - The French Market: A massive demographic (especially in BCN). Translate guidebooks and listing descriptions into French. Emphasize \"pleasant stay\" (sejour agreable) and practicality.\n",
        "  - The Italian Market: Emphasize the strategic position (ottima posizione) of the asset in marketing materials.\n",
        "  - The \"Lifestyle\" Traveler (English speakers): Sell the neighborhood, not just the unit. Highlight nearby restaurants, walkability, and the local vibe.\n",
        "- Encourage Recommendations: Since \"willingness to recommend\" is the ultimate currency of satisfaction, post-stay communication should gently encourage guests to mention if they would recommend the place to others, fueling social proof.\n",
        "\n",
        "4. **Investment Misconceptions (What NOT to prioritize)**\n",
        "- Price Sensitivity is Low: We found a negligible relationship between Price and Sentiment. High prices do not automatically lead to harsher reviews. Investors should not fear premium pricing if the location and hygiene factors are met.\n",
        "- Volume does not equal Quality: Do not simply buy assets based on the total number of reviews. A high volume of reviews does not correlate with higher satisfaction. Focus on quality consistency over booking quantity.\n",
        "- Physical Specs are Secondary: The number of bedrooms and occupancy capacity have a low relationship with satisfaction. A small, well-located studio in Salamanca managed by a Superhost will outperform a large, ill-positioned apartment in ratings."
      ],
      "metadata": {
        "id": "cSjxkEqd1l2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Final Verdict**\n",
        "\n",
        "For maximum ROI based on guest satisfaction, the data points to Madrid as the superior investment environment. The winning formula is Professional Management (Superhost level) + Prime Location (Walking distance to landmarks). While Barcelona offers high volume, Madrid offers stability and higher sentiment consistency."
      ],
      "metadata": {
        "id": "Y-2Zi4cK3_iL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Conclusions**"
      ],
      "metadata": {
        "id": "LK_EoaddGuzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Throughout this project, we have conducted a comprehensive analysis of the Airbnb market in Madrid and Barcelona, combining descriptive analysis techniques, spatial segmentation, price and occupancy studies, Superhost evaluations, and an in-depth analysis of reviews using NLP. The multidimensional comparison between the two markets allows us to draw a clear and well-founded conclusion: **Madrid offers a more solid, stable, and consistent investment opportunity than Barcelona**, especially for investors who prioritize controlled risk, stable demand, and the ability to scale a portfolio.\n",
        "\n",
        "Firstly, from a strictly economic perspective, **Barcelona has higher price levels, but also greater volatility**, with highly dispersed distributions and strong dependence on specific tourist areas. **Madrid, although slightly cheaper per night, offers a much more predictable price structure and consistently higher occupancy across all accommodation categories**. This means that revenues in Madrid, although somewhat lower per night, show greater operational stability and less exposure to fluctuations in demand due to seasonal factors or supply saturation.\n",
        "\n",
        "Geographical analysis confirms this difference in behavior. Barcelona is organized around a small number of hypercompetitive tourist corridors (Gothic Quarter, Eixample, coast), where the concentration of supply does not reduce prices due to extremely strong but volatile demand. In contrast, **Madrid has multiple profitable micro-markets**, which are more widely distributed throughout the city and subject to less direct competitive pressure. Furthermore, the penalty for distance from the center is much more pronounced in Madrid, making it easier to identify optimal areas where the price-location ratio is particularly favorable for investors.\n",
        "\n",
        "The operational dimension adds a decisive element. Our analysis of Superhosts' performance shows that the status is not cosmetic: it has a real economic impact, raising prices, occupancy, and, overall, total revenue. However, the way this impact manifests itself differs between cities. **In Barcelona, the Superhost advantage mainly translates into greater pricing power; in Madrid, on the other hand, the improvement is mainly seen in occupancy (+10 percentage points)**. From an investor's point of view, this difference is key: **occupancy is a more stable and resilient driver of revenue than price**, so the “Superhost effect” in Madrid is especially valuable for a portfolio focused on revenue stability.\n",
        "\n",
        "Finally, the analysis of reviews and sentiment provides a qualitative dimension that reinforces the same conclusion. Although there is a systematic bias toward positivity on Airbnb—which limits the discriminatory power of numerical scores—we observe consistent patterns: **Madrid not only obtains a higher sentiment score, but also less dispersion and greater homogeneity in the guest experience**. This means that reputational risk is lower and that satisfaction depends more on manageable factors (location, cleanliness, management) and not on seasonal fluctuations or tourist tensions, as is the case in Barcelona.\n",
        "\n",
        "Overall, the results clearly converge:\n",
        "**Madrid offers a more balanced, less volatile market, with highly profitable micro-areas, a Superhost effect that enhances operational stability, and more consistent customer behavior**. Barcelona, while more lucrative in very specific scenarios, has greater competition, dependence on tourism, and volatility in sentiment and prices.\n",
        "\n",
        "Therefore, **the final recommendation for investors is to prioritize investment in Madrid**, particularly in the neighborhoods of **Salamanca, Retiro, Chamartín, Vicálvaro, and Canillejas**, apply professional management geared toward Superhost status, and secure locations with good connectivity and high pedestrian accessibility to major urban hubs.\n",
        "\n",
        "In this way, Madrid is positioned, under quantitative and qualitative metrics, as the most solid environment for maximizing risk-adjusted returns and building a sustainable, consistent, and scalable Airbnb portfolio in the long term.\n"
      ],
      "metadata": {
        "id": "4Y3cBEG0GzcJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "1WEsqMaHT-5b",
        "K2seRgPMmhM1",
        "ImwvI4zaitjN",
        "olF-r-8WGoQH",
        "UnFcFC97JH6Q",
        "x2QNRl05_iBT",
        "oFdh6ZJAlT7w",
        "q2HA3PNnAcoA",
        "RnUwr9jJVEni",
        "ZCKncG44Sjhc",
        "JetLpBykJoTf",
        "OvDwoZbhJ1jP",
        "VU1lbWLoJ4Tq",
        "jZplo1L_J6ka",
        "kGFvJ9O4L1aQ",
        "1AaVWlNJ563U",
        "Rcn5c4FOMPJx",
        "hW0uSCU7m_0o"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}